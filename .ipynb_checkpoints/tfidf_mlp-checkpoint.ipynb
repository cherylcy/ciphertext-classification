{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d11aac-2269-493f-8492-7e166a088ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 01:00:36.479611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Add, Concatenate\n",
    "from keras.layers import BatchNormalization, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977fb70e-cb45-4531-b668-aa5649b3a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    data_path = {\n",
    "        'train': './data/train_enc.tsv',\n",
    "        'dev': './data/dev_enc.tsv',\n",
    "        'test': './test_enc_unlabeled.tsv'\n",
    "    }\n",
    "    res = []\n",
    "    if dataset in ['train','dev']:\n",
    "        for x in open(data_path[dataset], encoding='utf-8'):\n",
    "            x = x.rstrip('\\n\\r').split('\\t')\n",
    "            x[0] = int(x[0])\n",
    "            res.append(x)\n",
    "    elif dataset == 'test':\n",
    "        for x in open(data_path[dataset], encoding='utf-8'):\n",
    "            x = x.rstrip('\\n\\r')\n",
    "            res.append(x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6e1d02-24fb-403c-8bcb-fbabbcb42f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('train')\n",
    "dev = load_data('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff102844-3f94-44ea-a82a-90b3fec9759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [x[0] for x in train]\n",
    "train_texts = [x[1] for x in train]\n",
    "dev_labels = [x[0] for x in dev]\n",
    "dev_texts = [x[1] for x in dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee3fbab-94b5-42c6-b6a1-ae3a586983b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16220\n",
      "Dev size: 2027\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", len(train_labels))\n",
    "print(\"Dev size:\", len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde5efb8-877a-4399-8b65-91c025a2e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16220, 17248)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(train_texts)\n",
    "cv_vec = cv.transform(train_texts)\n",
    "print(cv_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfeed907-ccc6-46ac-9c17-03265c148240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features using TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1,4),\n",
    "    max_df=0.6,\n",
    "    min_df=0.001\n",
    ")\n",
    "tfidf.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f19260-275f-4064-9525-048304e22076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16220, 3967)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = tfidf.transform(train_texts)\n",
    "print(tfidf_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94902123-853f-4fba-80e5-336bccae5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the feats_matrix\n",
    "train_feats_matrix = tfidf.transform(train_texts).toarray()\n",
    "dev_feats_matrix = tfidf.transform(dev_texts).toarray()\n",
    "# convert labels to label_matrix\n",
    "num_classes = 2\n",
    "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
    "train_label_matrix = keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
    "dev_label_matrix = keras.utils.to_categorical(dev_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe316ea-2bd5-48ff-834a-d23cf814c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP(input_size, output_size, num_layers, hidden_size,\n",
    "              activation=\"relu\",\n",
    "              dropout_rate=0.0,\n",
    "              batch_norm=False,\n",
    "              layer_norm=False,\n",
    "              l2_reg=0.0,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              learning_rate=0.1,\n",
    "              metric=\"accuracy\"):\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "    if num_layers == 1:\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=input_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\",\n",
    "                        kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "    else:\n",
    "        for i in range(num_layers-1):\n",
    "            if i == 0:\n",
    "                # fitst layer: input -> hidden\n",
    "                model.add(Dense(hidden_size,\n",
    "                                input_dim=input_size,\n",
    "                                kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                                bias_initializer=\"zeros\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            else:\n",
    "                # hidden layers: hidden -> hidden\n",
    "                model.add(Dense(hidden_size,\n",
    "                                input_dim=hidden_size,\n",
    "                                kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                                bias_initializer=\"zeros\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            # add layer_norm\n",
    "            if layer_norm:\n",
    "                model.add(LayerNormalization())\n",
    "            # add batch_norm\n",
    "            if batch_norm:\n",
    "                model.add(BatchNormalization())\n",
    "            # add activation\n",
    "            model.add(Activation(activation))\n",
    "            # add dropout here (set seed as 0 in order to reproduce)\n",
    "            if dropout_rate > 0.0:\n",
    "                model.add(Dropout(dropout_rate, seed=0))\n",
    "        # last layer: hidden -> class\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=hidden_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\"))\n",
    "    \n",
    "    # set the loss, the optimizer, and the metric\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf9fb87-fcd4-46a7-affa-86e7c8d2b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01dd96f5-f00c-41e1-918c-7f12ff9c0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5924 - loss: 0.7535 - val_accuracy: 0.7928 - val_loss: 0.4556\n",
      "Epoch 2/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7814 - loss: 0.4785 - val_accuracy: 0.8185 - val_loss: 0.4559\n",
      "Epoch 3/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.3746 - val_accuracy: 0.8397 - val_loss: 0.4411\n",
      "Epoch 4/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8765 - loss: 0.2996 - val_accuracy: 0.8411 - val_loss: 0.4604\n",
      "Epoch 5/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8953 - loss: 0.2586 - val_accuracy: 0.8367 - val_loss: 0.5235\n",
      "Epoch 6/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2263 - val_accuracy: 0.8485 - val_loss: 0.5016\n",
      "Epoch 7/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.1930 - val_accuracy: 0.8535 - val_loss: 0.5213\n",
      "Epoch 8/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9349 - loss: 0.1682 - val_accuracy: 0.8569 - val_loss: 0.5636\n",
      "Epoch 9/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.1463 - val_accuracy: 0.8633 - val_loss: 0.5454\n",
      "Epoch 10/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9485 - loss: 0.1315 - val_accuracy: 0.8648 - val_loss: 0.5287\n",
      "Epoch 11/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.1321 - val_accuracy: 0.8604 - val_loss: 0.5466\n",
      "Epoch 12/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1207 - val_accuracy: 0.8678 - val_loss: 0.5671\n",
      "Epoch 13/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9591 - loss: 0.1090 - val_accuracy: 0.8673 - val_loss: 0.5766\n",
      "Epoch 14/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.0966 - val_accuracy: 0.8663 - val_loss: 0.5878\n",
      "Epoch 15/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.0950 - val_accuracy: 0.8777 - val_loss: 0.6206\n",
      "Epoch 16/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0831 - val_accuracy: 0.8688 - val_loss: 0.6447\n",
      "Epoch 17/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.0784 - val_accuracy: 0.8633 - val_loss: 0.6934\n",
      "Epoch 18/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9704 - loss: 0.0781 - val_accuracy: 0.8688 - val_loss: 0.6380\n",
      "Epoch 19/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0712 - val_accuracy: 0.8732 - val_loss: 0.6845\n",
      "Epoch 20/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0684 - val_accuracy: 0.8722 - val_loss: 0.6656\n",
      "Epoch 21/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.0653 - val_accuracy: 0.8742 - val_loss: 0.6447\n",
      "Epoch 22/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0573 - val_accuracy: 0.8742 - val_loss: 0.7099\n",
      "Epoch 23/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0567 - val_accuracy: 0.8737 - val_loss: 0.6812\n",
      "Epoch 24/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.0511 - val_accuracy: 0.8752 - val_loss: 0.7068\n",
      "Epoch 25/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9787 - loss: 0.0537 - val_accuracy: 0.8747 - val_loss: 0.7171\n",
      "Epoch 26/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9807 - loss: 0.0530 - val_accuracy: 0.8752 - val_loss: 0.7242\n",
      "Epoch 27/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0476 - val_accuracy: 0.8717 - val_loss: 0.7585\n",
      "Epoch 28/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0498 - val_accuracy: 0.8747 - val_loss: 0.7410\n",
      "Epoch 29/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0430 - val_accuracy: 0.8727 - val_loss: 0.7499\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0389 - val_accuracy: 0.8737 - val_loss: 0.7576\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0447\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.6679\n",
      "training loss: 0.04433406516909599 training accuracy 0.9827989935874939\n",
      "validation loss: 0.6206386685371399 validation accuracy 0.8776516914367676\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=3, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e98d59-8e05-4aeb-9778-daed7b104f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.6148 - accuracy: 0.6948 - val_loss: 0.4475 - val_accuracy: 0.7918\n",
      "Epoch 2/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.4104 - accuracy: 0.8175 - val_loss: 0.4106 - val_accuracy: 0.8229\n",
      "Epoch 3/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3249 - accuracy: 0.8621 - val_loss: 0.3948 - val_accuracy: 0.8441\n",
      "Epoch 4/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2639 - accuracy: 0.8923 - val_loss: 0.3974 - val_accuracy: 0.8495\n",
      "Epoch 5/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2266 - accuracy: 0.9087 - val_loss: 0.4093 - val_accuracy: 0.8574\n",
      "Epoch 6/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1937 - accuracy: 0.9273 - val_loss: 0.4244 - val_accuracy: 0.8559\n",
      "Epoch 7/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1710 - accuracy: 0.9335 - val_loss: 0.4075 - val_accuracy: 0.8688\n",
      "Epoch 8/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1534 - accuracy: 0.9413 - val_loss: 0.4628 - val_accuracy: 0.8619\n",
      "Epoch 9/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1385 - accuracy: 0.9501 - val_loss: 0.4254 - val_accuracy: 0.8747\n",
      "Epoch 10/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1324 - accuracy: 0.9524 - val_loss: 0.4269 - val_accuracy: 0.8707\n",
      "Epoch 11/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1168 - accuracy: 0.9599 - val_loss: 0.4422 - val_accuracy: 0.8678\n",
      "Epoch 12/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1066 - accuracy: 0.9628 - val_loss: 0.4622 - val_accuracy: 0.8791\n",
      "Epoch 13/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1019 - accuracy: 0.9645 - val_loss: 0.4656 - val_accuracy: 0.8678\n",
      "Epoch 14/30\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.4902 - val_accuracy: 0.8752\n",
      "Epoch 15/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0954 - accuracy: 0.9668 - val_loss: 0.4805 - val_accuracy: 0.8673\n",
      "Epoch 16/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0870 - accuracy: 0.9702 - val_loss: 0.4719 - val_accuracy: 0.8806\n",
      "Epoch 17/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.4832 - val_accuracy: 0.8737\n",
      "Epoch 18/30\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0843 - accuracy: 0.9731 - val_loss: 0.4615 - val_accuracy: 0.8732\n",
      "Epoch 19/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 0.4790 - val_accuracy: 0.8722\n",
      "Epoch 20/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.4881 - val_accuracy: 0.8678\n",
      "Epoch 21/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.4771 - val_accuracy: 0.8663\n",
      "Epoch 22/30\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 0.5024 - val_accuracy: 0.8698\n",
      "Epoch 23/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0725 - accuracy: 0.9769 - val_loss: 0.4834 - val_accuracy: 0.8752\n",
      "Epoch 24/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0736 - accuracy: 0.9768 - val_loss: 0.4939 - val_accuracy: 0.8727\n",
      "Epoch 25/30\n",
      "507/507 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 0.4961 - val_accuracy: 0.8727\n",
      "Epoch 26/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0670 - accuracy: 0.9784 - val_loss: 0.5043 - val_accuracy: 0.8767\n",
      "Epoch 27/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.5041 - val_accuracy: 0.8732\n",
      "Epoch 28/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.5054 - val_accuracy: 0.8727\n",
      "Epoch 29/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.5015 - val_accuracy: 0.8727\n",
      "Epoch 30/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.5052 - val_accuracy: 0.8777\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.9864\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.8806\n",
      "training loss: 0.03251943364739418 training accuracy 0.9863748550415039\n",
      "validation loss: 0.47187790274620056 validation accuracy 0.8806117177009583\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d79cc2e-a1fe-4c84-aa74-9aa0e7b1c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.6856 - accuracy: 0.5801 - val_loss: 0.6768 - val_accuracy: 0.7010\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.6702 - accuracy: 0.6819 - val_loss: 0.6646 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.7102 - val_loss: 0.6511 - val_accuracy: 0.7277\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.6441 - accuracy: 0.7276 - val_loss: 0.6400 - val_accuracy: 0.7277\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.6331 - accuracy: 0.7394 - val_loss: 0.6302 - val_accuracy: 0.7316\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.7473 - val_loss: 0.6215 - val_accuracy: 0.7346\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.7523 - val_loss: 0.6138 - val_accuracy: 0.7361\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.6053 - accuracy: 0.7544 - val_loss: 0.6079 - val_accuracy: 0.7366\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5973 - accuracy: 0.7596 - val_loss: 0.5988 - val_accuracy: 0.7420\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.7593 - val_loss: 0.5926 - val_accuracy: 0.7454\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5829 - accuracy: 0.7633 - val_loss: 0.5866 - val_accuracy: 0.7454\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.7667 - val_loss: 0.5813 - val_accuracy: 0.7474\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7693 - val_loss: 0.5788 - val_accuracy: 0.7479\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5649 - accuracy: 0.7723 - val_loss: 0.5718 - val_accuracy: 0.7499\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7740 - val_loss: 0.5674 - val_accuracy: 0.7514\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7765 - val_loss: 0.5630 - val_accuracy: 0.7533\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5498 - accuracy: 0.7762 - val_loss: 0.5592 - val_accuracy: 0.7528\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7770 - val_loss: 0.5555 - val_accuracy: 0.7533\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7822 - val_loss: 0.5531 - val_accuracy: 0.7573\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7816 - val_loss: 0.5480 - val_accuracy: 0.7588\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7832 - val_loss: 0.5448 - val_accuracy: 0.7573\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5288 - accuracy: 0.7856 - val_loss: 0.5426 - val_accuracy: 0.7593\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7849 - val_loss: 0.5399 - val_accuracy: 0.7602\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7883 - val_loss: 0.5360 - val_accuracy: 0.7588\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7898 - val_loss: 0.5332 - val_accuracy: 0.7607\n",
      "Epoch 26/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7911 - val_loss: 0.5314 - val_accuracy: 0.7602\n",
      "Epoch 27/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7925 - val_loss: 0.5287 - val_accuracy: 0.7612\n",
      "Epoch 28/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7932 - val_loss: 0.5263 - val_accuracy: 0.7612\n",
      "Epoch 29/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7963 - val_loss: 0.5237 - val_accuracy: 0.7607\n",
      "Epoch 30/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5029 - accuracy: 0.7972 - val_loss: 0.5230 - val_accuracy: 0.7652\n",
      "Epoch 31/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5002 - accuracy: 0.7987 - val_loss: 0.5194 - val_accuracy: 0.7642\n",
      "Epoch 32/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7990 - val_loss: 0.5178 - val_accuracy: 0.7617\n",
      "Epoch 33/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.8015 - val_loss: 0.5152 - val_accuracy: 0.7662\n",
      "Epoch 34/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.8030 - val_loss: 0.5133 - val_accuracy: 0.7662\n",
      "Epoch 35/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.8041 - val_loss: 0.5095 - val_accuracy: 0.7652\n",
      "Epoch 37/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.8053 - val_loss: 0.5078 - val_accuracy: 0.7671\n",
      "Epoch 38/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.8054 - val_loss: 0.5060 - val_accuracy: 0.7676\n",
      "Epoch 39/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.8068 - val_loss: 0.5058 - val_accuracy: 0.7706\n",
      "Epoch 40/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8086 - val_loss: 0.5031 - val_accuracy: 0.7691\n",
      "Epoch 41/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8084 - val_loss: 0.5026 - val_accuracy: 0.7726\n",
      "Epoch 42/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.8091 - val_loss: 0.5001 - val_accuracy: 0.7691\n",
      "Epoch 43/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.8096 - val_loss: 0.4983 - val_accuracy: 0.7731\n",
      "Epoch 44/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4704 - accuracy: 0.8120 - val_loss: 0.4975 - val_accuracy: 0.7745\n",
      "Epoch 45/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8115 - val_loss: 0.4957 - val_accuracy: 0.7696\n",
      "Epoch 46/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.8126 - val_loss: 0.4952 - val_accuracy: 0.7750\n",
      "Epoch 47/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.8141 - val_loss: 0.4932 - val_accuracy: 0.7731\n",
      "Epoch 48/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8157 - val_loss: 0.4919 - val_accuracy: 0.7736\n",
      "Epoch 49/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4614 - accuracy: 0.8154 - val_loss: 0.4932 - val_accuracy: 0.7795\n",
      "Epoch 50/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8159 - val_loss: 0.4904 - val_accuracy: 0.7800\n",
      "Epoch 51/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.8160 - val_loss: 0.4880 - val_accuracy: 0.7741\n",
      "Epoch 52/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8173 - val_loss: 0.4884 - val_accuracy: 0.7805\n",
      "Epoch 53/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8193 - val_loss: 0.4858 - val_accuracy: 0.7765\n",
      "Epoch 54/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8200 - val_loss: 0.4846 - val_accuracy: 0.7829\n",
      "Epoch 55/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.8213 - val_loss: 0.4839 - val_accuracy: 0.7780\n",
      "Epoch 56/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.8192 - val_loss: 0.4826 - val_accuracy: 0.7815\n",
      "Epoch 57/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8217 - val_loss: 0.4819 - val_accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8237 - val_loss: 0.4804 - val_accuracy: 0.7829\n",
      "Epoch 59/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8221 - val_loss: 0.4811 - val_accuracy: 0.7819\n",
      "Epoch 60/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8242 - val_loss: 0.4786 - val_accuracy: 0.7839\n",
      "Epoch 61/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8247 - val_loss: 0.4783 - val_accuracy: 0.7810\n",
      "Epoch 62/100\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.4419 - accuracy: 0.8245 - val_loss: 0.4771 - val_accuracy: 0.7824\n",
      "Epoch 63/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8254 - val_loss: 0.4761 - val_accuracy: 0.7805\n",
      "Epoch 64/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8276 - val_loss: 0.4764 - val_accuracy: 0.7849\n",
      "Epoch 65/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4379 - accuracy: 0.8266 - val_loss: 0.4745 - val_accuracy: 0.7834\n",
      "Epoch 66/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4367 - accuracy: 0.8263 - val_loss: 0.4731 - val_accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4355 - accuracy: 0.8294 - val_loss: 0.4728 - val_accuracy: 0.7829\n",
      "Epoch 68/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.8286 - val_loss: 0.4716 - val_accuracy: 0.7879\n",
      "Epoch 69/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4331 - accuracy: 0.8289 - val_loss: 0.4709 - val_accuracy: 0.7874\n",
      "Epoch 70/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4318 - accuracy: 0.8312 - val_loss: 0.4715 - val_accuracy: 0.7849\n",
      "Epoch 71/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4308 - accuracy: 0.8303 - val_loss: 0.4694 - val_accuracy: 0.7908\n",
      "Epoch 72/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4297 - accuracy: 0.8303 - val_loss: 0.4693 - val_accuracy: 0.7869\n",
      "Epoch 73/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4284 - accuracy: 0.8318 - val_loss: 0.4693 - val_accuracy: 0.7834\n",
      "Epoch 74/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4274 - accuracy: 0.8316 - val_loss: 0.4676 - val_accuracy: 0.7903\n",
      "Epoch 75/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4264 - accuracy: 0.8326 - val_loss: 0.4667 - val_accuracy: 0.7913\n",
      "Epoch 76/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.4657 - val_accuracy: 0.7918\n",
      "Epoch 77/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8338 - val_loss: 0.4650 - val_accuracy: 0.7923\n",
      "Epoch 78/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4232 - accuracy: 0.8343 - val_loss: 0.4643 - val_accuracy: 0.7923\n",
      "Epoch 79/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4221 - accuracy: 0.8346 - val_loss: 0.4652 - val_accuracy: 0.7859\n",
      "Epoch 80/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4212 - accuracy: 0.8349 - val_loss: 0.4630 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8361 - val_loss: 0.4629 - val_accuracy: 0.7928\n",
      "Epoch 82/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8357 - val_loss: 0.4623 - val_accuracy: 0.7938\n",
      "Epoch 83/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4181 - accuracy: 0.8374 - val_loss: 0.4633 - val_accuracy: 0.7859\n",
      "Epoch 84/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8363 - val_loss: 0.4604 - val_accuracy: 0.7977\n",
      "Epoch 85/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8366 - val_loss: 0.4600 - val_accuracy: 0.7963\n",
      "Epoch 86/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8375 - val_loss: 0.4608 - val_accuracy: 0.7898\n",
      "Epoch 87/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4144 - accuracy: 0.8374 - val_loss: 0.4603 - val_accuracy: 0.7913\n",
      "Epoch 88/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4135 - accuracy: 0.8380 - val_loss: 0.4582 - val_accuracy: 0.7982\n",
      "Epoch 89/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4126 - accuracy: 0.8381 - val_loss: 0.4581 - val_accuracy: 0.7982\n",
      "Epoch 90/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8393 - val_loss: 0.4582 - val_accuracy: 0.7938\n",
      "Epoch 91/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8389 - val_loss: 0.4592 - val_accuracy: 0.7859\n",
      "Epoch 92/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4101 - accuracy: 0.8396 - val_loss: 0.4559 - val_accuracy: 0.7987\n",
      "Epoch 93/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4093 - accuracy: 0.8403 - val_loss: 0.4560 - val_accuracy: 0.8002\n",
      "Epoch 94/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4083 - accuracy: 0.8403 - val_loss: 0.4550 - val_accuracy: 0.8007\n",
      "Epoch 95/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4075 - accuracy: 0.8408 - val_loss: 0.4544 - val_accuracy: 0.8002\n",
      "Epoch 96/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4068 - accuracy: 0.8407 - val_loss: 0.4545 - val_accuracy: 0.8002\n",
      "Epoch 97/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4060 - accuracy: 0.8409 - val_loss: 0.4535 - val_accuracy: 0.8017\n",
      "Epoch 98/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4052 - accuracy: 0.8420 - val_loss: 0.4530 - val_accuracy: 0.8012\n",
      "Epoch 99/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8414 - val_loss: 0.4529 - val_accuracy: 0.8017\n",
      "Epoch 100/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4035 - accuracy: 0.8415 - val_loss: 0.4537 - val_accuracy: 0.7958\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8420\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8017\n",
      "training loss: 0.4050333797931671 training accuracy 0.842046856880188\n",
      "validation loss: 0.4535011053085327 validation accuracy 0.8016773462295532\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=1, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=100, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b71d67b2-2c7f-4144-b554-48d4bce55406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4051 - accuracy: 0.8417 - val_loss: 0.4540 - val_accuracy: 0.7982\n",
      "Epoch 102/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8417 - val_loss: 0.4530 - val_accuracy: 0.7997\n",
      "Epoch 103/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4035 - accuracy: 0.8426 - val_loss: 0.4521 - val_accuracy: 0.8022\n",
      "Epoch 104/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8425 - val_loss: 0.4522 - val_accuracy: 0.8007\n",
      "Epoch 105/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4020 - accuracy: 0.8446 - val_loss: 0.4517 - val_accuracy: 0.8022\n",
      "Epoch 106/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4013 - accuracy: 0.8435 - val_loss: 0.4509 - val_accuracy: 0.8037\n",
      "Epoch 107/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8443 - val_loss: 0.4510 - val_accuracy: 0.7997\n",
      "Epoch 108/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8451 - val_loss: 0.4512 - val_accuracy: 0.7987\n",
      "Epoch 109/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3992 - accuracy: 0.8451 - val_loss: 0.4494 - val_accuracy: 0.8041\n",
      "Epoch 110/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8457 - val_loss: 0.4489 - val_accuracy: 0.8037\n",
      "Epoch 111/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8465 - val_loss: 0.4485 - val_accuracy: 0.8076\n",
      "Epoch 112/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8457 - val_loss: 0.4480 - val_accuracy: 0.8076\n",
      "Epoch 113/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8456 - val_loss: 0.4495 - val_accuracy: 0.7967\n",
      "Epoch 114/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8464 - val_loss: 0.4473 - val_accuracy: 0.8061\n",
      "Epoch 115/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8468 - val_loss: 0.4472 - val_accuracy: 0.8041\n",
      "Epoch 116/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8469 - val_loss: 0.4469 - val_accuracy: 0.8041\n",
      "Epoch 117/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3936 - accuracy: 0.8478 - val_loss: 0.4464 - val_accuracy: 0.8061\n",
      "Epoch 118/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8477 - val_loss: 0.4458 - val_accuracy: 0.8071\n",
      "Epoch 119/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3923 - accuracy: 0.8475 - val_loss: 0.4467 - val_accuracy: 0.8017\n",
      "Epoch 120/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3915 - accuracy: 0.8485 - val_loss: 0.4450 - val_accuracy: 0.8096\n",
      "Epoch 121/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3910 - accuracy: 0.8494 - val_loss: 0.4447 - val_accuracy: 0.8096\n",
      "Epoch 122/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3903 - accuracy: 0.8480 - val_loss: 0.4451 - val_accuracy: 0.8066\n",
      "Epoch 123/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3896 - accuracy: 0.8489 - val_loss: 0.4447 - val_accuracy: 0.8066\n",
      "Epoch 124/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3890 - accuracy: 0.8491 - val_loss: 0.4436 - val_accuracy: 0.8096\n",
      "Epoch 125/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3884 - accuracy: 0.8500 - val_loss: 0.4432 - val_accuracy: 0.8096\n",
      "Epoch 126/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3878 - accuracy: 0.8501 - val_loss: 0.4435 - val_accuracy: 0.8076\n",
      "Epoch 127/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8508 - val_loss: 0.4428 - val_accuracy: 0.8091\n",
      "Epoch 128/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8511 - val_loss: 0.4424 - val_accuracy: 0.8106\n",
      "Epoch 129/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8516 - val_loss: 0.4421 - val_accuracy: 0.8106\n",
      "Epoch 130/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8511 - val_loss: 0.4429 - val_accuracy: 0.8076\n",
      "Epoch 131/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3849 - accuracy: 0.8514 - val_loss: 0.4415 - val_accuracy: 0.8096\n",
      "Epoch 132/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.8510 - val_loss: 0.4413 - val_accuracy: 0.8096\n",
      "Epoch 133/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8516 - val_loss: 0.4407 - val_accuracy: 0.8106\n",
      "Epoch 134/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8514 - val_loss: 0.4403 - val_accuracy: 0.8120\n",
      "Epoch 135/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8520 - val_loss: 0.4400 - val_accuracy: 0.8111\n",
      "Epoch 136/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3820 - accuracy: 0.8518 - val_loss: 0.4397 - val_accuracy: 0.8101\n",
      "Epoch 137/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8525 - val_loss: 0.4394 - val_accuracy: 0.8111\n",
      "Epoch 138/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8528 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 139/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3805 - accuracy: 0.8533 - val_loss: 0.4397 - val_accuracy: 0.8091\n",
      "Epoch 140/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3798 - accuracy: 0.8539 - val_loss: 0.4386 - val_accuracy: 0.8115\n",
      "Epoch 141/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8544 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 142/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8543 - val_loss: 0.4382 - val_accuracy: 0.8120\n",
      "Epoch 143/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8554 - val_loss: 0.4378 - val_accuracy: 0.8115\n",
      "Epoch 144/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8552 - val_loss: 0.4377 - val_accuracy: 0.8125\n",
      "Epoch 145/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8547 - val_loss: 0.4373 - val_accuracy: 0.8115\n",
      "Epoch 146/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8547 - val_loss: 0.4375 - val_accuracy: 0.8125\n",
      "Epoch 147/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8549 - val_loss: 0.4370 - val_accuracy: 0.8115\n",
      "Epoch 148/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8558 - val_loss: 0.4366 - val_accuracy: 0.8125\n",
      "Epoch 149/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3752 - accuracy: 0.8549 - val_loss: 0.4383 - val_accuracy: 0.8086\n",
      "Epoch 150/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8565 - val_loss: 0.4370 - val_accuracy: 0.8115\n",
      "Epoch 151/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8558 - val_loss: 0.4357 - val_accuracy: 0.8135\n",
      "Epoch 152/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3737 - accuracy: 0.8565 - val_loss: 0.4366 - val_accuracy: 0.8115\n",
      "Epoch 153/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8565 - val_loss: 0.4352 - val_accuracy: 0.8135\n",
      "Epoch 154/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8556 - val_loss: 0.4349 - val_accuracy: 0.8111\n",
      "Epoch 155/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8579 - val_loss: 0.4349 - val_accuracy: 0.8120\n",
      "Epoch 156/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3718 - accuracy: 0.8576 - val_loss: 0.4346 - val_accuracy: 0.8115\n",
      "Epoch 157/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8581 - val_loss: 0.4348 - val_accuracy: 0.8130\n",
      "Epoch 158/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3709 - accuracy: 0.8574 - val_loss: 0.4340 - val_accuracy: 0.8101\n",
      "Epoch 159/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8580 - val_loss: 0.4352 - val_accuracy: 0.8115\n",
      "Epoch 160/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3701 - accuracy: 0.8581 - val_loss: 0.4336 - val_accuracy: 0.8150\n",
      "Epoch 161/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3696 - accuracy: 0.8585 - val_loss: 0.4337 - val_accuracy: 0.8125\n",
      "Epoch 162/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3692 - accuracy: 0.8584 - val_loss: 0.4334 - val_accuracy: 0.8120\n",
      "Epoch 163/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8584 - val_loss: 0.4332 - val_accuracy: 0.8125\n",
      "Epoch 164/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8592 - val_loss: 0.4339 - val_accuracy: 0.8150\n",
      "Epoch 165/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3677 - accuracy: 0.8586 - val_loss: 0.4328 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3674 - accuracy: 0.8583 - val_loss: 0.4322 - val_accuracy: 0.8115\n",
      "Epoch 167/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8589 - val_loss: 0.4323 - val_accuracy: 0.8120\n",
      "Epoch 168/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8599 - val_loss: 0.4319 - val_accuracy: 0.8120\n",
      "Epoch 169/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3661 - accuracy: 0.8596 - val_loss: 0.4318 - val_accuracy: 0.8130\n",
      "Epoch 170/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.8593 - val_loss: 0.4328 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3652 - accuracy: 0.8607 - val_loss: 0.4313 - val_accuracy: 0.8140\n",
      "Epoch 172/200\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3649 - accuracy: 0.8598 - val_loss: 0.4318 - val_accuracy: 0.8150\n",
      "Epoch 173/200\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3643 - accuracy: 0.8595 - val_loss: 0.4321 - val_accuracy: 0.8150\n",
      "Epoch 174/200\n",
      "507/507 [==============================] - 3s 7ms/step - loss: 0.3640 - accuracy: 0.8599 - val_loss: 0.4312 - val_accuracy: 0.8140\n",
      "Epoch 175/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3636 - accuracy: 0.8611 - val_loss: 0.4308 - val_accuracy: 0.8130\n",
      "Epoch 176/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3633 - accuracy: 0.8597 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
      "Epoch 177/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8601 - val_loss: 0.4301 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8615 - val_loss: 0.4299 - val_accuracy: 0.8130\n",
      "Epoch 179/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8608 - val_loss: 0.4307 - val_accuracy: 0.8165\n",
      "Epoch 180/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8599 - val_loss: 0.4296 - val_accuracy: 0.8135\n",
      "Epoch 181/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8607 - val_loss: 0.4298 - val_accuracy: 0.8135\n",
      "Epoch 182/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8618 - val_loss: 0.4297 - val_accuracy: 0.8135\n",
      "Epoch 183/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8626 - val_loss: 0.4308 - val_accuracy: 0.8155\n",
      "Epoch 184/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8620 - val_loss: 0.4288 - val_accuracy: 0.8115\n",
      "Epoch 185/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8618 - val_loss: 0.4288 - val_accuracy: 0.8150\n",
      "Epoch 186/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8612 - val_loss: 0.4301 - val_accuracy: 0.8160\n",
      "Epoch 187/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8613 - val_loss: 0.4299 - val_accuracy: 0.8165\n",
      "Epoch 188/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8609 - val_loss: 0.4282 - val_accuracy: 0.8145\n",
      "Epoch 189/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8620 - val_loss: 0.4285 - val_accuracy: 0.8125\n",
      "Epoch 190/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8623 - val_loss: 0.4288 - val_accuracy: 0.8175\n",
      "Epoch 191/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3574 - accuracy: 0.8618 - val_loss: 0.4299 - val_accuracy: 0.8155\n",
      "Epoch 192/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3572 - accuracy: 0.8623 - val_loss: 0.4275 - val_accuracy: 0.8120\n",
      "Epoch 193/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8626 - val_loss: 0.4278 - val_accuracy: 0.8130\n",
      "Epoch 194/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8634 - val_loss: 0.4273 - val_accuracy: 0.8155\n",
      "Epoch 195/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.8626 - val_loss: 0.4270 - val_accuracy: 0.8130\n",
      "Epoch 196/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8633 - val_loss: 0.4273 - val_accuracy: 0.8130\n",
      "Epoch 197/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8635 - val_loss: 0.4269 - val_accuracy: 0.8150\n",
      "Epoch 198/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8637 - val_loss: 0.4267 - val_accuracy: 0.8150\n",
      "Epoch 199/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8641 - val_loss: 0.4268 - val_accuracy: 0.8150\n",
      "Epoch 200/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8641 - val_loss: 0.4279 - val_accuracy: 0.8165\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8640\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8175\n",
      "training loss: 0.35726192593574524 training accuracy 0.8639950752258301\n",
      "validation loss: 0.42880958318710327 validation accuracy 0.8174642324447632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=200, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer], initial_epoch=100)\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories[-1] = history\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c703c5a9-bd2b-46b3-9bee-bcc381ac8189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3574 - accuracy: 0.8630 - val_loss: 0.4288 - val_accuracy: 0.8155\n",
      "Epoch 202/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3571 - accuracy: 0.8625 - val_loss: 0.4279 - val_accuracy: 0.8125\n",
      "Epoch 203/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8631 - val_loss: 0.4274 - val_accuracy: 0.8155\n",
      "Epoch 204/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8628 - val_loss: 0.4279 - val_accuracy: 0.8155\n",
      "Epoch 205/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3560 - accuracy: 0.8641 - val_loss: 0.4277 - val_accuracy: 0.8155\n",
      "Epoch 206/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8636 - val_loss: 0.4271 - val_accuracy: 0.8155\n",
      "Epoch 207/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3553 - accuracy: 0.8634 - val_loss: 0.4274 - val_accuracy: 0.8155\n",
      "Epoch 208/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3550 - accuracy: 0.8637 - val_loss: 0.4279 - val_accuracy: 0.8160\n",
      "Epoch 209/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8637 - val_loss: 0.4266 - val_accuracy: 0.8165\n",
      "Epoch 210/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8647 - val_loss: 0.4263 - val_accuracy: 0.8145\n",
      "Epoch 211/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.8648 - val_loss: 0.4262 - val_accuracy: 0.8140\n",
      "Epoch 212/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8642 - val_loss: 0.4260 - val_accuracy: 0.8140\n",
      "Epoch 213/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8663 - val_loss: 0.4274 - val_accuracy: 0.8165\n",
      "Epoch 214/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8650 - val_loss: 0.4258 - val_accuracy: 0.8140\n",
      "Epoch 215/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8655 - val_loss: 0.4259 - val_accuracy: 0.8175\n",
      "Epoch 216/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3523 - accuracy: 0.8657 - val_loss: 0.4259 - val_accuracy: 0.8165\n",
      "Epoch 217/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8645 - val_loss: 0.4255 - val_accuracy: 0.8170\n",
      "Epoch 218/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8651 - val_loss: 0.4253 - val_accuracy: 0.8155\n",
      "Epoch 219/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8654 - val_loss: 0.4263 - val_accuracy: 0.8145\n",
      "Epoch 220/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8662 - val_loss: 0.4249 - val_accuracy: 0.8145\n",
      "Epoch 221/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3507 - accuracy: 0.8650 - val_loss: 0.4249 - val_accuracy: 0.8145\n",
      "Epoch 222/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8652 - val_loss: 0.4254 - val_accuracy: 0.8165\n",
      "Epoch 223/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8665 - val_loss: 0.4252 - val_accuracy: 0.8165\n",
      "Epoch 224/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8651 - val_loss: 0.4245 - val_accuracy: 0.8150\n",
      "Epoch 225/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8666 - val_loss: 0.4243 - val_accuracy: 0.8150\n",
      "Epoch 226/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3491 - accuracy: 0.8665 - val_loss: 0.4249 - val_accuracy: 0.8160\n",
      "Epoch 227/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3488 - accuracy: 0.8660 - val_loss: 0.4242 - val_accuracy: 0.8175\n",
      "Epoch 228/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8663 - val_loss: 0.4241 - val_accuracy: 0.8180\n",
      "Epoch 229/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8669 - val_loss: 0.4240 - val_accuracy: 0.8180\n",
      "Epoch 230/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.8672 - val_loss: 0.4248 - val_accuracy: 0.8140\n",
      "Epoch 231/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8675 - val_loss: 0.4239 - val_accuracy: 0.8185\n",
      "Epoch 232/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8676 - val_loss: 0.4237 - val_accuracy: 0.8180\n",
      "Epoch 233/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8664 - val_loss: 0.4234 - val_accuracy: 0.8155\n",
      "Epoch 234/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8669 - val_loss: 0.4232 - val_accuracy: 0.8165\n",
      "Epoch 235/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8676 - val_loss: 0.4231 - val_accuracy: 0.8155\n",
      "Epoch 236/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8685 - val_loss: 0.4230 - val_accuracy: 0.8155\n",
      "Epoch 237/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8681 - val_loss: 0.4229 - val_accuracy: 0.8165\n",
      "Epoch 238/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8678 - val_loss: 0.4227 - val_accuracy: 0.8165\n",
      "Epoch 239/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8682 - val_loss: 0.4234 - val_accuracy: 0.8180\n",
      "Epoch 240/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8685 - val_loss: 0.4225 - val_accuracy: 0.8175\n",
      "Epoch 241/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8682 - val_loss: 0.4230 - val_accuracy: 0.8189\n",
      "Epoch 242/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.8678 - val_loss: 0.4225 - val_accuracy: 0.8175\n",
      "Epoch 243/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8699 - val_loss: 0.4224 - val_accuracy: 0.8175\n",
      "Epoch 244/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8694 - val_loss: 0.4223 - val_accuracy: 0.8175\n",
      "Epoch 245/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8688 - val_loss: 0.4221 - val_accuracy: 0.8175\n",
      "Epoch 246/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8700 - val_loss: 0.4223 - val_accuracy: 0.8170\n",
      "Epoch 247/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3429 - accuracy: 0.8690 - val_loss: 0.4221 - val_accuracy: 0.8170\n",
      "Epoch 248/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3427 - accuracy: 0.8704 - val_loss: 0.4219 - val_accuracy: 0.8180\n",
      "Epoch 249/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8691 - val_loss: 0.4234 - val_accuracy: 0.8140\n",
      "Epoch 250/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3421 - accuracy: 0.8700 - val_loss: 0.4225 - val_accuracy: 0.8165\n",
      "Epoch 251/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8689 - val_loss: 0.4214 - val_accuracy: 0.8160\n",
      "Epoch 252/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8701 - val_loss: 0.4224 - val_accuracy: 0.8180\n",
      "Epoch 253/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8699 - val_loss: 0.4212 - val_accuracy: 0.8170\n",
      "Epoch 254/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8698 - val_loss: 0.4211 - val_accuracy: 0.8170\n",
      "Epoch 255/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8708 - val_loss: 0.4212 - val_accuracy: 0.8185\n",
      "Epoch 256/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8709 - val_loss: 0.4211 - val_accuracy: 0.8175\n",
      "Epoch 257/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3402 - accuracy: 0.8704 - val_loss: 0.4214 - val_accuracy: 0.8175\n",
      "Epoch 258/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8711 - val_loss: 0.4208 - val_accuracy: 0.8175\n",
      "Epoch 259/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8711 - val_loss: 0.4221 - val_accuracy: 0.8160\n",
      "Epoch 260/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8703 - val_loss: 0.4206 - val_accuracy: 0.8199\n",
      "Epoch 261/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8712 - val_loss: 0.4207 - val_accuracy: 0.8180\n",
      "Epoch 262/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8716 - val_loss: 0.4206 - val_accuracy: 0.8180\n",
      "Epoch 263/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8707 - val_loss: 0.4207 - val_accuracy: 0.8175\n",
      "Epoch 264/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8715 - val_loss: 0.4214 - val_accuracy: 0.8189\n",
      "Epoch 265/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.8717 - val_loss: 0.4204 - val_accuracy: 0.8189\n",
      "Epoch 266/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8712 - val_loss: 0.4200 - val_accuracy: 0.8165\n",
      "Epoch 267/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8705 - val_loss: 0.4203 - val_accuracy: 0.8175\n",
      "Epoch 268/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8725 - val_loss: 0.4199 - val_accuracy: 0.8180\n",
      "Epoch 269/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8716 - val_loss: 0.4200 - val_accuracy: 0.8194\n",
      "Epoch 270/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8716 - val_loss: 0.4210 - val_accuracy: 0.8180\n",
      "Epoch 271/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8719 - val_loss: 0.4197 - val_accuracy: 0.8204\n",
      "Epoch 272/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3365 - accuracy: 0.8727 - val_loss: 0.4203 - val_accuracy: 0.8189\n",
      "Epoch 273/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8726 - val_loss: 0.4206 - val_accuracy: 0.8189\n",
      "Epoch 274/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8726 - val_loss: 0.4200 - val_accuracy: 0.8189\n",
      "Epoch 275/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8725 - val_loss: 0.4196 - val_accuracy: 0.8185\n",
      "Epoch 276/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8724 - val_loss: 0.4194 - val_accuracy: 0.8199\n",
      "Epoch 277/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8727 - val_loss: 0.4192 - val_accuracy: 0.8199\n",
      "Epoch 278/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8731 - val_loss: 0.4192 - val_accuracy: 0.8199\n",
      "Epoch 279/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8721 - val_loss: 0.4198 - val_accuracy: 0.8185\n",
      "Epoch 280/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8726 - val_loss: 0.4190 - val_accuracy: 0.8189\n",
      "Epoch 281/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8726 - val_loss: 0.4193 - val_accuracy: 0.8189\n",
      "Epoch 282/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8740 - val_loss: 0.4193 - val_accuracy: 0.8189\n",
      "Epoch 283/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8740 - val_loss: 0.4204 - val_accuracy: 0.8165\n",
      "Epoch 284/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8739 - val_loss: 0.4187 - val_accuracy: 0.8175\n",
      "Epoch 285/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8729 - val_loss: 0.4187 - val_accuracy: 0.8185\n",
      "Epoch 286/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8729 - val_loss: 0.4200 - val_accuracy: 0.8175\n",
      "Epoch 287/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8732 - val_loss: 0.4199 - val_accuracy: 0.8170\n",
      "Epoch 288/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3326 - accuracy: 0.8744 - val_loss: 0.4184 - val_accuracy: 0.8180\n",
      "Epoch 289/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8729 - val_loss: 0.4188 - val_accuracy: 0.8204\n",
      "Epoch 290/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8745 - val_loss: 0.4191 - val_accuracy: 0.8194\n",
      "Epoch 291/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8741 - val_loss: 0.4201 - val_accuracy: 0.8165\n",
      "Epoch 292/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8750 - val_loss: 0.4181 - val_accuracy: 0.8189\n",
      "Epoch 293/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8749 - val_loss: 0.4184 - val_accuracy: 0.8209\n",
      "Epoch 294/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8745 - val_loss: 0.4180 - val_accuracy: 0.8180\n",
      "Epoch 295/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8753 - val_loss: 0.4179 - val_accuracy: 0.8189\n",
      "Epoch 296/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8739 - val_loss: 0.4182 - val_accuracy: 0.8209\n",
      "Epoch 297/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8740 - val_loss: 0.4179 - val_accuracy: 0.8180\n",
      "Epoch 298/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8748 - val_loss: 0.4178 - val_accuracy: 0.8180\n",
      "Epoch 299/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8754 - val_loss: 0.4179 - val_accuracy: 0.8219\n",
      "Epoch 300/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8753 - val_loss: 0.4191 - val_accuracy: 0.8175\n",
      "Epoch 301/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8750 - val_loss: 0.4185 - val_accuracy: 0.8199\n",
      "Epoch 302/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8760 - val_loss: 0.4184 - val_accuracy: 0.8199\n",
      "Epoch 303/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8748 - val_loss: 0.4177 - val_accuracy: 0.8214\n",
      "Epoch 304/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8753 - val_loss: 0.4174 - val_accuracy: 0.8189\n",
      "Epoch 305/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3289 - accuracy: 0.8753 - val_loss: 0.4178 - val_accuracy: 0.8214\n",
      "Epoch 306/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3287 - accuracy: 0.8752 - val_loss: 0.4173 - val_accuracy: 0.8189\n",
      "Epoch 307/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3285 - accuracy: 0.8748 - val_loss: 0.4179 - val_accuracy: 0.8209\n",
      "Epoch 308/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8764 - val_loss: 0.4177 - val_accuracy: 0.8214\n",
      "Epoch 309/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8758 - val_loss: 0.4173 - val_accuracy: 0.8214\n",
      "Epoch 310/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8769 - val_loss: 0.4171 - val_accuracy: 0.8204\n",
      "Epoch 311/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8761 - val_loss: 0.4182 - val_accuracy: 0.8189\n",
      "Epoch 312/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8763 - val_loss: 0.4181 - val_accuracy: 0.8189\n",
      "Epoch 313/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8758 - val_loss: 0.4171 - val_accuracy: 0.8214\n",
      "Epoch 314/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8756 - val_loss: 0.4169 - val_accuracy: 0.8209\n",
      "Epoch 315/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8752 - val_loss: 0.4181 - val_accuracy: 0.8180\n",
      "Epoch 316/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3267 - accuracy: 0.8763 - val_loss: 0.4168 - val_accuracy: 0.8209\n",
      "Epoch 317/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3265 - accuracy: 0.8769 - val_loss: 0.4167 - val_accuracy: 0.8199\n",
      "Epoch 318/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3262 - accuracy: 0.8764 - val_loss: 0.4179 - val_accuracy: 0.8180\n",
      "Epoch 319/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.3262 - accuracy: 0.8776 - val_loss: 0.4169 - val_accuracy: 0.8224\n",
      "Epoch 320/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3259 - accuracy: 0.8780 - val_loss: 0.4167 - val_accuracy: 0.8214\n",
      "Epoch 321/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8774 - val_loss: 0.4170 - val_accuracy: 0.8214\n",
      "Epoch 322/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3255 - accuracy: 0.8773 - val_loss: 0.4167 - val_accuracy: 0.8219\n",
      "Epoch 323/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3253 - accuracy: 0.8772 - val_loss: 0.4163 - val_accuracy: 0.8209\n",
      "Epoch 324/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.3252 - accuracy: 0.8771 - val_loss: 0.4166 - val_accuracy: 0.8219\n",
      "Epoch 325/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3249 - accuracy: 0.8771 - val_loss: 0.4163 - val_accuracy: 0.8214\n",
      "Epoch 326/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8777 - val_loss: 0.4164 - val_accuracy: 0.8224\n",
      "Epoch 327/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8774 - val_loss: 0.4162 - val_accuracy: 0.8224\n",
      "Epoch 328/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.8777 - val_loss: 0.4161 - val_accuracy: 0.8239\n",
      "Epoch 329/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3240 - accuracy: 0.8778 - val_loss: 0.4175 - val_accuracy: 0.8180\n",
      "Epoch 330/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3240 - accuracy: 0.8787 - val_loss: 0.4165 - val_accuracy: 0.8219\n",
      "Epoch 331/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8787 - val_loss: 0.4160 - val_accuracy: 0.8239\n",
      "Epoch 332/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8780 - val_loss: 0.4162 - val_accuracy: 0.8219\n",
      "Epoch 333/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8774 - val_loss: 0.4160 - val_accuracy: 0.8219\n",
      "Epoch 334/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8785 - val_loss: 0.4159 - val_accuracy: 0.8224\n",
      "Epoch 335/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.8785 - val_loss: 0.4168 - val_accuracy: 0.8189\n",
      "Epoch 336/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3228 - accuracy: 0.8774 - val_loss: 0.4162 - val_accuracy: 0.8214\n",
      "Epoch 337/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3226 - accuracy: 0.8776 - val_loss: 0.4160 - val_accuracy: 0.8219\n",
      "Epoch 338/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8780 - val_loss: 0.4166 - val_accuracy: 0.8199\n",
      "Epoch 339/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3223 - accuracy: 0.8781 - val_loss: 0.4166 - val_accuracy: 0.8199\n",
      "Epoch 340/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3220 - accuracy: 0.8786 - val_loss: 0.4156 - val_accuracy: 0.8239\n",
      "Epoch 341/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3219 - accuracy: 0.8787 - val_loss: 0.4159 - val_accuracy: 0.8209\n",
      "Epoch 342/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3216 - accuracy: 0.8792 - val_loss: 0.4171 - val_accuracy: 0.8155\n",
      "Epoch 343/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3215 - accuracy: 0.8793 - val_loss: 0.4155 - val_accuracy: 0.8244\n",
      "Epoch 344/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3214 - accuracy: 0.8797 - val_loss: 0.4160 - val_accuracy: 0.8219\n",
      "Epoch 345/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8785 - val_loss: 0.4162 - val_accuracy: 0.8204\n",
      "Epoch 346/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3211 - accuracy: 0.8784 - val_loss: 0.4154 - val_accuracy: 0.8239\n",
      "Epoch 347/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3209 - accuracy: 0.8782 - val_loss: 0.4154 - val_accuracy: 0.8239\n",
      "Epoch 348/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3207 - accuracy: 0.8795 - val_loss: 0.4153 - val_accuracy: 0.8239\n",
      "Epoch 349/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3205 - accuracy: 0.8785 - val_loss: 0.4158 - val_accuracy: 0.8214\n",
      "Epoch 350/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.8793 - val_loss: 0.4166 - val_accuracy: 0.8165\n",
      "Epoch 351/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8793 - val_loss: 0.4152 - val_accuracy: 0.8254\n",
      "Epoch 352/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8796 - val_loss: 0.4152 - val_accuracy: 0.8239\n",
      "Epoch 353/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8796 - val_loss: 0.4155 - val_accuracy: 0.8214\n",
      "Epoch 354/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8787 - val_loss: 0.4155 - val_accuracy: 0.8219\n",
      "Epoch 355/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8795 - val_loss: 0.4155 - val_accuracy: 0.8209\n",
      "Epoch 356/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.8808 - val_loss: 0.4152 - val_accuracy: 0.8224\n",
      "Epoch 357/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8795 - val_loss: 0.4152 - val_accuracy: 0.8219\n",
      "Epoch 358/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8793 - val_loss: 0.4155 - val_accuracy: 0.8214\n",
      "Epoch 359/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8798 - val_loss: 0.4163 - val_accuracy: 0.8160\n",
      "Epoch 360/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3187 - accuracy: 0.8802 - val_loss: 0.4150 - val_accuracy: 0.8229\n",
      "Epoch 361/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8800 - val_loss: 0.4151 - val_accuracy: 0.8219\n",
      "Epoch 362/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3183 - accuracy: 0.8801 - val_loss: 0.4151 - val_accuracy: 0.8219\n",
      "Epoch 363/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.8806 - val_loss: 0.4152 - val_accuracy: 0.8204\n",
      "Epoch 364/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8810 - val_loss: 0.4158 - val_accuracy: 0.8175\n",
      "Epoch 365/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8799 - val_loss: 0.4155 - val_accuracy: 0.8189\n",
      "Epoch 366/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3176 - accuracy: 0.8798 - val_loss: 0.4148 - val_accuracy: 0.8229\n",
      "Epoch 367/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8804 - val_loss: 0.4146 - val_accuracy: 0.8254\n",
      "Epoch 368/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8809 - val_loss: 0.4151 - val_accuracy: 0.8214\n",
      "Epoch 369/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.8808 - val_loss: 0.4146 - val_accuracy: 0.8259\n",
      "Epoch 370/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8799 - val_loss: 0.4150 - val_accuracy: 0.8204\n",
      "Epoch 371/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3167 - accuracy: 0.8801 - val_loss: 0.4153 - val_accuracy: 0.8189\n",
      "Epoch 372/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8804 - val_loss: 0.4145 - val_accuracy: 0.8259\n",
      "Epoch 373/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8813 - val_loss: 0.4145 - val_accuracy: 0.8239\n",
      "Epoch 374/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8812 - val_loss: 0.4144 - val_accuracy: 0.8263\n",
      "Epoch 375/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.8803 - val_loss: 0.4146 - val_accuracy: 0.8224\n",
      "Epoch 376/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3160 - accuracy: 0.8812 - val_loss: 0.4148 - val_accuracy: 0.8209\n",
      "Epoch 377/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3158 - accuracy: 0.8814 - val_loss: 0.4148 - val_accuracy: 0.8209\n",
      "Epoch 378/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3157 - accuracy: 0.8805 - val_loss: 0.4150 - val_accuracy: 0.8199\n",
      "Epoch 379/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.8805 - val_loss: 0.4150 - val_accuracy: 0.8199\n",
      "Epoch 380/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8809 - val_loss: 0.4145 - val_accuracy: 0.8219\n",
      "Epoch 381/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3151 - accuracy: 0.8808 - val_loss: 0.4144 - val_accuracy: 0.8219\n",
      "Epoch 382/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.8806 - val_loss: 0.4151 - val_accuracy: 0.8194\n",
      "Epoch 383/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8817 - val_loss: 0.4141 - val_accuracy: 0.8263\n",
      "Epoch 384/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.8812 - val_loss: 0.4143 - val_accuracy: 0.8229\n",
      "Epoch 385/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3146 - accuracy: 0.8817 - val_loss: 0.4147 - val_accuracy: 0.8194\n",
      "Epoch 386/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8811 - val_loss: 0.4145 - val_accuracy: 0.8209\n",
      "Epoch 387/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8815 - val_loss: 0.4148 - val_accuracy: 0.8185\n",
      "Epoch 388/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8821 - val_loss: 0.4142 - val_accuracy: 0.8234\n",
      "Epoch 389/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8814 - val_loss: 0.4154 - val_accuracy: 0.8180\n",
      "Epoch 390/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8826 - val_loss: 0.4150 - val_accuracy: 0.8180\n",
      "Epoch 391/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3136 - accuracy: 0.8822 - val_loss: 0.4140 - val_accuracy: 0.8229\n",
      "Epoch 392/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3135 - accuracy: 0.8812 - val_loss: 0.4162 - val_accuracy: 0.8160\n",
      "Epoch 393/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3133 - accuracy: 0.8819 - val_loss: 0.4140 - val_accuracy: 0.8229\n",
      "Epoch 394/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.8820 - val_loss: 0.4141 - val_accuracy: 0.8234\n",
      "Epoch 395/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8818 - val_loss: 0.4143 - val_accuracy: 0.8199\n",
      "Epoch 396/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8830 - val_loss: 0.4141 - val_accuracy: 0.8214\n",
      "Epoch 397/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3128 - accuracy: 0.8825 - val_loss: 0.4143 - val_accuracy: 0.8199\n",
      "Epoch 398/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.8821 - val_loss: 0.4138 - val_accuracy: 0.8244\n",
      "Epoch 399/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.8819 - val_loss: 0.4142 - val_accuracy: 0.8199\n",
      "Epoch 400/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8822 - val_loss: 0.4147 - val_accuracy: 0.8194\n",
      "Epoch 401/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8827 - val_loss: 0.4138 - val_accuracy: 0.8244\n",
      "Epoch 402/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8813 - val_loss: 0.4137 - val_accuracy: 0.8249\n",
      "Epoch 403/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3119 - accuracy: 0.8830 - val_loss: 0.4139 - val_accuracy: 0.8219\n",
      "Epoch 404/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8818 - val_loss: 0.4141 - val_accuracy: 0.8194\n",
      "Epoch 405/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3116 - accuracy: 0.8824 - val_loss: 0.4136 - val_accuracy: 0.8263\n",
      "Epoch 406/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8817 - val_loss: 0.4140 - val_accuracy: 0.8209\n",
      "Epoch 407/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3113 - accuracy: 0.8822 - val_loss: 0.4140 - val_accuracy: 0.8209\n",
      "Epoch 408/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8832 - val_loss: 0.4136 - val_accuracy: 0.8263\n",
      "Epoch 409/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8829 - val_loss: 0.4137 - val_accuracy: 0.8234\n",
      "Epoch 410/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8826 - val_loss: 0.4136 - val_accuracy: 0.8244\n",
      "Epoch 411/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8822 - val_loss: 0.4140 - val_accuracy: 0.8199\n",
      "Epoch 412/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8823 - val_loss: 0.4142 - val_accuracy: 0.8189\n",
      "Epoch 413/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8838 - val_loss: 0.4135 - val_accuracy: 0.8263\n",
      "Epoch 414/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8826 - val_loss: 0.4135 - val_accuracy: 0.8249\n",
      "Epoch 415/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.8841 - val_loss: 0.4137 - val_accuracy: 0.8214\n",
      "Epoch 416/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3099 - accuracy: 0.8835 - val_loss: 0.4134 - val_accuracy: 0.8259\n",
      "Epoch 417/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3098 - accuracy: 0.8833 - val_loss: 0.4143 - val_accuracy: 0.8180\n",
      "Epoch 418/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.8827 - val_loss: 0.4136 - val_accuracy: 0.8214\n",
      "Epoch 419/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8828 - val_loss: 0.4145 - val_accuracy: 0.8199\n",
      "Epoch 420/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8835 - val_loss: 0.4135 - val_accuracy: 0.8229\n",
      "Epoch 421/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3093 - accuracy: 0.8830 - val_loss: 0.4133 - val_accuracy: 0.8249\n",
      "Epoch 422/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.8838 - val_loss: 0.4135 - val_accuracy: 0.8229\n",
      "Epoch 423/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3091 - accuracy: 0.8838 - val_loss: 0.4133 - val_accuracy: 0.8249\n",
      "Epoch 424/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.8832 - val_loss: 0.4134 - val_accuracy: 0.8224\n",
      "Epoch 425/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8836 - val_loss: 0.4133 - val_accuracy: 0.8249\n",
      "Epoch 426/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.3087 - accuracy: 0.8828 - val_loss: 0.4133 - val_accuracy: 0.8249\n",
      "Epoch 427/1000\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3085 - accuracy: 0.8828 - val_loss: 0.4141 - val_accuracy: 0.8180\n",
      "Epoch 428/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.3084 - accuracy: 0.8843 - val_loss: 0.4141 - val_accuracy: 0.8180\n",
      "Epoch 429/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.3082 - accuracy: 0.8845 - val_loss: 0.4136 - val_accuracy: 0.8204\n",
      "Epoch 430/1000\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3081 - accuracy: 0.8846 - val_loss: 0.4134 - val_accuracy: 0.8209\n",
      "Epoch 431/1000\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3080 - accuracy: 0.8835 - val_loss: 0.4135 - val_accuracy: 0.8204\n",
      "Epoch 432/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.3078 - accuracy: 0.8838 - val_loss: 0.4137 - val_accuracy: 0.8194\n",
      "Epoch 433/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3077 - accuracy: 0.8839 - val_loss: 0.4132 - val_accuracy: 0.8234\n",
      "Epoch 434/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8839 - val_loss: 0.4136 - val_accuracy: 0.8194\n",
      "Epoch 435/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3074 - accuracy: 0.8835 - val_loss: 0.4132 - val_accuracy: 0.8263\n",
      "Epoch 436/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8843 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 437/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8840 - val_loss: 0.4133 - val_accuracy: 0.8209\n",
      "Epoch 438/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3071 - accuracy: 0.8836 - val_loss: 0.4136 - val_accuracy: 0.8189\n",
      "Epoch 439/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8837 - val_loss: 0.4149 - val_accuracy: 0.8185\n",
      "Epoch 440/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8850 - val_loss: 0.4130 - val_accuracy: 0.8249\n",
      "Epoch 441/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3066 - accuracy: 0.8838 - val_loss: 0.4133 - val_accuracy: 0.8214\n",
      "Epoch 442/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8849 - val_loss: 0.4147 - val_accuracy: 0.8194\n",
      "Epoch 443/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8850 - val_loss: 0.4130 - val_accuracy: 0.8234\n",
      "Epoch 444/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8856 - val_loss: 0.4139 - val_accuracy: 0.8189\n",
      "Epoch 445/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.8850 - val_loss: 0.4130 - val_accuracy: 0.8229\n",
      "Epoch 446/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3060 - accuracy: 0.8852 - val_loss: 0.4144 - val_accuracy: 0.8194\n",
      "Epoch 447/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3058 - accuracy: 0.8850 - val_loss: 0.4147 - val_accuracy: 0.8199\n",
      "Epoch 448/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8853 - val_loss: 0.4136 - val_accuracy: 0.8194\n",
      "Epoch 449/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3056 - accuracy: 0.8849 - val_loss: 0.4138 - val_accuracy: 0.8189\n",
      "Epoch 450/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.3055 - accuracy: 0.8845 - val_loss: 0.4130 - val_accuracy: 0.8219\n",
      "Epoch 451/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.3053 - accuracy: 0.8851 - val_loss: 0.4135 - val_accuracy: 0.8189\n",
      "Epoch 452/1000\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3052 - accuracy: 0.8856 - val_loss: 0.4131 - val_accuracy: 0.8209\n",
      "Epoch 453/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.3051 - accuracy: 0.8858 - val_loss: 0.4138 - val_accuracy: 0.8194\n",
      "Epoch 454/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3050 - accuracy: 0.8861 - val_loss: 0.4139 - val_accuracy: 0.8194\n",
      "Epoch 455/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8859 - val_loss: 0.4129 - val_accuracy: 0.8234\n",
      "Epoch 456/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8854 - val_loss: 0.4133 - val_accuracy: 0.8189\n",
      "Epoch 457/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8856 - val_loss: 0.4134 - val_accuracy: 0.8185\n",
      "Epoch 458/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8851 - val_loss: 0.4141 - val_accuracy: 0.8185\n",
      "Epoch 459/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3043 - accuracy: 0.8848 - val_loss: 0.4130 - val_accuracy: 0.8209\n",
      "Epoch 460/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8861 - val_loss: 0.4132 - val_accuracy: 0.8199\n",
      "Epoch 461/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.8849 - val_loss: 0.4130 - val_accuracy: 0.8199\n",
      "Epoch 462/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.8866 - val_loss: 0.4134 - val_accuracy: 0.8189\n",
      "Epoch 463/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8857 - val_loss: 0.4133 - val_accuracy: 0.8185\n",
      "Epoch 464/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8851 - val_loss: 0.4128 - val_accuracy: 0.8214\n",
      "Epoch 465/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8858 - val_loss: 0.4135 - val_accuracy: 0.8185\n",
      "Epoch 466/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3035 - accuracy: 0.8857 - val_loss: 0.4129 - val_accuracy: 0.8263\n",
      "Epoch 467/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8859 - val_loss: 0.4128 - val_accuracy: 0.8263\n",
      "Epoch 468/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8861 - val_loss: 0.4132 - val_accuracy: 0.8194\n",
      "Epoch 469/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3031 - accuracy: 0.8856 - val_loss: 0.4130 - val_accuracy: 0.8199\n",
      "Epoch 470/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8864 - val_loss: 0.4130 - val_accuracy: 0.8204\n",
      "Epoch 471/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8864 - val_loss: 0.4131 - val_accuracy: 0.8189\n",
      "Epoch 472/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.8857 - val_loss: 0.4138 - val_accuracy: 0.8199\n",
      "Epoch 473/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.8865 - val_loss: 0.4128 - val_accuracy: 0.8209\n",
      "Epoch 474/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8861 - val_loss: 0.4128 - val_accuracy: 0.8209\n",
      "Epoch 475/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.8867 - val_loss: 0.4130 - val_accuracy: 0.8194\n",
      "Epoch 476/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8863 - val_loss: 0.4128 - val_accuracy: 0.8209\n",
      "Epoch 477/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3022 - accuracy: 0.8866 - val_loss: 0.4130 - val_accuracy: 0.8194\n",
      "Epoch 478/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3021 - accuracy: 0.8864 - val_loss: 0.4135 - val_accuracy: 0.8189\n",
      "Epoch 479/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.8857 - val_loss: 0.4131 - val_accuracy: 0.8189\n",
      "Epoch 480/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.8861 - val_loss: 0.4144 - val_accuracy: 0.8199\n",
      "Epoch 481/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.8864 - val_loss: 0.4130 - val_accuracy: 0.8194\n",
      "Epoch 482/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3016 - accuracy: 0.8862 - val_loss: 0.4128 - val_accuracy: 0.8199\n",
      "Epoch 483/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8867 - val_loss: 0.4135 - val_accuracy: 0.8189\n",
      "Epoch 484/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8871 - val_loss: 0.4131 - val_accuracy: 0.8189\n",
      "Epoch 485/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.8866 - val_loss: 0.4132 - val_accuracy: 0.8189\n",
      "Epoch 486/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8861 - val_loss: 0.4132 - val_accuracy: 0.8189\n",
      "Epoch 487/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.8869 - val_loss: 0.4127 - val_accuracy: 0.8209\n",
      "Epoch 488/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3010 - accuracy: 0.8871 - val_loss: 0.4130 - val_accuracy: 0.8189\n",
      "Epoch 489/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8858 - val_loss: 0.4129 - val_accuracy: 0.8194\n",
      "Epoch 490/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8870 - val_loss: 0.4126 - val_accuracy: 0.8219\n",
      "Epoch 491/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.8874 - val_loss: 0.4136 - val_accuracy: 0.8189\n",
      "Epoch 492/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.8862 - val_loss: 0.4131 - val_accuracy: 0.8189\n",
      "Epoch 493/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.3004 - accuracy: 0.8875 - val_loss: 0.4132 - val_accuracy: 0.8194\n",
      "Epoch 494/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.3002 - accuracy: 0.8871 - val_loss: 0.4131 - val_accuracy: 0.8189\n",
      "Epoch 495/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.8875 - val_loss: 0.4128 - val_accuracy: 0.8199\n",
      "Epoch 496/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.8874 - val_loss: 0.4126 - val_accuracy: 0.8234\n",
      "Epoch 497/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.8873 - val_loss: 0.4127 - val_accuracy: 0.8209\n",
      "Epoch 498/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.8879 - val_loss: 0.4127 - val_accuracy: 0.8209\n",
      "Epoch 499/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.8873 - val_loss: 0.4133 - val_accuracy: 0.8189\n",
      "Epoch 500/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8874 - val_loss: 0.4126 - val_accuracy: 0.8224\n",
      "Epoch 501/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8882 - val_loss: 0.4127 - val_accuracy: 0.8209\n",
      "Epoch 502/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8870 - val_loss: 0.4135 - val_accuracy: 0.8185\n",
      "Epoch 503/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.8874 - val_loss: 0.4127 - val_accuracy: 0.8214\n",
      "Epoch 504/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.8875 - val_loss: 0.4137 - val_accuracy: 0.8199\n",
      "Epoch 505/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.8877 - val_loss: 0.4127 - val_accuracy: 0.8214\n",
      "Epoch 506/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2990 - accuracy: 0.8878 - val_loss: 0.4138 - val_accuracy: 0.8194\n",
      "Epoch 507/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.8879 - val_loss: 0.4137 - val_accuracy: 0.8194\n",
      "Epoch 508/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8878 - val_loss: 0.4127 - val_accuracy: 0.8204\n",
      "Epoch 509/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8874 - val_loss: 0.4126 - val_accuracy: 0.8224\n",
      "Epoch 510/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.8874 - val_loss: 0.4132 - val_accuracy: 0.8199\n",
      "Epoch 511/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.8872 - val_loss: 0.4130 - val_accuracy: 0.8199\n",
      "Epoch 512/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.8883 - val_loss: 0.4128 - val_accuracy: 0.8189\n",
      "Epoch 513/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.8888 - val_loss: 0.4126 - val_accuracy: 0.8224\n",
      "Epoch 514/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8880 - val_loss: 0.4128 - val_accuracy: 0.8194\n",
      "Epoch 515/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.8884 - val_loss: 0.4130 - val_accuracy: 0.8189\n",
      "Epoch 516/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8882 - val_loss: 0.4132 - val_accuracy: 0.8204\n",
      "Epoch 517/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2977 - accuracy: 0.8879 - val_loss: 0.4125 - val_accuracy: 0.8224\n",
      "Epoch 518/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.8890 - val_loss: 0.4135 - val_accuracy: 0.8189\n",
      "Epoch 519/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.8892 - val_loss: 0.4127 - val_accuracy: 0.8209\n",
      "Epoch 520/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.8885 - val_loss: 0.4126 - val_accuracy: 0.8229\n",
      "Epoch 521/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2973 - accuracy: 0.8892 - val_loss: 0.4127 - val_accuracy: 0.8204\n",
      "Epoch 522/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2973 - accuracy: 0.8887 - val_loss: 0.4126 - val_accuracy: 0.8229\n",
      "Epoch 523/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.8884 - val_loss: 0.4126 - val_accuracy: 0.8229\n",
      "Epoch 524/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8881 - val_loss: 0.4134 - val_accuracy: 0.8189\n",
      "Epoch 525/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2969 - accuracy: 0.8895 - val_loss: 0.4130 - val_accuracy: 0.8194\n",
      "Epoch 526/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2969 - accuracy: 0.8890 - val_loss: 0.4126 - val_accuracy: 0.8224\n",
      "Epoch 527/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8890 - val_loss: 0.4125 - val_accuracy: 0.8229\n",
      "Epoch 528/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2966 - accuracy: 0.8890 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 529/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2965 - accuracy: 0.8888 - val_loss: 0.4125 - val_accuracy: 0.8224\n",
      "Epoch 530/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.8886 - val_loss: 0.4126 - val_accuracy: 0.8229\n",
      "Epoch 531/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2964 - accuracy: 0.8884 - val_loss: 0.4130 - val_accuracy: 0.8199\n",
      "Epoch 532/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8885 - val_loss: 0.4129 - val_accuracy: 0.8194\n",
      "Epoch 533/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8891 - val_loss: 0.4132 - val_accuracy: 0.8194\n",
      "Epoch 534/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8892 - val_loss: 0.4128 - val_accuracy: 0.8194\n",
      "Epoch 535/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.8893 - val_loss: 0.4126 - val_accuracy: 0.8229\n",
      "Epoch 536/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8891 - val_loss: 0.4133 - val_accuracy: 0.8199\n",
      "Epoch 537/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.8889 - val_loss: 0.4138 - val_accuracy: 0.8199\n",
      "Epoch 538/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8899 - val_loss: 0.4130 - val_accuracy: 0.8199\n",
      "Epoch 539/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2956 - accuracy: 0.8895 - val_loss: 0.4132 - val_accuracy: 0.8199\n",
      "Epoch 540/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.8882 - val_loss: 0.4135 - val_accuracy: 0.8194\n",
      "Epoch 541/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8901 - val_loss: 0.4126 - val_accuracy: 0.8224\n",
      "Epoch 542/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8898 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 543/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8896 - val_loss: 0.4129 - val_accuracy: 0.8199\n",
      "Epoch 544/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8880 - val_loss: 0.4125 - val_accuracy: 0.8219\n",
      "Epoch 545/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8893 - val_loss: 0.4127 - val_accuracy: 0.8214\n",
      "Epoch 546/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8896 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 547/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.8895 - val_loss: 0.4132 - val_accuracy: 0.8199\n",
      "Epoch 548/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8901 - val_loss: 0.4136 - val_accuracy: 0.8199\n",
      "Epoch 549/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8903 - val_loss: 0.4129 - val_accuracy: 0.8199\n",
      "Epoch 550/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8896 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 551/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8896 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 552/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.8895 - val_loss: 0.4126 - val_accuracy: 0.8219\n",
      "Epoch 553/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2941 - accuracy: 0.8904 - val_loss: 0.4134 - val_accuracy: 0.8204\n",
      "Epoch 554/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2941 - accuracy: 0.8892 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 555/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2940 - accuracy: 0.8899 - val_loss: 0.4145 - val_accuracy: 0.8204\n",
      "Epoch 556/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.8897 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 557/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8906 - val_loss: 0.4130 - val_accuracy: 0.8194\n",
      "Epoch 558/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.8896 - val_loss: 0.4127 - val_accuracy: 0.8234\n",
      "Epoch 559/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8909 - val_loss: 0.4128 - val_accuracy: 0.8214\n",
      "Epoch 560/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8896 - val_loss: 0.4131 - val_accuracy: 0.8194\n",
      "Epoch 561/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2934 - accuracy: 0.8903 - val_loss: 0.4134 - val_accuracy: 0.8209\n",
      "Epoch 562/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8912 - val_loss: 0.4128 - val_accuracy: 0.8214\n",
      "Epoch 563/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2933 - accuracy: 0.8901 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 564/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2931 - accuracy: 0.8900 - val_loss: 0.4135 - val_accuracy: 0.8204\n",
      "Epoch 565/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2930 - accuracy: 0.8904 - val_loss: 0.4132 - val_accuracy: 0.8194\n",
      "Epoch 566/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2929 - accuracy: 0.8913 - val_loss: 0.4126 - val_accuracy: 0.8219\n",
      "Epoch 567/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.8901 - val_loss: 0.4127 - val_accuracy: 0.8224\n",
      "Epoch 568/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.8898 - val_loss: 0.4145 - val_accuracy: 0.8199\n",
      "Epoch 569/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.8903 - val_loss: 0.4127 - val_accuracy: 0.8229\n",
      "Epoch 570/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2925 - accuracy: 0.8909 - val_loss: 0.4139 - val_accuracy: 0.8199\n",
      "Epoch 571/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2925 - accuracy: 0.8900 - val_loss: 0.4127 - val_accuracy: 0.8224\n",
      "Epoch 572/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2924 - accuracy: 0.8916 - val_loss: 0.4127 - val_accuracy: 0.8229\n",
      "Epoch 573/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.8906 - val_loss: 0.4127 - val_accuracy: 0.8224\n",
      "Epoch 574/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8906 - val_loss: 0.4130 - val_accuracy: 0.8204\n",
      "Epoch 575/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.8908 - val_loss: 0.4134 - val_accuracy: 0.8214\n",
      "Epoch 576/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2920 - accuracy: 0.8903 - val_loss: 0.4127 - val_accuracy: 0.8224\n",
      "Epoch 577/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2919 - accuracy: 0.8920 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 578/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2918 - accuracy: 0.8915 - val_loss: 0.4128 - val_accuracy: 0.8229\n",
      "Epoch 579/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2917 - accuracy: 0.8901 - val_loss: 0.4137 - val_accuracy: 0.8199\n",
      "Epoch 580/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2916 - accuracy: 0.8906 - val_loss: 0.4134 - val_accuracy: 0.8214\n",
      "Epoch 581/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8916 - val_loss: 0.4133 - val_accuracy: 0.8209\n",
      "Epoch 582/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2915 - accuracy: 0.8909 - val_loss: 0.4129 - val_accuracy: 0.8229\n",
      "Epoch 583/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.8901 - val_loss: 0.4130 - val_accuracy: 0.8219\n",
      "Epoch 584/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8914 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 585/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2912 - accuracy: 0.8911 - val_loss: 0.4127 - val_accuracy: 0.8219\n",
      "Epoch 586/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.8917 - val_loss: 0.4129 - val_accuracy: 0.8229\n",
      "Epoch 587/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2909 - accuracy: 0.8919 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 588/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8916 - val_loss: 0.4131 - val_accuracy: 0.8214\n",
      "Epoch 589/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8909 - val_loss: 0.4131 - val_accuracy: 0.8214\n",
      "Epoch 590/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.8909 - val_loss: 0.4130 - val_accuracy: 0.8219\n",
      "Epoch 591/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.8914 - val_loss: 0.4134 - val_accuracy: 0.8209\n",
      "Epoch 592/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.8919 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 593/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.8919 - val_loss: 0.4128 - val_accuracy: 0.8229\n",
      "Epoch 594/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2904 - accuracy: 0.8920 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 595/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2903 - accuracy: 0.8917 - val_loss: 0.4128 - val_accuracy: 0.8219\n",
      "Epoch 596/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.8915 - val_loss: 0.4129 - val_accuracy: 0.8229\n",
      "Epoch 597/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8912 - val_loss: 0.4140 - val_accuracy: 0.8199\n",
      "Epoch 598/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.8922 - val_loss: 0.4134 - val_accuracy: 0.8214\n",
      "Epoch 599/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8917 - val_loss: 0.4130 - val_accuracy: 0.8234\n",
      "Epoch 600/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.8920 - val_loss: 0.4130 - val_accuracy: 0.8234\n",
      "Epoch 601/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.8925 - val_loss: 0.4130 - val_accuracy: 0.8234\n",
      "Epoch 602/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8917 - val_loss: 0.4129 - val_accuracy: 0.8224\n",
      "Epoch 603/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.8916 - val_loss: 0.4128 - val_accuracy: 0.8224\n",
      "Epoch 604/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8925 - val_loss: 0.4139 - val_accuracy: 0.8199\n",
      "Epoch 605/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.8919 - val_loss: 0.4139 - val_accuracy: 0.8194\n",
      "Epoch 606/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2893 - accuracy: 0.8918 - val_loss: 0.4130 - val_accuracy: 0.8229\n",
      "Epoch 607/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2893 - accuracy: 0.8921 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 608/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2892 - accuracy: 0.8916 - val_loss: 0.4130 - val_accuracy: 0.8224\n",
      "Epoch 609/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2891 - accuracy: 0.8927 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 610/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.8925 - val_loss: 0.4135 - val_accuracy: 0.8219\n",
      "Epoch 611/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8929 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 612/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8927 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 613/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8920 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 614/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8922 - val_loss: 0.4129 - val_accuracy: 0.8224\n",
      "Epoch 615/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.8928 - val_loss: 0.4144 - val_accuracy: 0.8204\n",
      "Epoch 616/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8923 - val_loss: 0.4135 - val_accuracy: 0.8224\n",
      "Epoch 617/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.8933 - val_loss: 0.4130 - val_accuracy: 0.8224\n",
      "Epoch 618/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.8928 - val_loss: 0.4130 - val_accuracy: 0.8224\n",
      "Epoch 619/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8924 - val_loss: 0.4131 - val_accuracy: 0.8224\n",
      "Epoch 620/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2882 - accuracy: 0.8923 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 621/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2881 - accuracy: 0.8924 - val_loss: 0.4137 - val_accuracy: 0.8219\n",
      "Epoch 622/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8927 - val_loss: 0.4139 - val_accuracy: 0.8204\n",
      "Epoch 623/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8931 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 624/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.8932 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 625/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.8927 - val_loss: 0.4131 - val_accuracy: 0.8224\n",
      "Epoch 626/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.8930 - val_loss: 0.4130 - val_accuracy: 0.8219\n",
      "Epoch 627/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.8928 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 628/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.8929 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 629/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.8928 - val_loss: 0.4130 - val_accuracy: 0.8219\n",
      "Epoch 630/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2873 - accuracy: 0.8925 - val_loss: 0.4144 - val_accuracy: 0.8204\n",
      "Epoch 631/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2873 - accuracy: 0.8932 - val_loss: 0.4131 - val_accuracy: 0.8224\n",
      "Epoch 632/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8935 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 633/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8935 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 634/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.8933 - val_loss: 0.4132 - val_accuracy: 0.8224\n",
      "Epoch 635/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.8932 - val_loss: 0.4131 - val_accuracy: 0.8224\n",
      "Epoch 636/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2868 - accuracy: 0.8936 - val_loss: 0.4136 - val_accuracy: 0.8234\n",
      "Epoch 637/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2868 - accuracy: 0.8941 - val_loss: 0.4134 - val_accuracy: 0.8229\n",
      "Epoch 638/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8933 - val_loss: 0.4137 - val_accuracy: 0.8229\n",
      "Epoch 639/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.8935 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 640/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.8937 - val_loss: 0.4132 - val_accuracy: 0.8219\n",
      "Epoch 641/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8930 - val_loss: 0.4132 - val_accuracy: 0.8219\n",
      "Epoch 642/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8930 - val_loss: 0.4134 - val_accuracy: 0.8229\n",
      "Epoch 643/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2863 - accuracy: 0.8941 - val_loss: 0.4132 - val_accuracy: 0.8214\n",
      "Epoch 644/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2862 - accuracy: 0.8938 - val_loss: 0.4136 - val_accuracy: 0.8239\n",
      "Epoch 645/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2862 - accuracy: 0.8941 - val_loss: 0.4138 - val_accuracy: 0.8229\n",
      "Epoch 646/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.8941 - val_loss: 0.4137 - val_accuracy: 0.8234\n",
      "Epoch 647/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8933 - val_loss: 0.4143 - val_accuracy: 0.8209\n",
      "Epoch 648/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.8940 - val_loss: 0.4137 - val_accuracy: 0.8234\n",
      "Epoch 649/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8937 - val_loss: 0.4135 - val_accuracy: 0.8224\n",
      "Epoch 650/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2856 - accuracy: 0.8945 - val_loss: 0.4133 - val_accuracy: 0.8229\n",
      "Epoch 651/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8941 - val_loss: 0.4133 - val_accuracy: 0.8219\n",
      "Epoch 652/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8928 - val_loss: 0.4134 - val_accuracy: 0.8224\n",
      "Epoch 653/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2854 - accuracy: 0.8937 - val_loss: 0.4142 - val_accuracy: 0.8229\n",
      "Epoch 654/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2854 - accuracy: 0.8938 - val_loss: 0.4133 - val_accuracy: 0.8219\n",
      "Epoch 655/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2854 - accuracy: 0.8938 - val_loss: 0.4136 - val_accuracy: 0.8229\n",
      "Epoch 656/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2852 - accuracy: 0.8933 - val_loss: 0.4134 - val_accuracy: 0.8224\n",
      "Epoch 657/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.8940 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 658/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2850 - accuracy: 0.8934 - val_loss: 0.4133 - val_accuracy: 0.8224\n",
      "Epoch 659/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8941 - val_loss: 0.4140 - val_accuracy: 0.8224\n",
      "Epoch 660/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.8953 - val_loss: 0.4145 - val_accuracy: 0.8224\n",
      "Epoch 661/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2849 - accuracy: 0.8942 - val_loss: 0.4148 - val_accuracy: 0.8224\n",
      "Epoch 662/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8940 - val_loss: 0.4136 - val_accuracy: 0.8229\n",
      "Epoch 663/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.8948 - val_loss: 0.4139 - val_accuracy: 0.8234\n",
      "Epoch 664/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.8938 - val_loss: 0.4140 - val_accuracy: 0.8234\n",
      "Epoch 665/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.8936 - val_loss: 0.4139 - val_accuracy: 0.8234\n",
      "Epoch 666/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2846 - accuracy: 0.8942 - val_loss: 0.4139 - val_accuracy: 0.8234\n",
      "Epoch 667/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.8940 - val_loss: 0.4142 - val_accuracy: 0.8229\n",
      "Epoch 668/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.8943 - val_loss: 0.4145 - val_accuracy: 0.8229\n",
      "Epoch 669/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2843 - accuracy: 0.8945 - val_loss: 0.4139 - val_accuracy: 0.8234\n",
      "Epoch 670/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8939 - val_loss: 0.4138 - val_accuracy: 0.8229\n",
      "Epoch 671/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8948 - val_loss: 0.4151 - val_accuracy: 0.8234\n",
      "Epoch 672/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8946 - val_loss: 0.4141 - val_accuracy: 0.8239\n",
      "Epoch 673/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.8946 - val_loss: 0.4137 - val_accuracy: 0.8229\n",
      "Epoch 674/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2839 - accuracy: 0.8941 - val_loss: 0.4135 - val_accuracy: 0.8214\n",
      "Epoch 675/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8945 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 676/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.8945 - val_loss: 0.4140 - val_accuracy: 0.8244\n",
      "Epoch 677/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8949 - val_loss: 0.4136 - val_accuracy: 0.8219\n",
      "Epoch 678/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8946 - val_loss: 0.4141 - val_accuracy: 0.8244\n",
      "Epoch 679/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8954 - val_loss: 0.4139 - val_accuracy: 0.8229\n",
      "Epoch 680/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8952 - val_loss: 0.4144 - val_accuracy: 0.8229\n",
      "Epoch 681/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.8948 - val_loss: 0.4147 - val_accuracy: 0.8234\n",
      "Epoch 682/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.8946 - val_loss: 0.4140 - val_accuracy: 0.8239\n",
      "Epoch 683/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.8946 - val_loss: 0.4141 - val_accuracy: 0.8244\n",
      "Epoch 684/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8943 - val_loss: 0.4145 - val_accuracy: 0.8239\n",
      "Epoch 685/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8947 - val_loss: 0.4143 - val_accuracy: 0.8234\n",
      "Epoch 686/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.8951 - val_loss: 0.4143 - val_accuracy: 0.8234\n",
      "Epoch 687/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.8943 - val_loss: 0.4141 - val_accuracy: 0.8239\n",
      "Epoch 688/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8947 - val_loss: 0.4149 - val_accuracy: 0.8239\n",
      "Epoch 689/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2828 - accuracy: 0.8951 - val_loss: 0.4143 - val_accuracy: 0.8234\n",
      "Epoch 690/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.8959 - val_loss: 0.4139 - val_accuracy: 0.8229\n",
      "Epoch 691/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.8949 - val_loss: 0.4145 - val_accuracy: 0.8239\n",
      "Epoch 692/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2826 - accuracy: 0.8948 - val_loss: 0.4140 - val_accuracy: 0.8229\n",
      "Epoch 693/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.8938 - val_loss: 0.4142 - val_accuracy: 0.8234\n",
      "Epoch 694/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8956 - val_loss: 0.4141 - val_accuracy: 0.8239\n",
      "Epoch 695/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.8954 - val_loss: 0.4144 - val_accuracy: 0.8234\n",
      "Epoch 696/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8948 - val_loss: 0.4144 - val_accuracy: 0.8234\n",
      "Epoch 697/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8953 - val_loss: 0.4143 - val_accuracy: 0.8224\n",
      "Epoch 698/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8958 - val_loss: 0.4140 - val_accuracy: 0.8229\n",
      "Epoch 699/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.8953 - val_loss: 0.4140 - val_accuracy: 0.8234\n",
      "Epoch 700/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8956 - val_loss: 0.4139 - val_accuracy: 0.8219\n",
      "Epoch 701/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8951 - val_loss: 0.4146 - val_accuracy: 0.8244\n",
      "Epoch 702/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.8950 - val_loss: 0.4147 - val_accuracy: 0.8244\n",
      "Epoch 703/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.8953 - val_loss: 0.4149 - val_accuracy: 0.8234\n",
      "Epoch 704/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.8953 - val_loss: 0.4139 - val_accuracy: 0.8229\n",
      "Epoch 705/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.8948 - val_loss: 0.4144 - val_accuracy: 0.8229\n",
      "Epoch 706/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.8958 - val_loss: 0.4142 - val_accuracy: 0.8239\n",
      "Epoch 707/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.8948 - val_loss: 0.4139 - val_accuracy: 0.8224\n",
      "Epoch 708/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8958 - val_loss: 0.4142 - val_accuracy: 0.8239\n",
      "Epoch 709/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8956 - val_loss: 0.4141 - val_accuracy: 0.8249\n",
      "Epoch 710/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8951 - val_loss: 0.4144 - val_accuracy: 0.8234\n",
      "Epoch 711/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.8962 - val_loss: 0.4143 - val_accuracy: 0.8229\n",
      "Epoch 712/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.8953 - val_loss: 0.4147 - val_accuracy: 0.8239\n",
      "Epoch 713/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2811 - accuracy: 0.8951 - val_loss: 0.4141 - val_accuracy: 0.8224\n",
      "Epoch 714/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8948 - val_loss: 0.4151 - val_accuracy: 0.8244\n",
      "Epoch 715/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2809 - accuracy: 0.8954 - val_loss: 0.4141 - val_accuracy: 0.8234\n",
      "Epoch 716/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2809 - accuracy: 0.8960 - val_loss: 0.4146 - val_accuracy: 0.8229\n",
      "Epoch 717/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2808 - accuracy: 0.8962 - val_loss: 0.4147 - val_accuracy: 0.8239\n",
      "Epoch 718/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2807 - accuracy: 0.8960 - val_loss: 0.4141 - val_accuracy: 0.8234\n",
      "Epoch 719/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.8966 - val_loss: 0.4146 - val_accuracy: 0.8229\n",
      "Epoch 720/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8949 - val_loss: 0.4151 - val_accuracy: 0.8239\n",
      "Epoch 721/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8954 - val_loss: 0.4142 - val_accuracy: 0.8239\n",
      "Epoch 722/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8953 - val_loss: 0.4142 - val_accuracy: 0.8229\n",
      "Epoch 723/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8957 - val_loss: 0.4146 - val_accuracy: 0.8229\n",
      "Epoch 724/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8959 - val_loss: 0.4155 - val_accuracy: 0.8244\n",
      "Epoch 725/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8957 - val_loss: 0.4149 - val_accuracy: 0.8239\n",
      "Epoch 726/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.8959 - val_loss: 0.4146 - val_accuracy: 0.8229\n",
      "Epoch 727/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.8961 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 728/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8961 - val_loss: 0.4147 - val_accuracy: 0.8229\n",
      "Epoch 729/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2800 - accuracy: 0.8957 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 730/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8967 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 731/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.8959 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 732/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.8962 - val_loss: 0.4145 - val_accuracy: 0.8229\n",
      "Epoch 733/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.8966 - val_loss: 0.4147 - val_accuracy: 0.8234\n",
      "Epoch 734/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.8954 - val_loss: 0.4144 - val_accuracy: 0.8239\n",
      "Epoch 735/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.8961 - val_loss: 0.4148 - val_accuracy: 0.8239\n",
      "Epoch 736/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.8948 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 737/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.8970 - val_loss: 0.4149 - val_accuracy: 0.8239\n",
      "Epoch 738/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.8970 - val_loss: 0.4148 - val_accuracy: 0.8239\n",
      "Epoch 739/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.8963 - val_loss: 0.4145 - val_accuracy: 0.8234\n",
      "Epoch 740/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.8966 - val_loss: 0.4150 - val_accuracy: 0.8239\n",
      "Epoch 741/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8957 - val_loss: 0.4145 - val_accuracy: 0.8239\n",
      "Epoch 742/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.8962 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 743/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2791 - accuracy: 0.8960 - val_loss: 0.4151 - val_accuracy: 0.8239\n",
      "Epoch 744/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.8959 - val_loss: 0.4156 - val_accuracy: 0.8244\n",
      "Epoch 745/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2790 - accuracy: 0.8964 - val_loss: 0.4147 - val_accuracy: 0.8239\n",
      "Epoch 746/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2789 - accuracy: 0.8963 - val_loss: 0.4155 - val_accuracy: 0.8249\n",
      "Epoch 747/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.8964 - val_loss: 0.4154 - val_accuracy: 0.8254\n",
      "Epoch 748/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2787 - accuracy: 0.8967 - val_loss: 0.4158 - val_accuracy: 0.8249\n",
      "Epoch 749/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2786 - accuracy: 0.8967 - val_loss: 0.4146 - val_accuracy: 0.8234\n",
      "Epoch 750/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2786 - accuracy: 0.8967 - val_loss: 0.4147 - val_accuracy: 0.8234\n",
      "Epoch 751/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2786 - accuracy: 0.8967 - val_loss: 0.4150 - val_accuracy: 0.8239\n",
      "Epoch 752/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2784 - accuracy: 0.8973 - val_loss: 0.4166 - val_accuracy: 0.8214\n",
      "Epoch 753/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2785 - accuracy: 0.8962 - val_loss: 0.4146 - val_accuracy: 0.8239\n",
      "Epoch 754/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.8965 - val_loss: 0.4155 - val_accuracy: 0.8249\n",
      "Epoch 755/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2783 - accuracy: 0.8966 - val_loss: 0.4153 - val_accuracy: 0.8239\n",
      "Epoch 756/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.8972 - val_loss: 0.4147 - val_accuracy: 0.8234\n",
      "Epoch 757/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.8973 - val_loss: 0.4151 - val_accuracy: 0.8239\n",
      "Epoch 758/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2781 - accuracy: 0.8973 - val_loss: 0.4163 - val_accuracy: 0.8229\n",
      "Epoch 759/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2780 - accuracy: 0.8972 - val_loss: 0.4151 - val_accuracy: 0.8239\n",
      "Epoch 760/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.8975 - val_loss: 0.4148 - val_accuracy: 0.8234\n",
      "Epoch 761/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.8969 - val_loss: 0.4147 - val_accuracy: 0.8224\n",
      "Epoch 762/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8965 - val_loss: 0.4159 - val_accuracy: 0.8244\n",
      "Epoch 763/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.8966 - val_loss: 0.4148 - val_accuracy: 0.8244\n",
      "Epoch 764/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.8970 - val_loss: 0.4148 - val_accuracy: 0.8234\n",
      "Epoch 765/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2777 - accuracy: 0.8967 - val_loss: 0.4157 - val_accuracy: 0.8254\n",
      "Epoch 766/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2776 - accuracy: 0.8975 - val_loss: 0.4148 - val_accuracy: 0.8239\n",
      "Epoch 767/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2775 - accuracy: 0.8975 - val_loss: 0.4153 - val_accuracy: 0.8239\n",
      "Epoch 768/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.8966 - val_loss: 0.4149 - val_accuracy: 0.8239\n",
      "Epoch 769/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2774 - accuracy: 0.8965 - val_loss: 0.4155 - val_accuracy: 0.8239\n",
      "Epoch 770/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2774 - accuracy: 0.8962 - val_loss: 0.4158 - val_accuracy: 0.8254\n",
      "Epoch 771/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8964 - val_loss: 0.4150 - val_accuracy: 0.8239\n",
      "Epoch 772/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8962 - val_loss: 0.4151 - val_accuracy: 0.8234\n",
      "Epoch 773/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.8969 - val_loss: 0.4162 - val_accuracy: 0.8249\n",
      "Epoch 774/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.8978 - val_loss: 0.4163 - val_accuracy: 0.8249\n",
      "Epoch 775/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2771 - accuracy: 0.8970 - val_loss: 0.4160 - val_accuracy: 0.8244\n",
      "Epoch 776/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2770 - accuracy: 0.8970 - val_loss: 0.4150 - val_accuracy: 0.8244\n",
      "Epoch 777/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2770 - accuracy: 0.8975 - val_loss: 0.4152 - val_accuracy: 0.8239\n",
      "Epoch 778/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2769 - accuracy: 0.8974 - val_loss: 0.4151 - val_accuracy: 0.8239\n",
      "Epoch 779/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2766 - accuracy: 0.8970 - val_loss: 0.4157 - val_accuracy: 0.8239\n",
      "Epoch 780/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2767 - accuracy: 0.8970 - val_loss: 0.4154 - val_accuracy: 0.8244\n",
      "Epoch 781/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2767 - accuracy: 0.8976 - val_loss: 0.4152 - val_accuracy: 0.8239\n",
      "Epoch 782/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2767 - accuracy: 0.8975 - val_loss: 0.4155 - val_accuracy: 0.8244\n",
      "Epoch 783/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2765 - accuracy: 0.8966 - val_loss: 0.4151 - val_accuracy: 0.8244\n",
      "Epoch 784/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8970 - val_loss: 0.4152 - val_accuracy: 0.8239\n",
      "Epoch 785/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2764 - accuracy: 0.8978 - val_loss: 0.4155 - val_accuracy: 0.8244\n",
      "Epoch 786/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2763 - accuracy: 0.8969 - val_loss: 0.4152 - val_accuracy: 0.8244\n",
      "Epoch 787/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2763 - accuracy: 0.8972 - val_loss: 0.4153 - val_accuracy: 0.8239\n",
      "Epoch 788/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2762 - accuracy: 0.8973 - val_loss: 0.4152 - val_accuracy: 0.8229\n",
      "Epoch 789/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2762 - accuracy: 0.8964 - val_loss: 0.4155 - val_accuracy: 0.8244\n",
      "Epoch 790/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2761 - accuracy: 0.8973 - val_loss: 0.4152 - val_accuracy: 0.8254\n",
      "Epoch 791/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2760 - accuracy: 0.8972 - val_loss: 0.4155 - val_accuracy: 0.8239\n",
      "Epoch 792/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2760 - accuracy: 0.8970 - val_loss: 0.4164 - val_accuracy: 0.8249\n",
      "Epoch 793/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2758 - accuracy: 0.8967 - val_loss: 0.4156 - val_accuracy: 0.8239\n",
      "Epoch 794/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2759 - accuracy: 0.8977 - val_loss: 0.4154 - val_accuracy: 0.8239\n",
      "Epoch 795/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2758 - accuracy: 0.8979 - val_loss: 0.4157 - val_accuracy: 0.8244\n",
      "Epoch 796/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2757 - accuracy: 0.8980 - val_loss: 0.4159 - val_accuracy: 0.8244\n",
      "Epoch 797/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.8977 - val_loss: 0.4171 - val_accuracy: 0.8224\n",
      "Epoch 798/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2756 - accuracy: 0.8976 - val_loss: 0.4156 - val_accuracy: 0.8239\n",
      "Epoch 799/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2756 - accuracy: 0.8976 - val_loss: 0.4157 - val_accuracy: 0.8239\n",
      "Epoch 800/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8981 - val_loss: 0.4160 - val_accuracy: 0.8249\n",
      "Epoch 801/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8975 - val_loss: 0.4156 - val_accuracy: 0.8239\n",
      "Epoch 802/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2753 - accuracy: 0.8975 - val_loss: 0.4167 - val_accuracy: 0.8239\n",
      "Epoch 803/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.8977 - val_loss: 0.4163 - val_accuracy: 0.8259\n",
      "Epoch 804/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.8973 - val_loss: 0.4156 - val_accuracy: 0.8244\n",
      "Epoch 805/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.8969 - val_loss: 0.4161 - val_accuracy: 0.8254\n",
      "Epoch 806/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2752 - accuracy: 0.8976 - val_loss: 0.4156 - val_accuracy: 0.8239\n",
      "Epoch 807/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8982 - val_loss: 0.4156 - val_accuracy: 0.8249\n",
      "Epoch 808/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8979 - val_loss: 0.4155 - val_accuracy: 0.8239\n",
      "Epoch 809/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.8977 - val_loss: 0.4158 - val_accuracy: 0.8239\n",
      "Epoch 810/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8983 - val_loss: 0.4158 - val_accuracy: 0.8239\n",
      "Epoch 811/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.8980 - val_loss: 0.4156 - val_accuracy: 0.8254\n",
      "Epoch 812/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.8990 - val_loss: 0.4158 - val_accuracy: 0.8239\n",
      "Epoch 813/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8980 - val_loss: 0.4165 - val_accuracy: 0.8254\n",
      "Epoch 814/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8993 - val_loss: 0.4164 - val_accuracy: 0.8259\n",
      "Epoch 815/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8975 - val_loss: 0.4180 - val_accuracy: 0.8224\n",
      "Epoch 816/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8990 - val_loss: 0.4166 - val_accuracy: 0.8254\n",
      "Epoch 817/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8979 - val_loss: 0.4158 - val_accuracy: 0.8244\n",
      "Epoch 818/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8987 - val_loss: 0.4159 - val_accuracy: 0.8244\n",
      "Epoch 819/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.8977 - val_loss: 0.4165 - val_accuracy: 0.8259\n",
      "Epoch 820/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.8979 - val_loss: 0.4157 - val_accuracy: 0.8244\n",
      "Epoch 821/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8978 - val_loss: 0.4158 - val_accuracy: 0.8254\n",
      "Epoch 822/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.8985 - val_loss: 0.4158 - val_accuracy: 0.8249\n",
      "Epoch 823/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2741 - accuracy: 0.8980 - val_loss: 0.4167 - val_accuracy: 0.8254\n",
      "Epoch 824/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8990 - val_loss: 0.4158 - val_accuracy: 0.8249\n",
      "Epoch 825/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.8988 - val_loss: 0.4158 - val_accuracy: 0.8249\n",
      "Epoch 826/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8986 - val_loss: 0.4167 - val_accuracy: 0.8254\n",
      "Epoch 827/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8980 - val_loss: 0.4163 - val_accuracy: 0.8244\n",
      "Epoch 828/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.4163 - val_accuracy: 0.8244\n",
      "Epoch 829/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8979 - val_loss: 0.4160 - val_accuracy: 0.8254\n",
      "Epoch 830/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.8986 - val_loss: 0.4171 - val_accuracy: 0.8244\n",
      "Epoch 831/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.8983 - val_loss: 0.4163 - val_accuracy: 0.8244\n",
      "Epoch 832/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.8977 - val_loss: 0.4167 - val_accuracy: 0.8254\n",
      "Epoch 833/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8981 - val_loss: 0.4160 - val_accuracy: 0.8268\n",
      "Epoch 834/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8987 - val_loss: 0.4160 - val_accuracy: 0.8239\n",
      "Epoch 835/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2735 - accuracy: 0.8978 - val_loss: 0.4171 - val_accuracy: 0.8254\n",
      "Epoch 836/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2734 - accuracy: 0.8990 - val_loss: 0.4162 - val_accuracy: 0.8244\n",
      "Epoch 837/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2734 - accuracy: 0.8983 - val_loss: 0.4164 - val_accuracy: 0.8244\n",
      "Epoch 838/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2733 - accuracy: 0.8979 - val_loss: 0.4163 - val_accuracy: 0.8239\n",
      "Epoch 839/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2732 - accuracy: 0.8987 - val_loss: 0.4164 - val_accuracy: 0.8239\n",
      "Epoch 840/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2732 - accuracy: 0.8986 - val_loss: 0.4161 - val_accuracy: 0.8249\n",
      "Epoch 841/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2732 - accuracy: 0.8986 - val_loss: 0.4162 - val_accuracy: 0.8259\n",
      "Epoch 842/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2731 - accuracy: 0.8989 - val_loss: 0.4166 - val_accuracy: 0.8244\n",
      "Epoch 843/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8988 - val_loss: 0.4167 - val_accuracy: 0.8249\n",
      "Epoch 844/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8990 - val_loss: 0.4167 - val_accuracy: 0.8259\n",
      "Epoch 845/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2729 - accuracy: 0.8988 - val_loss: 0.4165 - val_accuracy: 0.8239\n",
      "Epoch 846/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8987 - val_loss: 0.4164 - val_accuracy: 0.8244\n",
      "Epoch 847/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8984 - val_loss: 0.4165 - val_accuracy: 0.8244\n",
      "Epoch 848/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2728 - accuracy: 0.8986 - val_loss: 0.4165 - val_accuracy: 0.8244\n",
      "Epoch 849/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.8993 - val_loss: 0.4164 - val_accuracy: 0.8259\n",
      "Epoch 850/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8984 - val_loss: 0.4166 - val_accuracy: 0.8244\n",
      "Epoch 851/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8993 - val_loss: 0.4163 - val_accuracy: 0.8259\n",
      "Epoch 852/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2725 - accuracy: 0.8976 - val_loss: 0.4168 - val_accuracy: 0.8254\n",
      "Epoch 853/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2725 - accuracy: 0.8992 - val_loss: 0.4165 - val_accuracy: 0.8259\n",
      "Epoch 854/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8978 - val_loss: 0.4174 - val_accuracy: 0.8249\n",
      "Epoch 855/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8989 - val_loss: 0.4168 - val_accuracy: 0.8244\n",
      "Epoch 856/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.8986 - val_loss: 0.4166 - val_accuracy: 0.8244\n",
      "Epoch 857/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8985 - val_loss: 0.4166 - val_accuracy: 0.8244\n",
      "Epoch 858/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2720 - accuracy: 0.8998 - val_loss: 0.4166 - val_accuracy: 0.8259\n",
      "Epoch 859/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8990 - val_loss: 0.4165 - val_accuracy: 0.8259\n",
      "Epoch 860/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8988 - val_loss: 0.4167 - val_accuracy: 0.8239\n",
      "Epoch 861/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2720 - accuracy: 0.8994 - val_loss: 0.4165 - val_accuracy: 0.8249\n",
      "Epoch 862/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.8989 - val_loss: 0.4166 - val_accuracy: 0.8263\n",
      "Epoch 863/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2719 - accuracy: 0.9002 - val_loss: 0.4173 - val_accuracy: 0.8249\n",
      "Epoch 864/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8996 - val_loss: 0.4166 - val_accuracy: 0.8259\n",
      "Epoch 865/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8983 - val_loss: 0.4175 - val_accuracy: 0.8249\n",
      "Epoch 866/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8993 - val_loss: 0.4167 - val_accuracy: 0.8263\n",
      "Epoch 867/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8998 - val_loss: 0.4166 - val_accuracy: 0.8254\n",
      "Epoch 868/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.8993 - val_loss: 0.4168 - val_accuracy: 0.8259\n",
      "Epoch 869/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2715 - accuracy: 0.8994 - val_loss: 0.4166 - val_accuracy: 0.8249\n",
      "Epoch 870/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2715 - accuracy: 0.8998 - val_loss: 0.4169 - val_accuracy: 0.8244\n",
      "Epoch 871/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2715 - accuracy: 0.8996 - val_loss: 0.4172 - val_accuracy: 0.8249\n",
      "Epoch 872/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8996 - val_loss: 0.4170 - val_accuracy: 0.8244\n",
      "Epoch 873/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8990 - val_loss: 0.4168 - val_accuracy: 0.8263\n",
      "Epoch 874/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8998 - val_loss: 0.4171 - val_accuracy: 0.8244\n",
      "Epoch 875/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8998 - val_loss: 0.4167 - val_accuracy: 0.8249\n",
      "Epoch 876/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2712 - accuracy: 0.9001 - val_loss: 0.4174 - val_accuracy: 0.8249\n",
      "Epoch 877/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2711 - accuracy: 0.8995 - val_loss: 0.4177 - val_accuracy: 0.8244\n",
      "Epoch 878/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.8999 - val_loss: 0.4169 - val_accuracy: 0.8259\n",
      "Epoch 879/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2710 - accuracy: 0.9001 - val_loss: 0.4173 - val_accuracy: 0.8249\n",
      "Epoch 880/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2711 - accuracy: 0.8996 - val_loss: 0.4179 - val_accuracy: 0.8239\n",
      "Epoch 881/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2709 - accuracy: 0.8998 - val_loss: 0.4184 - val_accuracy: 0.8244\n",
      "Epoch 882/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2710 - accuracy: 0.8994 - val_loss: 0.4173 - val_accuracy: 0.8249\n",
      "Epoch 883/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8999 - val_loss: 0.4169 - val_accuracy: 0.8254\n",
      "Epoch 884/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2708 - accuracy: 0.9001 - val_loss: 0.4174 - val_accuracy: 0.8249\n",
      "Epoch 885/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2706 - accuracy: 0.9001 - val_loss: 0.4169 - val_accuracy: 0.8259\n",
      "Epoch 886/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2707 - accuracy: 0.9004 - val_loss: 0.4170 - val_accuracy: 0.8263\n",
      "Epoch 887/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2706 - accuracy: 0.8993 - val_loss: 0.4171 - val_accuracy: 0.8259\n",
      "Epoch 888/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8996 - val_loss: 0.4171 - val_accuracy: 0.8259\n",
      "Epoch 889/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2705 - accuracy: 0.8998 - val_loss: 0.4170 - val_accuracy: 0.8249\n",
      "Epoch 890/1000\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.2705 - accuracy: 0.8994 - val_loss: 0.4170 - val_accuracy: 0.8263\n",
      "Epoch 891/1000\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.2704 - accuracy: 0.8999 - val_loss: 0.4170 - val_accuracy: 0.8263\n",
      "Epoch 892/1000\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.2704 - accuracy: 0.8999 - val_loss: 0.4171 - val_accuracy: 0.8263\n",
      "Epoch 893/1000\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.2703 - accuracy: 0.8994 - val_loss: 0.4174 - val_accuracy: 0.8249\n",
      "Epoch 894/1000\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2703 - accuracy: 0.8995 - val_loss: 0.4175 - val_accuracy: 0.8244\n",
      "Epoch 895/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2702 - accuracy: 0.8998 - val_loss: 0.4172 - val_accuracy: 0.8263\n",
      "Epoch 896/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.8996 - val_loss: 0.4176 - val_accuracy: 0.8249\n",
      "Epoch 897/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8998 - val_loss: 0.4173 - val_accuracy: 0.8254\n",
      "Epoch 898/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2701 - accuracy: 0.8998 - val_loss: 0.4176 - val_accuracy: 0.8249\n",
      "Epoch 899/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2700 - accuracy: 0.8992 - val_loss: 0.4174 - val_accuracy: 0.8259\n",
      "Epoch 900/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2699 - accuracy: 0.8992 - val_loss: 0.4175 - val_accuracy: 0.8259\n",
      "Epoch 901/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2699 - accuracy: 0.9007 - val_loss: 0.4172 - val_accuracy: 0.8263\n",
      "Epoch 902/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.9003 - val_loss: 0.4174 - val_accuracy: 0.8259\n",
      "Epoch 903/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8998 - val_loss: 0.4180 - val_accuracy: 0.8244\n",
      "Epoch 904/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.8999 - val_loss: 0.4178 - val_accuracy: 0.8249\n",
      "Epoch 905/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.9005 - val_loss: 0.4184 - val_accuracy: 0.8239\n",
      "Epoch 906/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.9002 - val_loss: 0.4176 - val_accuracy: 0.8259\n",
      "Epoch 907/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8996 - val_loss: 0.4174 - val_accuracy: 0.8263\n",
      "Epoch 908/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2695 - accuracy: 0.9000 - val_loss: 0.4180 - val_accuracy: 0.8244\n",
      "Epoch 909/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.8993 - val_loss: 0.4178 - val_accuracy: 0.8249\n",
      "Epoch 910/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8999 - val_loss: 0.4174 - val_accuracy: 0.8259\n",
      "Epoch 911/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2694 - accuracy: 0.9006 - val_loss: 0.4180 - val_accuracy: 0.8244\n",
      "Epoch 912/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2694 - accuracy: 0.9001 - val_loss: 0.4178 - val_accuracy: 0.8259\n",
      "Epoch 913/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9002 - val_loss: 0.4179 - val_accuracy: 0.8249\n",
      "Epoch 914/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9009 - val_loss: 0.4176 - val_accuracy: 0.8259\n",
      "Epoch 915/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9001 - val_loss: 0.4181 - val_accuracy: 0.8244\n",
      "Epoch 916/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2691 - accuracy: 0.9002 - val_loss: 0.4175 - val_accuracy: 0.8268\n",
      "Epoch 917/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2691 - accuracy: 0.9001 - val_loss: 0.4181 - val_accuracy: 0.8244\n",
      "Epoch 918/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2691 - accuracy: 0.9002 - val_loss: 0.4177 - val_accuracy: 0.8259\n",
      "Epoch 919/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2690 - accuracy: 0.9001 - val_loss: 0.4180 - val_accuracy: 0.8249\n",
      "Epoch 920/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.4176 - val_accuracy: 0.8273\n",
      "Epoch 921/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9002 - val_loss: 0.4183 - val_accuracy: 0.8244\n",
      "Epoch 922/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2689 - accuracy: 0.8995 - val_loss: 0.4184 - val_accuracy: 0.8239\n",
      "Epoch 923/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2688 - accuracy: 0.9002 - val_loss: 0.4177 - val_accuracy: 0.8278\n",
      "Epoch 924/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2688 - accuracy: 0.9004 - val_loss: 0.4179 - val_accuracy: 0.8263\n",
      "Epoch 925/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.9002 - val_loss: 0.4179 - val_accuracy: 0.8259\n",
      "Epoch 926/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2687 - accuracy: 0.9012 - val_loss: 0.4178 - val_accuracy: 0.8268\n",
      "Epoch 927/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8995 - val_loss: 0.4182 - val_accuracy: 0.8244\n",
      "Epoch 928/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.9011 - val_loss: 0.4181 - val_accuracy: 0.8259\n",
      "Epoch 929/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.9005 - val_loss: 0.4178 - val_accuracy: 0.8273\n",
      "Epoch 930/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.9002 - val_loss: 0.4185 - val_accuracy: 0.8244\n",
      "Epoch 931/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2683 - accuracy: 0.9009 - val_loss: 0.4179 - val_accuracy: 0.8259\n",
      "Epoch 932/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2685 - accuracy: 0.9007 - val_loss: 0.4184 - val_accuracy: 0.8244\n",
      "Epoch 933/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9014 - val_loss: 0.4179 - val_accuracy: 0.8259\n",
      "Epoch 934/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2683 - accuracy: 0.9012 - val_loss: 0.4186 - val_accuracy: 0.8239\n",
      "Epoch 935/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2682 - accuracy: 0.9015 - val_loss: 0.4179 - val_accuracy: 0.8278\n",
      "Epoch 936/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2681 - accuracy: 0.9009 - val_loss: 0.4179 - val_accuracy: 0.8273\n",
      "Epoch 937/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2682 - accuracy: 0.9009 - val_loss: 0.4180 - val_accuracy: 0.8259\n",
      "Epoch 938/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2681 - accuracy: 0.9005 - val_loss: 0.4194 - val_accuracy: 0.8249\n",
      "Epoch 939/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2681 - accuracy: 0.9009 - val_loss: 0.4187 - val_accuracy: 0.8239\n",
      "Epoch 940/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2680 - accuracy: 0.9010 - val_loss: 0.4182 - val_accuracy: 0.8254\n",
      "Epoch 941/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2679 - accuracy: 0.9014 - val_loss: 0.4183 - val_accuracy: 0.8254\n",
      "Epoch 942/1000\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.2678 - accuracy: 0.9008 - val_loss: 0.4181 - val_accuracy: 0.8259\n",
      "Epoch 943/1000\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2678 - accuracy: 0.9003 - val_loss: 0.4182 - val_accuracy: 0.8268\n",
      "Epoch 944/1000\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2677 - accuracy: 0.9002 - val_loss: 0.4185 - val_accuracy: 0.8254\n",
      "Epoch 945/1000\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2678 - accuracy: 0.9007 - val_loss: 0.4181 - val_accuracy: 0.8263\n",
      "Epoch 946/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2677 - accuracy: 0.9010 - val_loss: 0.4182 - val_accuracy: 0.8263\n",
      "Epoch 947/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.9010 - val_loss: 0.4183 - val_accuracy: 0.8268\n",
      "Epoch 948/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.9009 - val_loss: 0.4186 - val_accuracy: 0.8259\n",
      "Epoch 949/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.9010 - val_loss: 0.4182 - val_accuracy: 0.8268\n",
      "Epoch 950/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.9004 - val_loss: 0.4183 - val_accuracy: 0.8263\n",
      "Epoch 951/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.9012 - val_loss: 0.4183 - val_accuracy: 0.8263\n",
      "Epoch 952/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.9014 - val_loss: 0.4186 - val_accuracy: 0.8263\n",
      "Epoch 953/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.9006 - val_loss: 0.4187 - val_accuracy: 0.8254\n",
      "Epoch 954/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.9009 - val_loss: 0.4185 - val_accuracy: 0.8259\n",
      "Epoch 955/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.9003 - val_loss: 0.4184 - val_accuracy: 0.8268\n",
      "Epoch 956/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.9011 - val_loss: 0.4195 - val_accuracy: 0.8234\n",
      "Epoch 957/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2671 - accuracy: 0.9014 - val_loss: 0.4186 - val_accuracy: 0.8263\n",
      "Epoch 958/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9012 - val_loss: 0.4184 - val_accuracy: 0.8268\n",
      "Epoch 959/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.9017 - val_loss: 0.4186 - val_accuracy: 0.8259\n",
      "Epoch 960/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9005 - val_loss: 0.4184 - val_accuracy: 0.8268\n",
      "Epoch 961/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2668 - accuracy: 0.9023 - val_loss: 0.4195 - val_accuracy: 0.8229\n",
      "Epoch 962/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.9014 - val_loss: 0.4188 - val_accuracy: 0.8259\n",
      "Epoch 963/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.9010 - val_loss: 0.4190 - val_accuracy: 0.8254\n",
      "Epoch 964/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2668 - accuracy: 0.9016 - val_loss: 0.4193 - val_accuracy: 0.8229\n",
      "Epoch 965/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9018 - val_loss: 0.4186 - val_accuracy: 0.8268\n",
      "Epoch 966/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2668 - accuracy: 0.9008 - val_loss: 0.4191 - val_accuracy: 0.8254\n",
      "Epoch 967/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9010 - val_loss: 0.4187 - val_accuracy: 0.8273\n",
      "Epoch 968/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9014 - val_loss: 0.4187 - val_accuracy: 0.8273\n",
      "Epoch 969/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.9017 - val_loss: 0.4188 - val_accuracy: 0.8259\n",
      "Epoch 970/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.9014 - val_loss: 0.4186 - val_accuracy: 0.8268\n",
      "Epoch 971/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9016 - val_loss: 0.4195 - val_accuracy: 0.8229\n",
      "Epoch 972/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.9006 - val_loss: 0.4188 - val_accuracy: 0.8268\n",
      "Epoch 973/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.9010 - val_loss: 0.4190 - val_accuracy: 0.8259\n",
      "Epoch 974/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9014 - val_loss: 0.4192 - val_accuracy: 0.8259\n",
      "Epoch 975/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2663 - accuracy: 0.9019 - val_loss: 0.4199 - val_accuracy: 0.8234\n",
      "Epoch 976/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.9007 - val_loss: 0.4187 - val_accuracy: 0.8273\n",
      "Epoch 977/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.9019 - val_loss: 0.4197 - val_accuracy: 0.8234\n",
      "Epoch 978/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.9017 - val_loss: 0.4191 - val_accuracy: 0.8259\n",
      "Epoch 979/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.9005 - val_loss: 0.4190 - val_accuracy: 0.8263\n",
      "Epoch 980/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.9021 - val_loss: 0.4190 - val_accuracy: 0.8273\n",
      "Epoch 981/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.9011 - val_loss: 0.4195 - val_accuracy: 0.8244\n",
      "Epoch 982/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.9020 - val_loss: 0.4191 - val_accuracy: 0.8263\n",
      "Epoch 983/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.9010 - val_loss: 0.4197 - val_accuracy: 0.8229\n",
      "Epoch 984/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.9023 - val_loss: 0.4198 - val_accuracy: 0.8234\n",
      "Epoch 985/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.9021 - val_loss: 0.4192 - val_accuracy: 0.8263\n",
      "Epoch 986/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.9015 - val_loss: 0.4189 - val_accuracy: 0.8268\n",
      "Epoch 987/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2657 - accuracy: 0.9010 - val_loss: 0.4195 - val_accuracy: 0.8254\n",
      "Epoch 988/1000\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2657 - accuracy: 0.9010 - val_loss: 0.4199 - val_accuracy: 0.8229\n",
      "Epoch 989/1000\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2657 - accuracy: 0.9018 - val_loss: 0.4191 - val_accuracy: 0.8268\n",
      "Epoch 990/1000\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.2656 - accuracy: 0.9023 - val_loss: 0.4194 - val_accuracy: 0.8263\n",
      "Epoch 991/1000\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.2655 - accuracy: 0.9011 - val_loss: 0.4190 - val_accuracy: 0.8263\n",
      "Epoch 992/1000\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2656 - accuracy: 0.9012 - val_loss: 0.4196 - val_accuracy: 0.8259\n",
      "Epoch 993/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2655 - accuracy: 0.9006 - val_loss: 0.4197 - val_accuracy: 0.8249\n",
      "Epoch 994/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2655 - accuracy: 0.9017 - val_loss: 0.4195 - val_accuracy: 0.8263\n",
      "Epoch 995/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2654 - accuracy: 0.9018 - val_loss: 0.4197 - val_accuracy: 0.8254\n",
      "Epoch 996/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2654 - accuracy: 0.9014 - val_loss: 0.4194 - val_accuracy: 0.8259\n",
      "Epoch 997/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2653 - accuracy: 0.9018 - val_loss: 0.4195 - val_accuracy: 0.8263\n",
      "Epoch 998/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.2653 - accuracy: 0.9015 - val_loss: 0.4199 - val_accuracy: 0.8244\n",
      "Epoch 999/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.9027 - val_loss: 0.4200 - val_accuracy: 0.8229\n",
      "Epoch 1000/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.9020 - val_loss: 0.4198 - val_accuracy: 0.8254\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.2686 - accuracy: 0.9004\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8278\n",
      "training loss: 0.2685718536376953 training accuracy 0.9003699421882629\n",
      "validation loss: 0.41765162348747253 validation accuracy 0.8278243541717529\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=1000, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer], initial_epoch=200)\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories[-1] = history\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7645995a-bba0-4a7a-aa32-614150dc36ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "507/507 [==============================] - 5s 8ms/step - loss: 0.5833 - accuracy: 0.7155 - val_loss: 0.4433 - val_accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3735 - accuracy: 0.8405 - val_loss: 0.3909 - val_accuracy: 0.8357\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2847 - accuracy: 0.8848 - val_loss: 0.4365 - val_accuracy: 0.8446\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.2215 - accuracy: 0.9129 - val_loss: 0.4648 - val_accuracy: 0.8323\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1898 - accuracy: 0.9268 - val_loss: 0.3952 - val_accuracy: 0.8629\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1536 - accuracy: 0.9436 - val_loss: 0.5393 - val_accuracy: 0.8214\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.1425 - accuracy: 0.9498 - val_loss: 0.4331 - val_accuracy: 0.8648\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.1254 - accuracy: 0.9555 - val_loss: 0.4710 - val_accuracy: 0.8624\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1153 - accuracy: 0.9598 - val_loss: 0.4460 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1094 - accuracy: 0.9633 - val_loss: 0.4582 - val_accuracy: 0.8722\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1018 - accuracy: 0.9665 - val_loss: 0.4613 - val_accuracy: 0.8683\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0975 - accuracy: 0.9673 - val_loss: 0.4843 - val_accuracy: 0.8698\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0854 - accuracy: 0.9726 - val_loss: 0.5134 - val_accuracy: 0.8599\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0845 - accuracy: 0.9731 - val_loss: 0.4847 - val_accuracy: 0.8712\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 0.5015 - val_accuracy: 0.8663\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0730 - accuracy: 0.9762 - val_loss: 0.4920 - val_accuracy: 0.8742\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.5177 - val_accuracy: 0.8737\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0751 - accuracy: 0.9773 - val_loss: 0.4803 - val_accuracy: 0.8717\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.5088 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.5015 - val_accuracy: 0.8717\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0683 - accuracy: 0.9782 - val_loss: 0.4802 - val_accuracy: 0.8678\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.5168 - val_accuracy: 0.8648\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0614 - accuracy: 0.9801 - val_loss: 0.4878 - val_accuracy: 0.8707\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.4986 - val_accuracy: 0.8732\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.5282 - val_accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.4963 - val_accuracy: 0.8698\n",
      "Epoch 27/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 0.4961 - val_accuracy: 0.8722\n",
      "Epoch 28/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.5318 - val_accuracy: 0.8707\n",
      "Epoch 29/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.5103 - val_accuracy: 0.8698\n",
      "Epoch 30/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.5033 - val_accuracy: 0.8757\n",
      "Epoch 31/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.4992 - val_accuracy: 0.8737\n",
      "Epoch 32/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.4983 - val_accuracy: 0.8747\n",
      "Epoch 33/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0541 - accuracy: 0.9819 - val_loss: 0.4881 - val_accuracy: 0.8742\n",
      "Epoch 34/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0514 - accuracy: 0.9830 - val_loss: 0.5187 - val_accuracy: 0.8747\n",
      "Epoch 35/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.5782 - val_accuracy: 0.8614\n",
      "Epoch 36/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.5235 - val_accuracy: 0.8717\n",
      "Epoch 37/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.5087 - val_accuracy: 0.8732\n",
      "Epoch 38/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.5229 - val_accuracy: 0.8757\n",
      "Epoch 39/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.4955 - val_accuracy: 0.8703\n",
      "Epoch 40/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.5185 - val_accuracy: 0.8737\n",
      "Epoch 41/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.5269 - val_accuracy: 0.8722\n",
      "Epoch 42/100\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.0508 - accuracy: 0.9834 - val_loss: 0.5064 - val_accuracy: 0.8752\n",
      "Epoch 43/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.5175 - val_accuracy: 0.8762\n",
      "Epoch 44/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.5056 - val_accuracy: 0.8762\n",
      "Epoch 45/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 0.5067 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0447 - accuracy: 0.9843 - val_loss: 0.5231 - val_accuracy: 0.8791\n",
      "Epoch 47/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0448 - accuracy: 0.9846 - val_loss: 0.5217 - val_accuracy: 0.8707\n",
      "Epoch 48/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.5168 - val_accuracy: 0.8732\n",
      "Epoch 49/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0440 - accuracy: 0.9850 - val_loss: 0.5150 - val_accuracy: 0.8747\n",
      "Epoch 50/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.5257 - val_accuracy: 0.8712\n",
      "Epoch 51/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.5236 - val_accuracy: 0.8747\n",
      "Epoch 52/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.5237 - val_accuracy: 0.8742\n",
      "Epoch 53/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.5255 - val_accuracy: 0.8762\n",
      "Epoch 54/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0461 - accuracy: 0.9843 - val_loss: 0.5183 - val_accuracy: 0.8732\n",
      "Epoch 55/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.5029 - val_accuracy: 0.8801\n",
      "Epoch 56/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.5134 - val_accuracy: 0.8786\n",
      "Epoch 57/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0445 - accuracy: 0.9838 - val_loss: 0.5187 - val_accuracy: 0.8777\n",
      "Epoch 58/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0431 - accuracy: 0.9850 - val_loss: 0.5245 - val_accuracy: 0.8732\n",
      "Epoch 59/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.5170 - val_accuracy: 0.8772\n",
      "Epoch 60/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0386 - accuracy: 0.9863 - val_loss: 0.5465 - val_accuracy: 0.8752\n",
      "Epoch 61/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 0.5276 - val_accuracy: 0.8767\n",
      "Epoch 62/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.5331 - val_accuracy: 0.8732\n",
      "Epoch 63/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.5225 - val_accuracy: 0.8717\n",
      "Epoch 64/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.5237 - val_accuracy: 0.8777\n",
      "Epoch 65/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.5323 - val_accuracy: 0.8767\n",
      "Epoch 66/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.5270 - val_accuracy: 0.8781\n",
      "Epoch 67/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0400 - accuracy: 0.9856 - val_loss: 0.5207 - val_accuracy: 0.8777\n",
      "Epoch 68/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 0.5231 - val_accuracy: 0.8801\n",
      "Epoch 69/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.5218 - val_accuracy: 0.8786\n",
      "Epoch 70/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0390 - accuracy: 0.9864 - val_loss: 0.5164 - val_accuracy: 0.8786\n",
      "Epoch 71/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.5462 - val_accuracy: 0.8752\n",
      "Epoch 72/100\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.5484 - val_accuracy: 0.8742\n",
      "Epoch 73/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.5252 - val_accuracy: 0.8742\n",
      "Epoch 74/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 0.5201 - val_accuracy: 0.8786\n",
      "Epoch 75/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0375 - accuracy: 0.9864 - val_loss: 0.5189 - val_accuracy: 0.8777\n",
      "Epoch 76/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.5223 - val_accuracy: 0.8801\n",
      "Epoch 77/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.5302 - val_accuracy: 0.8757\n",
      "Epoch 78/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0377 - accuracy: 0.9863 - val_loss: 0.5335 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0387 - accuracy: 0.9850 - val_loss: 0.5197 - val_accuracy: 0.8767\n",
      "Epoch 80/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 0.5174 - val_accuracy: 0.8791\n",
      "Epoch 81/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.5294 - val_accuracy: 0.8777\n",
      "Epoch 82/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.5429 - val_accuracy: 0.8777\n",
      "Epoch 83/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0373 - accuracy: 0.9859 - val_loss: 0.5338 - val_accuracy: 0.8801\n",
      "Epoch 84/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.5338 - val_accuracy: 0.8772\n",
      "Epoch 85/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.5343 - val_accuracy: 0.8816\n",
      "Epoch 86/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0381 - accuracy: 0.9853 - val_loss: 0.5402 - val_accuracy: 0.8816\n",
      "Epoch 87/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0378 - accuracy: 0.9865 - val_loss: 0.5643 - val_accuracy: 0.8722\n",
      "Epoch 88/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.5416 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 0.5361 - val_accuracy: 0.8772\n",
      "Epoch 90/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0349 - accuracy: 0.9862 - val_loss: 0.5343 - val_accuracy: 0.8831\n",
      "Epoch 91/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 0.5347 - val_accuracy: 0.8806\n",
      "Epoch 92/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 0.5561 - val_accuracy: 0.8752\n",
      "Epoch 93/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0354 - accuracy: 0.9861 - val_loss: 0.5424 - val_accuracy: 0.8781\n",
      "Epoch 94/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0329 - accuracy: 0.9873 - val_loss: 0.5420 - val_accuracy: 0.8752\n",
      "Epoch 95/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.5503 - val_accuracy: 0.8762\n",
      "Epoch 96/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0355 - accuracy: 0.9859 - val_loss: 0.5354 - val_accuracy: 0.8752\n",
      "Epoch 97/100\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0364 - accuracy: 0.9863 - val_loss: 0.5418 - val_accuracy: 0.8752\n",
      "Epoch 98/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0346 - accuracy: 0.9856 - val_loss: 0.5504 - val_accuracy: 0.8737\n",
      "Epoch 99/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.5445 - val_accuracy: 0.8781\n",
      "Epoch 100/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0330 - accuracy: 0.9867 - val_loss: 0.5568 - val_accuracy: 0.8762\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0183 - accuracy: 0.9891\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.8831\n",
      "training loss: 0.018285376951098442 training accuracy 0.9890875220298767\n",
      "validation loss: 0.5343468189239502 validation accuracy 0.8830784559249878\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.4)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=100, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "672cb254-4874-4dfb-87fa-101286a9d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "507/507 [==============================] - 9s 15ms/step - loss: 0.6306 - accuracy: 0.7086 - val_loss: 0.4477 - val_accuracy: 0.8002\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.3897 - accuracy: 0.8340 - val_loss: 0.4573 - val_accuracy: 0.8135\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.2812 - accuracy: 0.8905 - val_loss: 0.4487 - val_accuracy: 0.8377\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.2150 - accuracy: 0.9183 - val_loss: 0.4254 - val_accuracy: 0.8555\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.1870 - accuracy: 0.9285 - val_loss: 0.4409 - val_accuracy: 0.8589\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.1495 - accuracy: 0.9467 - val_loss: 0.5626 - val_accuracy: 0.8367\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.1329 - accuracy: 0.9561 - val_loss: 0.5171 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1181 - accuracy: 0.9605 - val_loss: 0.5168 - val_accuracy: 0.8564\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.1077 - accuracy: 0.9633 - val_loss: 0.4915 - val_accuracy: 0.8663\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.1028 - accuracy: 0.9673 - val_loss: 0.4671 - val_accuracy: 0.8762\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.4970 - val_accuracy: 0.8707\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0873 - accuracy: 0.9729 - val_loss: 0.5554 - val_accuracy: 0.8668\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.5142 - val_accuracy: 0.8668\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.5178 - val_accuracy: 0.8703\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0808 - accuracy: 0.9754 - val_loss: 0.5018 - val_accuracy: 0.8742\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.5037 - val_accuracy: 0.8722\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0692 - accuracy: 0.9778 - val_loss: 0.5098 - val_accuracy: 0.8722\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 7s 13ms/step - loss: 0.0676 - accuracy: 0.9789 - val_loss: 0.5099 - val_accuracy: 0.8638\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0687 - accuracy: 0.9788 - val_loss: 0.5057 - val_accuracy: 0.8698\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0722 - accuracy: 0.9779 - val_loss: 0.5143 - val_accuracy: 0.8698\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0674 - accuracy: 0.9779 - val_loss: 0.5188 - val_accuracy: 0.8673\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.5390 - val_accuracy: 0.8683\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.5164 - val_accuracy: 0.8688\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0649 - accuracy: 0.9798 - val_loss: 0.5164 - val_accuracy: 0.8722\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.5202 - val_accuracy: 0.8683\n",
      "Epoch 26/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.5149 - val_accuracy: 0.8693\n",
      "Epoch 27/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0529 - accuracy: 0.9822 - val_loss: 0.5359 - val_accuracy: 0.8688\n",
      "Epoch 28/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0545 - accuracy: 0.9821 - val_loss: 0.5260 - val_accuracy: 0.8698\n",
      "Epoch 29/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 0.5260 - val_accuracy: 0.8688\n",
      "Epoch 30/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.5368 - val_accuracy: 0.8683\n",
      "Epoch 31/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.5324 - val_accuracy: 0.8683\n",
      "Epoch 32/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0544 - accuracy: 0.9832 - val_loss: 0.5186 - val_accuracy: 0.8732\n",
      "Epoch 33/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.5081 - val_accuracy: 0.8703\n",
      "Epoch 34/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 0.5231 - val_accuracy: 0.8693\n",
      "Epoch 35/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.5556 - val_accuracy: 0.8712\n",
      "Epoch 36/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.5330 - val_accuracy: 0.8683\n",
      "Epoch 37/100\n",
      "507/507 [==============================] - 7s 13ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 0.5491 - val_accuracy: 0.8727\n",
      "Epoch 38/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.5535 - val_accuracy: 0.8698\n",
      "Epoch 39/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.5280 - val_accuracy: 0.8648\n",
      "Epoch 40/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 0.5292 - val_accuracy: 0.8712\n",
      "Epoch 41/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.5192 - val_accuracy: 0.8727\n",
      "Epoch 42/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0484 - accuracy: 0.9834 - val_loss: 0.5247 - val_accuracy: 0.8717\n",
      "Epoch 43/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.5317 - val_accuracy: 0.8727\n",
      "Epoch 44/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0468 - accuracy: 0.9846 - val_loss: 0.5327 - val_accuracy: 0.8742\n",
      "Epoch 45/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0451 - accuracy: 0.9843 - val_loss: 0.5292 - val_accuracy: 0.8747\n",
      "Epoch 46/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.5369 - val_accuracy: 0.8737\n",
      "Epoch 47/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.5446 - val_accuracy: 0.8678\n",
      "Epoch 48/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 0.5347 - val_accuracy: 0.8703\n",
      "Epoch 49/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.5225 - val_accuracy: 0.8717\n",
      "Epoch 50/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0448 - accuracy: 0.9846 - val_loss: 0.5336 - val_accuracy: 0.8703\n",
      "Epoch 51/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0454 - accuracy: 0.9846 - val_loss: 0.5263 - val_accuracy: 0.8737\n",
      "Epoch 52/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.5349 - val_accuracy: 0.8737\n",
      "Epoch 53/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.5567 - val_accuracy: 0.8693\n",
      "Epoch 54/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 0.5334 - val_accuracy: 0.8747\n",
      "Epoch 55/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.5441 - val_accuracy: 0.8722\n",
      "Epoch 56/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.5479 - val_accuracy: 0.8688\n",
      "Epoch 57/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.5402 - val_accuracy: 0.8722\n",
      "Epoch 58/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.5726 - val_accuracy: 0.8658\n",
      "Epoch 59/100\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0432 - accuracy: 0.9850 - val_loss: 0.5659 - val_accuracy: 0.8663\n",
      "Epoch 60/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.5491 - val_accuracy: 0.8693\n",
      "Epoch 61/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0425 - accuracy: 0.9858 - val_loss: 0.5379 - val_accuracy: 0.8742\n",
      "Epoch 62/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.5454 - val_accuracy: 0.8678\n",
      "Epoch 63/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.5474 - val_accuracy: 0.8698\n",
      "Epoch 64/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 0.5499 - val_accuracy: 0.8688\n",
      "Epoch 65/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 0.5522 - val_accuracy: 0.8732\n",
      "Epoch 66/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0409 - accuracy: 0.9860 - val_loss: 0.5404 - val_accuracy: 0.8722\n",
      "Epoch 67/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0393 - accuracy: 0.9849 - val_loss: 0.5465 - val_accuracy: 0.8742\n",
      "Epoch 68/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0398 - accuracy: 0.9850 - val_loss: 0.5541 - val_accuracy: 0.8742\n",
      "Epoch 69/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0407 - accuracy: 0.9846 - val_loss: 0.5525 - val_accuracy: 0.8688\n",
      "Epoch 70/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.5523 - val_accuracy: 0.8693\n",
      "Epoch 71/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.5613 - val_accuracy: 0.8707\n",
      "Epoch 72/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.5866 - val_accuracy: 0.8668\n",
      "Epoch 73/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.5506 - val_accuracy: 0.8668\n",
      "Epoch 74/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.5410 - val_accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.5538 - val_accuracy: 0.8712\n",
      "Epoch 76/100\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0380 - accuracy: 0.9864 - val_loss: 0.5414 - val_accuracy: 0.8693\n",
      "Epoch 77/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.5490 - val_accuracy: 0.8698\n",
      "Epoch 78/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.5443 - val_accuracy: 0.8707\n",
      "Epoch 79/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 0.5530 - val_accuracy: 0.8717\n",
      "Epoch 80/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.5657 - val_accuracy: 0.8683\n",
      "Epoch 81/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.5603 - val_accuracy: 0.8663\n",
      "Epoch 82/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.5542 - val_accuracy: 0.8663\n",
      "Epoch 83/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.5632 - val_accuracy: 0.8688\n",
      "Epoch 84/100\n",
      "507/507 [==============================] - 7s 13ms/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.5645 - val_accuracy: 0.8693\n",
      "Epoch 85/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.5555 - val_accuracy: 0.8683\n",
      "Epoch 86/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0393 - accuracy: 0.9845 - val_loss: 0.5589 - val_accuracy: 0.8683\n",
      "Epoch 87/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 0.5569 - val_accuracy: 0.8678\n",
      "Epoch 88/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0357 - accuracy: 0.9871 - val_loss: 0.5514 - val_accuracy: 0.8712\n",
      "Epoch 89/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 0.5565 - val_accuracy: 0.8732\n",
      "Epoch 90/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0354 - accuracy: 0.9860 - val_loss: 0.5597 - val_accuracy: 0.8732\n",
      "Epoch 91/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.5510 - val_accuracy: 0.8742\n",
      "Epoch 92/100\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.5489 - val_accuracy: 0.8747\n",
      "Epoch 93/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 0.5507 - val_accuracy: 0.8707\n",
      "Epoch 94/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0359 - accuracy: 0.9870 - val_loss: 0.5539 - val_accuracy: 0.8742\n",
      "Epoch 95/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.5528 - val_accuracy: 0.8707\n",
      "Epoch 96/100\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.5425 - val_accuracy: 0.8707\n",
      "Epoch 97/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 0.5379 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0369 - accuracy: 0.9853 - val_loss: 0.5428 - val_accuracy: 0.8717\n",
      "Epoch 99/100\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0358 - accuracy: 0.9864 - val_loss: 0.5467 - val_accuracy: 0.8703\n",
      "Epoch 100/100\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.5583 - val_accuracy: 0.8712\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.9860\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.8762\n",
      "training loss: 0.04019128531217575 training accuracy 0.9860049486160278\n",
      "validation loss: 0.467102974653244 validation accuracy 0.8761717081069946\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=300, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.4)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=100, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c620231-82b1-4ba3-ac6a-32f7216fcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "507/507 [==============================] - 8s 11ms/step - loss: 0.5233 - accuracy: 0.7420 - val_loss: 0.4280 - val_accuracy: 0.8041\n",
      "Epoch 2/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3350 - accuracy: 0.8593 - val_loss: 0.4115 - val_accuracy: 0.8234\n",
      "Epoch 3/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.2552 - accuracy: 0.8971 - val_loss: 0.4416 - val_accuracy: 0.8303\n",
      "Epoch 4/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.1972 - accuracy: 0.9250 - val_loss: 0.4345 - val_accuracy: 0.8407\n",
      "Epoch 5/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.1707 - accuracy: 0.9377 - val_loss: 0.5016 - val_accuracy: 0.8273\n",
      "Epoch 6/30\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1426 - accuracy: 0.9501 - val_loss: 0.4632 - val_accuracy: 0.8500\n",
      "Epoch 7/30\n",
      "507/507 [==============================] - 7s 13ms/step - loss: 0.1274 - accuracy: 0.9578 - val_loss: 0.4666 - val_accuracy: 0.8481\n",
      "Epoch 8/30\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.1159 - accuracy: 0.9612 - val_loss: 0.5858 - val_accuracy: 0.8293\n",
      "Epoch 9/30\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.1071 - accuracy: 0.9637 - val_loss: 0.4702 - val_accuracy: 0.8574\n",
      "Epoch 10/30\n",
      "507/507 [==============================] - 7s 13ms/step - loss: 0.0988 - accuracy: 0.9669 - val_loss: 0.5402 - val_accuracy: 0.8530\n",
      "Epoch 11/30\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0944 - accuracy: 0.9685 - val_loss: 0.5284 - val_accuracy: 0.8609\n",
      "Epoch 12/30\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0901 - accuracy: 0.9693 - val_loss: 0.6482 - val_accuracy: 0.8490\n",
      "Epoch 13/30\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0820 - accuracy: 0.9729 - val_loss: 0.5067 - val_accuracy: 0.8678\n",
      "Epoch 14/30\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.5075 - val_accuracy: 0.8688\n",
      "Epoch 15/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0738 - accuracy: 0.9754 - val_loss: 0.5072 - val_accuracy: 0.8717\n",
      "Epoch 16/30\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9752 - val_loss: 0.5095 - val_accuracy: 0.8619\n",
      "Epoch 17/30\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9758 - val_loss: 0.5788 - val_accuracy: 0.8545\n",
      "Epoch 18/30\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.0673 - accuracy: 0.9776 - val_loss: 0.4887 - val_accuracy: 0.8698\n",
      "Epoch 19/30\n",
      "507/507 [==============================] - 3s 6ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.5277 - val_accuracy: 0.8698\n",
      "Epoch 20/30\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.5346 - val_accuracy: 0.8673\n",
      "Epoch 21/30\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.5245 - val_accuracy: 0.8614\n",
      "Epoch 22/30\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9786 - val_loss: 0.5551 - val_accuracy: 0.8658\n",
      "Epoch 23/30\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.5471 - val_accuracy: 0.8629\n",
      "Epoch 24/30\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 0.5950 - val_accuracy: 0.8668\n",
      "Epoch 25/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0595 - accuracy: 0.9797 - val_loss: 0.5612 - val_accuracy: 0.8624\n",
      "Epoch 26/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.5344 - val_accuracy: 0.8678\n",
      "Epoch 27/30\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.5357 - val_accuracy: 0.8673\n",
      "Epoch 28/30\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.5781 - val_accuracy: 0.8688\n",
      "Epoch 29/30\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 0.0559 - accuracy: 0.9804 - val_loss: 0.5686 - val_accuracy: 0.8663\n",
      "Epoch 30/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0539 - accuracy: 0.9812 - val_loss: 0.5559 - val_accuracy: 0.8668\n",
      "507/507 [==============================] - 3s 4ms/step - loss: 0.0378 - accuracy: 0.9866\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.8717\n",
      "training loss: 0.037826236337423325 training accuracy 0.9866214394569397\n",
      "validation loss: 0.5071656703948975 validation accuracy 0.8717316389083862\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=50, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.2)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0bbb18c-03f6-49f2-b8ca-d0edc7afb9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "507/507 [==============================] - 13s 21ms/step - loss: 0.5174 - accuracy: 0.7614 - val_loss: 0.4056 - val_accuracy: 0.8273\n",
      "Epoch 2/30\n",
      "507/507 [==============================] - 13s 25ms/step - loss: 0.2439 - accuracy: 0.9064 - val_loss: 0.3630 - val_accuracy: 0.8619\n",
      "Epoch 3/30\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 0.1564 - accuracy: 0.9494 - val_loss: 0.3698 - val_accuracy: 0.8614\n",
      "Epoch 4/30\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 0.1196 - accuracy: 0.9644 - val_loss: 0.3948 - val_accuracy: 0.8683\n",
      "Epoch 5/30\n",
      "507/507 [==============================] - 12s 24ms/step - loss: 0.1033 - accuracy: 0.9689 - val_loss: 0.4185 - val_accuracy: 0.8688\n",
      "Epoch 6/30\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 0.0869 - accuracy: 0.9730 - val_loss: 0.4433 - val_accuracy: 0.8614\n",
      "Epoch 7/30\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.4534 - val_accuracy: 0.8678\n",
      "Epoch 8/30\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.4633 - val_accuracy: 0.8614\n",
      "Epoch 9/30\n",
      "507/507 [==============================] - 16s 31ms/step - loss: 0.0735 - accuracy: 0.9773 - val_loss: 0.4706 - val_accuracy: 0.8658\n",
      "Epoch 10/30\n",
      "507/507 [==============================] - 13s 25ms/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 0.4471 - val_accuracy: 0.8732\n",
      "Epoch 11/30\n",
      "507/507 [==============================] - 12s 24ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 0.4868 - val_accuracy: 0.8624\n",
      "Epoch 12/30\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 0.4891 - val_accuracy: 0.8673\n",
      "Epoch 13/30\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 0.0587 - accuracy: 0.9784 - val_loss: 0.4988 - val_accuracy: 0.8693\n",
      "Epoch 14/30\n",
      "507/507 [==============================] - 16s 32ms/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.4918 - val_accuracy: 0.8658\n",
      "Epoch 15/30\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 0.0553 - accuracy: 0.9801 - val_loss: 0.5025 - val_accuracy: 0.8668\n",
      "Epoch 16/30\n",
      "507/507 [==============================] - 10s 19ms/step - loss: 0.0497 - accuracy: 0.9802 - val_loss: 0.5117 - val_accuracy: 0.8703\n",
      "Epoch 17/30\n",
      "507/507 [==============================] - 12s 23ms/step - loss: 0.0501 - accuracy: 0.9800 - val_loss: 0.5239 - val_accuracy: 0.8633\n",
      "Epoch 18/30\n",
      "507/507 [==============================] - 11s 22ms/step - loss: 0.0504 - accuracy: 0.9813 - val_loss: 0.5262 - val_accuracy: 0.8737\n",
      "Epoch 19/30\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 0.0502 - accuracy: 0.9801 - val_loss: 0.5070 - val_accuracy: 0.8762\n",
      "Epoch 20/30\n",
      "507/507 [==============================] - 13s 25ms/step - loss: 0.0491 - accuracy: 0.9809 - val_loss: 0.5469 - val_accuracy: 0.8658\n",
      "Epoch 21/30\n",
      "507/507 [==============================] - 12s 24ms/step - loss: 0.0457 - accuracy: 0.9811 - val_loss: 0.5382 - val_accuracy: 0.8648\n",
      "Epoch 22/30\n",
      "507/507 [==============================] - 12s 24ms/step - loss: 0.0436 - accuracy: 0.9819 - val_loss: 0.5513 - val_accuracy: 0.8643\n",
      "Epoch 23/30\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 0.0409 - accuracy: 0.9831 - val_loss: 0.5633 - val_accuracy: 0.8663\n",
      "Epoch 24/30\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 0.0439 - accuracy: 0.9822 - val_loss: 0.5617 - val_accuracy: 0.8658\n",
      "Epoch 25/30\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 0.0437 - accuracy: 0.9806 - val_loss: 0.5799 - val_accuracy: 0.8673\n",
      "Epoch 26/30\n",
      "507/507 [==============================] - 11s 22ms/step - loss: 0.0422 - accuracy: 0.9814 - val_loss: 0.5781 - val_accuracy: 0.8643\n",
      "Epoch 27/30\n",
      "507/507 [==============================] - 11s 22ms/step - loss: 0.0375 - accuracy: 0.9827 - val_loss: 0.6011 - val_accuracy: 0.8703\n",
      "Epoch 28/30\n",
      "507/507 [==============================] - 12s 23ms/step - loss: 0.0381 - accuracy: 0.9830 - val_loss: 0.5893 - val_accuracy: 0.8663\n",
      "Epoch 29/30\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 0.0390 - accuracy: 0.9829 - val_loss: 0.5933 - val_accuracy: 0.8712\n",
      "Epoch 30/30\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 0.0367 - accuracy: 0.9830 - val_loss: 0.5927 - val_accuracy: 0.8658\n",
      "507/507 [==============================] - 5s 8ms/step - loss: 0.0248 - accuracy: 0.9882\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.5070 - accuracy: 0.8762\n",
      "training loss: 0.024810096248984337 training accuracy 0.9881627559661865\n",
      "validation loss: 0.5070220232009888 validation accuracy 0.8761717081069946\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=200, activation=\"relu\", \n",
    "                  optimizer=\"Adam\", learning_rate=0.001,\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.2)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix, batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix, batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c7b8f28-5548-4d74-8432-adeb4bcbc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "507/507 [==============================] - 11s 19ms/step - loss: 1.4470 - accuracy: 0.7326 - val_loss: 1.0500 - val_accuracy: 0.7810\n",
      "Epoch 2/30\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.9673 - accuracy: 0.7978 - val_loss: 0.9446 - val_accuracy: 0.7987\n",
      "Epoch 3/30\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.9550 - accuracy: 0.7978 - val_loss: 0.9474 - val_accuracy: 0.8027\n",
      "Epoch 4/30\n",
      "507/507 [==============================] - 9s 18ms/step - loss: 0.9549 - accuracy: 0.7986 - val_loss: 0.9341 - val_accuracy: 0.7977\n",
      "Epoch 5/30\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.9541 - accuracy: 0.7938 - val_loss: 0.9876 - val_accuracy: 0.7701\n",
      "Epoch 6/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9557 - accuracy: 0.8036 - val_loss: 0.9861 - val_accuracy: 0.7982\n",
      "Epoch 7/30\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.9574 - accuracy: 0.7985 - val_loss: 0.9695 - val_accuracy: 0.7977\n",
      "Epoch 8/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9570 - accuracy: 0.8002 - val_loss: 0.9675 - val_accuracy: 0.7918\n",
      "Epoch 9/30\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.9535 - accuracy: 0.8038 - val_loss: 0.9574 - val_accuracy: 0.7928\n",
      "Epoch 10/30\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.9444 - accuracy: 0.7954 - val_loss: 0.9574 - val_accuracy: 0.8081\n",
      "Epoch 11/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9401 - accuracy: 0.8020 - val_loss: 0.9397 - val_accuracy: 0.8046\n",
      "Epoch 12/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9406 - accuracy: 0.8024 - val_loss: 0.9466 - val_accuracy: 0.7997\n",
      "Epoch 13/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9292 - accuracy: 0.8101 - val_loss: 0.9385 - val_accuracy: 0.8032\n",
      "Epoch 14/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9343 - accuracy: 0.8065 - val_loss: 0.9589 - val_accuracy: 0.8002\n",
      "Epoch 15/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9380 - accuracy: 0.8120 - val_loss: 0.9429 - val_accuracy: 0.8111\n",
      "Epoch 16/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9142 - accuracy: 0.8105 - val_loss: 0.9085 - val_accuracy: 0.8115\n",
      "Epoch 17/30\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.9047 - accuracy: 0.8118 - val_loss: 0.9285 - val_accuracy: 0.7972\n",
      "Epoch 18/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9066 - accuracy: 0.8113 - val_loss: 0.9127 - val_accuracy: 0.8130\n",
      "Epoch 19/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9183 - accuracy: 0.8106 - val_loss: 0.9489 - val_accuracy: 0.7933\n",
      "Epoch 20/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9086 - accuracy: 0.8117 - val_loss: 0.9464 - val_accuracy: 0.8056\n",
      "Epoch 21/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9095 - accuracy: 0.8138 - val_loss: 0.9528 - val_accuracy: 0.7967\n",
      "Epoch 22/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.9068 - accuracy: 0.8125 - val_loss: 0.9818 - val_accuracy: 0.7780\n",
      "Epoch 23/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8942 - accuracy: 0.8109 - val_loss: 0.8970 - val_accuracy: 0.8209\n",
      "Epoch 24/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8842 - accuracy: 0.8119 - val_loss: 0.9368 - val_accuracy: 0.7889\n",
      "Epoch 25/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8934 - accuracy: 0.8196 - val_loss: 0.9091 - val_accuracy: 0.8101\n",
      "Epoch 26/30\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.8958 - accuracy: 0.8150 - val_loss: 0.9170 - val_accuracy: 0.8199\n",
      "Epoch 27/30\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.8924 - accuracy: 0.8146 - val_loss: 0.9351 - val_accuracy: 0.8041\n",
      "Epoch 28/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8888 - accuracy: 0.8172 - val_loss: 0.9199 - val_accuracy: 0.8185\n",
      "Epoch 29/30\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.8922 - accuracy: 0.8133 - val_loss: 0.9248 - val_accuracy: 0.8130\n",
      "Epoch 30/30\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8843 - accuracy: 0.8179 - val_loss: 0.9618 - val_accuracy: 0.7839\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.7642 - accuracy: 0.8888\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.8970 - accuracy: 0.8209\n",
      "training loss: 0.7642340064048767 training accuracy 0.888840913772583\n",
      "validation loss: 0.8969910740852356 validation accuracy 0.8209176063537598\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=200, activation=\"relu\", \n",
    "                  optimizer=\"Adam\", learning_rate=0.001,\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5,\n",
    "                  l2_reg=0.01)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix, batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix, batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7f92fbf-d7eb-492a-aac1-18cddc043068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/60\n",
      "507/507 [==============================] - 11s 20ms/step - loss: 0.8877 - accuracy: 0.8142 - val_loss: 0.9202 - val_accuracy: 0.7967\n",
      "Epoch 32/60\n",
      "507/507 [==============================] - 8s 17ms/step - loss: 0.8856 - accuracy: 0.8155 - val_loss: 0.9201 - val_accuracy: 0.8170\n",
      "Epoch 33/60\n",
      "507/507 [==============================] - 12s 24ms/step - loss: 0.9050 - accuracy: 0.8136 - val_loss: 0.9343 - val_accuracy: 0.7992\n",
      "Epoch 34/60\n",
      "507/507 [==============================] - 10s 20ms/step - loss: 0.8901 - accuracy: 0.8156 - val_loss: 0.9204 - val_accuracy: 0.8066\n",
      "Epoch 35/60\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.8955 - accuracy: 0.8159 - val_loss: 0.8942 - val_accuracy: 0.8125\n",
      "Epoch 36/60\n",
      "507/507 [==============================] - 10s 19ms/step - loss: 0.8938 - accuracy: 0.8195 - val_loss: 0.9808 - val_accuracy: 0.7711\n",
      "Epoch 37/60\n",
      "507/507 [==============================] - 9s 17ms/step - loss: 0.8892 - accuracy: 0.8168 - val_loss: 0.9045 - val_accuracy: 0.8076\n",
      "Epoch 38/60\n",
      "507/507 [==============================] - 9s 17ms/step - loss: 0.8823 - accuracy: 0.8188 - val_loss: 0.9365 - val_accuracy: 0.7963\n",
      "Epoch 39/60\n",
      "507/507 [==============================] - 9s 18ms/step - loss: 0.8748 - accuracy: 0.8163 - val_loss: 0.9115 - val_accuracy: 0.8051\n",
      "Epoch 40/60\n",
      "507/507 [==============================] - 11s 21ms/step - loss: 0.8643 - accuracy: 0.8168 - val_loss: 1.0528 - val_accuracy: 0.7519\n",
      "Epoch 41/60\n",
      "507/507 [==============================] - 17s 34ms/step - loss: 0.8416 - accuracy: 0.8211 - val_loss: 0.8796 - val_accuracy: 0.8096\n",
      "Epoch 42/60\n",
      "507/507 [==============================] - 10s 19ms/step - loss: 0.8500 - accuracy: 0.8187 - val_loss: 0.9265 - val_accuracy: 0.8012\n",
      "Epoch 43/60\n",
      "507/507 [==============================] - 10s 19ms/step - loss: 0.8476 - accuracy: 0.8194 - val_loss: 0.8767 - val_accuracy: 0.8056\n",
      "Epoch 44/60\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.8382 - accuracy: 0.8197 - val_loss: 0.8780 - val_accuracy: 0.8106\n",
      "Epoch 45/60\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.8380 - accuracy: 0.8195 - val_loss: 0.8679 - val_accuracy: 0.8086\n",
      "Epoch 46/60\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.8231 - accuracy: 0.8206 - val_loss: 0.8685 - val_accuracy: 0.8012\n",
      "Epoch 47/60\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.8284 - accuracy: 0.8154 - val_loss: 0.8677 - val_accuracy: 0.8061\n",
      "Epoch 48/60\n",
      "507/507 [==============================] - 8s 17ms/step - loss: 0.8177 - accuracy: 0.8223 - val_loss: 0.8438 - val_accuracy: 0.8140\n",
      "Epoch 49/60\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.8154 - accuracy: 0.8218 - val_loss: 0.9238 - val_accuracy: 0.7834\n",
      "Epoch 50/60\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.8121 - accuracy: 0.8233 - val_loss: 0.8461 - val_accuracy: 0.8041\n",
      "Epoch 51/60\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.8093 - accuracy: 0.8217 - val_loss: 0.8359 - val_accuracy: 0.8160\n",
      "Epoch 52/60\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.8004 - accuracy: 0.8220 - val_loss: 0.9297 - val_accuracy: 0.7785\n",
      "Epoch 53/60\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.8026 - accuracy: 0.8183 - val_loss: 0.8241 - val_accuracy: 0.8135\n",
      "Epoch 54/60\n",
      "507/507 [==============================] - 10s 19ms/step - loss: 0.7945 - accuracy: 0.8201 - val_loss: 0.8340 - val_accuracy: 0.8046\n",
      "Epoch 55/60\n",
      "507/507 [==============================] - 9s 18ms/step - loss: 0.8005 - accuracy: 0.8212 - val_loss: 0.8145 - val_accuracy: 0.8209\n",
      "Epoch 56/60\n",
      "507/507 [==============================] - 7s 14ms/step - loss: 0.7881 - accuracy: 0.8263 - val_loss: 0.8167 - val_accuracy: 0.8071\n",
      "Epoch 57/60\n",
      "507/507 [==============================] - 8s 16ms/step - loss: 0.7953 - accuracy: 0.8222 - val_loss: 0.9007 - val_accuracy: 0.7839\n",
      "Epoch 58/60\n",
      "507/507 [==============================] - 8s 15ms/step - loss: 0.7902 - accuracy: 0.8227 - val_loss: 0.8214 - val_accuracy: 0.8180\n",
      "Epoch 59/60\n",
      "507/507 [==============================] - 7s 15ms/step - loss: 0.7985 - accuracy: 0.8207 - val_loss: 0.8178 - val_accuracy: 0.8101\n",
      "Epoch 60/60\n",
      "507/507 [==============================] - 9s 18ms/step - loss: 0.7844 - accuracy: 0.8213 - val_loss: 0.8479 - val_accuracy: 0.8120\n",
      "507/507 [==============================] - 3s 5ms/step - loss: 0.7642 - accuracy: 0.8888\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.8970 - accuracy: 0.8209\n",
      "training loss: 0.7642340064048767 training accuracy 0.888840913772583\n",
      "validation loss: 0.8969910740852356 validation accuracy 0.8209176063537598\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=60, batch_size=32, verbose=1, initial_epoch=30,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix, batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix, batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaa1b7c5-9743-4835-8621-40badcc08ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"loss\"], label=\"train loss\", color=\"blue\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val loss\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train accuracy\", color=\"blue\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val accuracy\", color=\"orange\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c01fe-169e-4762-9b5e-6b288f8aa252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECS289G",
   "language": "python",
   "name": "ecs289g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
