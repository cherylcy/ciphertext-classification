{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d11aac-2269-493f-8492-7e166a088ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 01:00:36.479611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Add, Concatenate\n",
    "from keras.layers import BatchNormalization, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977fb70e-cb45-4531-b668-aa5649b3a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    data_path = {\n",
    "        'train': './data/train_enc.tsv',\n",
    "        'dev': './data/dev_enc.tsv',\n",
    "        'test': './test_enc_unlabeled.tsv'\n",
    "    }\n",
    "    res = []\n",
    "    if dataset in ['train','dev']:\n",
    "        for x in open(data_path[dataset], encoding='utf-8'):\n",
    "            x = x.rstrip('\\n\\r').split('\\t')\n",
    "            x[0] = int(x[0])\n",
    "            res.append(x)\n",
    "    elif dataset == 'test':\n",
    "        for x in open(data_path[dataset], encoding='utf-8'):\n",
    "            x = x.rstrip('\\n\\r')\n",
    "            res.append(x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6e1d02-24fb-403c-8bcb-fbabbcb42f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('train')\n",
    "dev = load_data('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff102844-3f94-44ea-a82a-90b3fec9759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [x[0] for x in train]\n",
    "train_texts = [x[1] for x in train]\n",
    "dev_labels = [x[0] for x in dev]\n",
    "dev_texts = [x[1] for x in dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee3fbab-94b5-42c6-b6a1-ae3a586983b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16220\n",
      "Dev size: 2027\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", len(train_labels))\n",
    "print(\"Dev size:\", len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde5efb8-877a-4399-8b65-91c025a2e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16220, 17248)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(train_texts)\n",
    "cv_vec = cv.transform(train_texts)\n",
    "print(cv_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfeed907-ccc6-46ac-9c17-03265c148240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.6, min_df=0.001, ngram_range=(1, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features using TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1,4),\n",
    "    max_df=0.6,\n",
    "    min_df=0.001\n",
    ")\n",
    "tfidf.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f19260-275f-4064-9525-048304e22076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16220, 3967)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = tfidf.transform(train_texts)\n",
    "print(tfidf_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94902123-853f-4fba-80e5-336bccae5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the feats_matrix\n",
    "train_feats_matrix = tfidf.transform(train_texts).toarray()\n",
    "dev_feats_matrix = tfidf.transform(dev_texts).toarray()\n",
    "# convert labels to label_matrix\n",
    "num_classes = 2\n",
    "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
    "train_label_matrix = keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
    "dev_label_matrix = keras.utils.to_categorical(dev_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe316ea-2bd5-48ff-834a-d23cf814c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP(input_size, output_size, num_layers, hidden_size,\n",
    "              activation=\"relu\",\n",
    "              dropout_rate=0.0,\n",
    "              batch_norm=False,\n",
    "              layer_norm=False,\n",
    "              l2_reg=0.0,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              learning_rate=0.1,\n",
    "              metric=\"accuracy\"):\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "    if num_layers == 1:\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=input_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\",\n",
    "                        kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "    else:\n",
    "        for i in range(num_layers-1):\n",
    "            if i == 0:\n",
    "                # fitst layer: input -> hidden\n",
    "                model.add(Dense(hidden_size,\n",
    "                                input_dim=input_size,\n",
    "                                kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                                bias_initializer=\"zeros\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            else:\n",
    "                # hidden layers: hidden -> hidden\n",
    "                model.add(Dense(hidden_size,\n",
    "                                input_dim=hidden_size,\n",
    "                                kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                                bias_initializer=\"zeros\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            # add layer_norm\n",
    "            if layer_norm:\n",
    "                model.add(LayerNormalization())\n",
    "            # add batch_norm\n",
    "            if batch_norm:\n",
    "                model.add(BatchNormalization())\n",
    "            # add activation\n",
    "            model.add(Activation(activation))\n",
    "            # add dropout here (set seed as 0 in order to reproduce)\n",
    "            if dropout_rate > 0.0:\n",
    "                model.add(Dropout(dropout_rate, seed=0))\n",
    "        # last layer: hidden -> class\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=hidden_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\"))\n",
    "    \n",
    "    # set the loss, the optimizer, and the metric\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c803b-a7d6-4fd1-aeb4-a855220e5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM(input_size, output_size, num_layers, hidden_size,\n",
    "              activation=\"relu\",\n",
    "              dropout_rate=0.0,\n",
    "              batch_norm=False,\n",
    "              layer_norm=False,\n",
    "              l2_reg=0.0,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              learning_rate=0.1,\n",
    "              metric=\"accuracy\"):\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "    if num_layers == 1:\n",
    "        model.add(LSTM(output_size,\n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                       bias_initializer=\"zeros\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "        # last layer: hidden -> class\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=hidden_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\"))\n",
    "    else:\n",
    "        for i in range(num_layers-1):\n",
    "            if i == 0:\n",
    "                # fitst layer: input -> hidden\n",
    "                model.add(LSTM(hidden_size,\n",
    "                               kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                               bias_initializer=\"zeros\",\n",
    "                               kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            else:\n",
    "                # hidden layers: hidden -> hidden\n",
    "                model.add(LSTM(hidden_size,\n",
    "                               kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                               bias_initializer=\"zeros\",\n",
    "                               kernel_regularizer=keras.regularizers.l2(l2_reg)))\n",
    "            # add layer_norm\n",
    "            if layer_norm:\n",
    "                model.add(LayerNormalization())\n",
    "            # add batch_norm\n",
    "            if batch_norm:\n",
    "                model.add(BatchNormalization())\n",
    "            # add dropout here (set seed as 0 in order to reproduce)\n",
    "            if dropout_rate > 0.0:\n",
    "                model.add(Dropout(dropout_rate, seed=0))\n",
    "        # last layer: hidden -> class\n",
    "        model.add(Dense(output_size,\n",
    "                        activation=\"softmax\",\n",
    "                        input_dim=hidden_size,\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                        bias_initializer=\"zeros\"))\n",
    "    \n",
    "    # set the loss, the optimizer, and the metric\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf9fb87-fcd4-46a7-affa-86e7c8d2b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01dd96f5-f00c-41e1-918c-7f12ff9c0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5924 - loss: 0.7535 - val_accuracy: 0.7928 - val_loss: 0.4556\n",
      "Epoch 2/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7814 - loss: 0.4785 - val_accuracy: 0.8185 - val_loss: 0.4559\n",
      "Epoch 3/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.3746 - val_accuracy: 0.8397 - val_loss: 0.4411\n",
      "Epoch 4/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8765 - loss: 0.2996 - val_accuracy: 0.8411 - val_loss: 0.4604\n",
      "Epoch 5/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8953 - loss: 0.2586 - val_accuracy: 0.8367 - val_loss: 0.5235\n",
      "Epoch 6/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2263 - val_accuracy: 0.8485 - val_loss: 0.5016\n",
      "Epoch 7/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.1930 - val_accuracy: 0.8535 - val_loss: 0.5213\n",
      "Epoch 8/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9349 - loss: 0.1682 - val_accuracy: 0.8569 - val_loss: 0.5636\n",
      "Epoch 9/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.1463 - val_accuracy: 0.8633 - val_loss: 0.5454\n",
      "Epoch 10/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9485 - loss: 0.1315 - val_accuracy: 0.8648 - val_loss: 0.5287\n",
      "Epoch 11/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.1321 - val_accuracy: 0.8604 - val_loss: 0.5466\n",
      "Epoch 12/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1207 - val_accuracy: 0.8678 - val_loss: 0.5671\n",
      "Epoch 13/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9591 - loss: 0.1090 - val_accuracy: 0.8673 - val_loss: 0.5766\n",
      "Epoch 14/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.0966 - val_accuracy: 0.8663 - val_loss: 0.5878\n",
      "Epoch 15/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.0950 - val_accuracy: 0.8777 - val_loss: 0.6206\n",
      "Epoch 16/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0831 - val_accuracy: 0.8688 - val_loss: 0.6447\n",
      "Epoch 17/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.0784 - val_accuracy: 0.8633 - val_loss: 0.6934\n",
      "Epoch 18/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9704 - loss: 0.0781 - val_accuracy: 0.8688 - val_loss: 0.6380\n",
      "Epoch 19/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0712 - val_accuracy: 0.8732 - val_loss: 0.6845\n",
      "Epoch 20/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0684 - val_accuracy: 0.8722 - val_loss: 0.6656\n",
      "Epoch 21/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.0653 - val_accuracy: 0.8742 - val_loss: 0.6447\n",
      "Epoch 22/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0573 - val_accuracy: 0.8742 - val_loss: 0.7099\n",
      "Epoch 23/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0567 - val_accuracy: 0.8737 - val_loss: 0.6812\n",
      "Epoch 24/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.0511 - val_accuracy: 0.8752 - val_loss: 0.7068\n",
      "Epoch 25/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9787 - loss: 0.0537 - val_accuracy: 0.8747 - val_loss: 0.7171\n",
      "Epoch 26/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9807 - loss: 0.0530 - val_accuracy: 0.8752 - val_loss: 0.7242\n",
      "Epoch 27/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0476 - val_accuracy: 0.8717 - val_loss: 0.7585\n",
      "Epoch 28/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0498 - val_accuracy: 0.8747 - val_loss: 0.7410\n",
      "Epoch 29/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0430 - val_accuracy: 0.8727 - val_loss: 0.7499\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0389 - val_accuracy: 0.8737 - val_loss: 0.7576\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0447\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.6679\n",
      "training loss: 0.04433406516909599 training accuracy 0.9827989935874939\n",
      "validation loss: 0.6206386685371399 validation accuracy 0.8776516914367676\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=3, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e98d59-8e05-4aeb-9778-daed7b104f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.6148 - accuracy: 0.6948 - val_loss: 0.4475 - val_accuracy: 0.7918\n",
      "Epoch 2/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.4104 - accuracy: 0.8175 - val_loss: 0.4106 - val_accuracy: 0.8229\n",
      "Epoch 3/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3249 - accuracy: 0.8621 - val_loss: 0.3948 - val_accuracy: 0.8441\n",
      "Epoch 4/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2639 - accuracy: 0.8923 - val_loss: 0.3974 - val_accuracy: 0.8495\n",
      "Epoch 5/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2266 - accuracy: 0.9087 - val_loss: 0.4093 - val_accuracy: 0.8574\n",
      "Epoch 6/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1937 - accuracy: 0.9273 - val_loss: 0.4244 - val_accuracy: 0.8559\n",
      "Epoch 7/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1710 - accuracy: 0.9335 - val_loss: 0.4075 - val_accuracy: 0.8688\n",
      "Epoch 8/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1534 - accuracy: 0.9413 - val_loss: 0.4628 - val_accuracy: 0.8619\n",
      "Epoch 9/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1385 - accuracy: 0.9501 - val_loss: 0.4254 - val_accuracy: 0.8747\n",
      "Epoch 10/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1324 - accuracy: 0.9524 - val_loss: 0.4269 - val_accuracy: 0.8707\n",
      "Epoch 11/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1168 - accuracy: 0.9599 - val_loss: 0.4422 - val_accuracy: 0.8678\n",
      "Epoch 12/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1066 - accuracy: 0.9628 - val_loss: 0.4622 - val_accuracy: 0.8791\n",
      "Epoch 13/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.1019 - accuracy: 0.9645 - val_loss: 0.4656 - val_accuracy: 0.8678\n",
      "Epoch 14/30\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.4902 - val_accuracy: 0.8752\n",
      "Epoch 15/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0954 - accuracy: 0.9668 - val_loss: 0.4805 - val_accuracy: 0.8673\n",
      "Epoch 16/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0870 - accuracy: 0.9702 - val_loss: 0.4719 - val_accuracy: 0.8806\n",
      "Epoch 17/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.4832 - val_accuracy: 0.8737\n",
      "Epoch 18/30\n",
      "507/507 [==============================] - 4s 9ms/step - loss: 0.0843 - accuracy: 0.9731 - val_loss: 0.4615 - val_accuracy: 0.8732\n",
      "Epoch 19/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 0.4790 - val_accuracy: 0.8722\n",
      "Epoch 20/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.4881 - val_accuracy: 0.8678\n",
      "Epoch 21/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.4771 - val_accuracy: 0.8663\n",
      "Epoch 22/30\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 0.5024 - val_accuracy: 0.8698\n",
      "Epoch 23/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0725 - accuracy: 0.9769 - val_loss: 0.4834 - val_accuracy: 0.8752\n",
      "Epoch 24/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0736 - accuracy: 0.9768 - val_loss: 0.4939 - val_accuracy: 0.8727\n",
      "Epoch 25/30\n",
      "507/507 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 0.4961 - val_accuracy: 0.8727\n",
      "Epoch 26/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0670 - accuracy: 0.9784 - val_loss: 0.5043 - val_accuracy: 0.8767\n",
      "Epoch 27/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.5041 - val_accuracy: 0.8732\n",
      "Epoch 28/30\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.5054 - val_accuracy: 0.8727\n",
      "Epoch 29/30\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.5015 - val_accuracy: 0.8727\n",
      "Epoch 30/30\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.5052 - val_accuracy: 0.8777\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.9864\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.8806\n",
      "training loss: 0.03251943364739418 training accuracy 0.9863748550415039\n",
      "validation loss: 0.47187790274620056 validation accuracy 0.8806117177009583\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=2, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=30, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d79cc2e-a1fe-4c84-aa74-9aa0e7b1c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.6856 - accuracy: 0.5801 - val_loss: 0.6768 - val_accuracy: 0.7010\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.6702 - accuracy: 0.6819 - val_loss: 0.6646 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.7102 - val_loss: 0.6511 - val_accuracy: 0.7277\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.6441 - accuracy: 0.7276 - val_loss: 0.6400 - val_accuracy: 0.7277\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.6331 - accuracy: 0.7394 - val_loss: 0.6302 - val_accuracy: 0.7316\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.7473 - val_loss: 0.6215 - val_accuracy: 0.7346\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.7523 - val_loss: 0.6138 - val_accuracy: 0.7361\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.6053 - accuracy: 0.7544 - val_loss: 0.6079 - val_accuracy: 0.7366\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5973 - accuracy: 0.7596 - val_loss: 0.5988 - val_accuracy: 0.7420\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.7593 - val_loss: 0.5926 - val_accuracy: 0.7454\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5829 - accuracy: 0.7633 - val_loss: 0.5866 - val_accuracy: 0.7454\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.7667 - val_loss: 0.5813 - val_accuracy: 0.7474\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7693 - val_loss: 0.5788 - val_accuracy: 0.7479\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5649 - accuracy: 0.7723 - val_loss: 0.5718 - val_accuracy: 0.7499\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7740 - val_loss: 0.5674 - val_accuracy: 0.7514\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7765 - val_loss: 0.5630 - val_accuracy: 0.7533\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5498 - accuracy: 0.7762 - val_loss: 0.5592 - val_accuracy: 0.7528\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7770 - val_loss: 0.5555 - val_accuracy: 0.7533\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7822 - val_loss: 0.5531 - val_accuracy: 0.7573\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7816 - val_loss: 0.5480 - val_accuracy: 0.7588\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7832 - val_loss: 0.5448 - val_accuracy: 0.7573\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5288 - accuracy: 0.7856 - val_loss: 0.5426 - val_accuracy: 0.7593\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7849 - val_loss: 0.5399 - val_accuracy: 0.7602\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7883 - val_loss: 0.5360 - val_accuracy: 0.7588\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7898 - val_loss: 0.5332 - val_accuracy: 0.7607\n",
      "Epoch 26/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7911 - val_loss: 0.5314 - val_accuracy: 0.7602\n",
      "Epoch 27/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7925 - val_loss: 0.5287 - val_accuracy: 0.7612\n",
      "Epoch 28/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7932 - val_loss: 0.5263 - val_accuracy: 0.7612\n",
      "Epoch 29/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7963 - val_loss: 0.5237 - val_accuracy: 0.7607\n",
      "Epoch 30/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.5029 - accuracy: 0.7972 - val_loss: 0.5230 - val_accuracy: 0.7652\n",
      "Epoch 31/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.5002 - accuracy: 0.7987 - val_loss: 0.5194 - val_accuracy: 0.7642\n",
      "Epoch 32/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7990 - val_loss: 0.5178 - val_accuracy: 0.7617\n",
      "Epoch 33/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.8015 - val_loss: 0.5152 - val_accuracy: 0.7662\n",
      "Epoch 34/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4920 - accuracy: 0.8030 - val_loss: 0.5133 - val_accuracy: 0.7662\n",
      "Epoch 35/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.8041 - val_loss: 0.5095 - val_accuracy: 0.7652\n",
      "Epoch 37/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.8053 - val_loss: 0.5078 - val_accuracy: 0.7671\n",
      "Epoch 38/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.8054 - val_loss: 0.5060 - val_accuracy: 0.7676\n",
      "Epoch 39/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.8068 - val_loss: 0.5058 - val_accuracy: 0.7706\n",
      "Epoch 40/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8086 - val_loss: 0.5031 - val_accuracy: 0.7691\n",
      "Epoch 41/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8084 - val_loss: 0.5026 - val_accuracy: 0.7726\n",
      "Epoch 42/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.8091 - val_loss: 0.5001 - val_accuracy: 0.7691\n",
      "Epoch 43/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.8096 - val_loss: 0.4983 - val_accuracy: 0.7731\n",
      "Epoch 44/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4704 - accuracy: 0.8120 - val_loss: 0.4975 - val_accuracy: 0.7745\n",
      "Epoch 45/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8115 - val_loss: 0.4957 - val_accuracy: 0.7696\n",
      "Epoch 46/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.8126 - val_loss: 0.4952 - val_accuracy: 0.7750\n",
      "Epoch 47/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.8141 - val_loss: 0.4932 - val_accuracy: 0.7731\n",
      "Epoch 48/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.8157 - val_loss: 0.4919 - val_accuracy: 0.7736\n",
      "Epoch 49/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4614 - accuracy: 0.8154 - val_loss: 0.4932 - val_accuracy: 0.7795\n",
      "Epoch 50/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8159 - val_loss: 0.4904 - val_accuracy: 0.7800\n",
      "Epoch 51/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.8160 - val_loss: 0.4880 - val_accuracy: 0.7741\n",
      "Epoch 52/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8173 - val_loss: 0.4884 - val_accuracy: 0.7805\n",
      "Epoch 53/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8193 - val_loss: 0.4858 - val_accuracy: 0.7765\n",
      "Epoch 54/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8200 - val_loss: 0.4846 - val_accuracy: 0.7829\n",
      "Epoch 55/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.8213 - val_loss: 0.4839 - val_accuracy: 0.7780\n",
      "Epoch 56/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.8192 - val_loss: 0.4826 - val_accuracy: 0.7815\n",
      "Epoch 57/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8217 - val_loss: 0.4819 - val_accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8237 - val_loss: 0.4804 - val_accuracy: 0.7829\n",
      "Epoch 59/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8221 - val_loss: 0.4811 - val_accuracy: 0.7819\n",
      "Epoch 60/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4446 - accuracy: 0.8242 - val_loss: 0.4786 - val_accuracy: 0.7839\n",
      "Epoch 61/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8247 - val_loss: 0.4783 - val_accuracy: 0.7810\n",
      "Epoch 62/100\n",
      "507/507 [==============================] - 2s 5ms/step - loss: 0.4419 - accuracy: 0.8245 - val_loss: 0.4771 - val_accuracy: 0.7824\n",
      "Epoch 63/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8254 - val_loss: 0.4761 - val_accuracy: 0.7805\n",
      "Epoch 64/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.8276 - val_loss: 0.4764 - val_accuracy: 0.7849\n",
      "Epoch 65/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4379 - accuracy: 0.8266 - val_loss: 0.4745 - val_accuracy: 0.7834\n",
      "Epoch 66/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4367 - accuracy: 0.8263 - val_loss: 0.4731 - val_accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4355 - accuracy: 0.8294 - val_loss: 0.4728 - val_accuracy: 0.7829\n",
      "Epoch 68/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4342 - accuracy: 0.8286 - val_loss: 0.4716 - val_accuracy: 0.7879\n",
      "Epoch 69/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4331 - accuracy: 0.8289 - val_loss: 0.4709 - val_accuracy: 0.7874\n",
      "Epoch 70/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4318 - accuracy: 0.8312 - val_loss: 0.4715 - val_accuracy: 0.7849\n",
      "Epoch 71/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4308 - accuracy: 0.8303 - val_loss: 0.4694 - val_accuracy: 0.7908\n",
      "Epoch 72/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4297 - accuracy: 0.8303 - val_loss: 0.4693 - val_accuracy: 0.7869\n",
      "Epoch 73/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4284 - accuracy: 0.8318 - val_loss: 0.4693 - val_accuracy: 0.7834\n",
      "Epoch 74/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4274 - accuracy: 0.8316 - val_loss: 0.4676 - val_accuracy: 0.7903\n",
      "Epoch 75/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4264 - accuracy: 0.8326 - val_loss: 0.4667 - val_accuracy: 0.7913\n",
      "Epoch 76/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.4657 - val_accuracy: 0.7918\n",
      "Epoch 77/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8338 - val_loss: 0.4650 - val_accuracy: 0.7923\n",
      "Epoch 78/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4232 - accuracy: 0.8343 - val_loss: 0.4643 - val_accuracy: 0.7923\n",
      "Epoch 79/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4221 - accuracy: 0.8346 - val_loss: 0.4652 - val_accuracy: 0.7859\n",
      "Epoch 80/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4212 - accuracy: 0.8349 - val_loss: 0.4630 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4203 - accuracy: 0.8361 - val_loss: 0.4629 - val_accuracy: 0.7928\n",
      "Epoch 82/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4192 - accuracy: 0.8357 - val_loss: 0.4623 - val_accuracy: 0.7938\n",
      "Epoch 83/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4181 - accuracy: 0.8374 - val_loss: 0.4633 - val_accuracy: 0.7859\n",
      "Epoch 84/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8363 - val_loss: 0.4604 - val_accuracy: 0.7977\n",
      "Epoch 85/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8366 - val_loss: 0.4600 - val_accuracy: 0.7963\n",
      "Epoch 86/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8375 - val_loss: 0.4608 - val_accuracy: 0.7898\n",
      "Epoch 87/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4144 - accuracy: 0.8374 - val_loss: 0.4603 - val_accuracy: 0.7913\n",
      "Epoch 88/100\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.4135 - accuracy: 0.8380 - val_loss: 0.4582 - val_accuracy: 0.7982\n",
      "Epoch 89/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4126 - accuracy: 0.8381 - val_loss: 0.4581 - val_accuracy: 0.7982\n",
      "Epoch 90/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8393 - val_loss: 0.4582 - val_accuracy: 0.7938\n",
      "Epoch 91/100\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8389 - val_loss: 0.4592 - val_accuracy: 0.7859\n",
      "Epoch 92/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4101 - accuracy: 0.8396 - val_loss: 0.4559 - val_accuracy: 0.7987\n",
      "Epoch 93/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4093 - accuracy: 0.8403 - val_loss: 0.4560 - val_accuracy: 0.8002\n",
      "Epoch 94/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4083 - accuracy: 0.8403 - val_loss: 0.4550 - val_accuracy: 0.8007\n",
      "Epoch 95/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4075 - accuracy: 0.8408 - val_loss: 0.4544 - val_accuracy: 0.8002\n",
      "Epoch 96/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4068 - accuracy: 0.8407 - val_loss: 0.4545 - val_accuracy: 0.8002\n",
      "Epoch 97/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4060 - accuracy: 0.8409 - val_loss: 0.4535 - val_accuracy: 0.8017\n",
      "Epoch 98/100\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4052 - accuracy: 0.8420 - val_loss: 0.4530 - val_accuracy: 0.8012\n",
      "Epoch 99/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8414 - val_loss: 0.4529 - val_accuracy: 0.8017\n",
      "Epoch 100/100\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4035 - accuracy: 0.8415 - val_loss: 0.4537 - val_accuracy: 0.7958\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8420\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8017\n",
      "training loss: 0.4050333797931671 training accuracy 0.842046856880188\n",
      "validation loss: 0.4535011053085327 validation accuracy 0.8016773462295532\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = build_MLP(input_size=train_feats_matrix.shape[1], output_size=num_classes,\n",
    "                  num_layers=1, hidden_size=200, activation=\"relu\",\n",
    "                  batch_norm=True, layer_norm=True, dropout_rate=0.5)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/mlp.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=100, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b71d67b2-2c7f-4144-b554-48d4bce55406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.4051 - accuracy: 0.8417 - val_loss: 0.4540 - val_accuracy: 0.7982\n",
      "Epoch 102/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8417 - val_loss: 0.4530 - val_accuracy: 0.7997\n",
      "Epoch 103/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4035 - accuracy: 0.8426 - val_loss: 0.4521 - val_accuracy: 0.8022\n",
      "Epoch 104/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8425 - val_loss: 0.4522 - val_accuracy: 0.8007\n",
      "Epoch 105/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.4020 - accuracy: 0.8446 - val_loss: 0.4517 - val_accuracy: 0.8022\n",
      "Epoch 106/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4013 - accuracy: 0.8435 - val_loss: 0.4509 - val_accuracy: 0.8037\n",
      "Epoch 107/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8443 - val_loss: 0.4510 - val_accuracy: 0.7997\n",
      "Epoch 108/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8451 - val_loss: 0.4512 - val_accuracy: 0.7987\n",
      "Epoch 109/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3992 - accuracy: 0.8451 - val_loss: 0.4494 - val_accuracy: 0.8041\n",
      "Epoch 110/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8457 - val_loss: 0.4489 - val_accuracy: 0.8037\n",
      "Epoch 111/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8465 - val_loss: 0.4485 - val_accuracy: 0.8076\n",
      "Epoch 112/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8457 - val_loss: 0.4480 - val_accuracy: 0.8076\n",
      "Epoch 113/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8456 - val_loss: 0.4495 - val_accuracy: 0.7967\n",
      "Epoch 114/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8464 - val_loss: 0.4473 - val_accuracy: 0.8061\n",
      "Epoch 115/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8468 - val_loss: 0.4472 - val_accuracy: 0.8041\n",
      "Epoch 116/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8469 - val_loss: 0.4469 - val_accuracy: 0.8041\n",
      "Epoch 117/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3936 - accuracy: 0.8478 - val_loss: 0.4464 - val_accuracy: 0.8061\n",
      "Epoch 118/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8477 - val_loss: 0.4458 - val_accuracy: 0.8071\n",
      "Epoch 119/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3923 - accuracy: 0.8475 - val_loss: 0.4467 - val_accuracy: 0.8017\n",
      "Epoch 120/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3915 - accuracy: 0.8485 - val_loss: 0.4450 - val_accuracy: 0.8096\n",
      "Epoch 121/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3910 - accuracy: 0.8494 - val_loss: 0.4447 - val_accuracy: 0.8096\n",
      "Epoch 122/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3903 - accuracy: 0.8480 - val_loss: 0.4451 - val_accuracy: 0.8066\n",
      "Epoch 123/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3896 - accuracy: 0.8489 - val_loss: 0.4447 - val_accuracy: 0.8066\n",
      "Epoch 124/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3890 - accuracy: 0.8491 - val_loss: 0.4436 - val_accuracy: 0.8096\n",
      "Epoch 125/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3884 - accuracy: 0.8500 - val_loss: 0.4432 - val_accuracy: 0.8096\n",
      "Epoch 126/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3878 - accuracy: 0.8501 - val_loss: 0.4435 - val_accuracy: 0.8076\n",
      "Epoch 127/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8508 - val_loss: 0.4428 - val_accuracy: 0.8091\n",
      "Epoch 128/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8511 - val_loss: 0.4424 - val_accuracy: 0.8106\n",
      "Epoch 129/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8516 - val_loss: 0.4421 - val_accuracy: 0.8106\n",
      "Epoch 130/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8511 - val_loss: 0.4429 - val_accuracy: 0.8076\n",
      "Epoch 131/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3849 - accuracy: 0.8514 - val_loss: 0.4415 - val_accuracy: 0.8096\n",
      "Epoch 132/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.8510 - val_loss: 0.4413 - val_accuracy: 0.8096\n",
      "Epoch 133/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8516 - val_loss: 0.4407 - val_accuracy: 0.8106\n",
      "Epoch 134/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8514 - val_loss: 0.4403 - val_accuracy: 0.8120\n",
      "Epoch 135/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8520 - val_loss: 0.4400 - val_accuracy: 0.8111\n",
      "Epoch 136/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3820 - accuracy: 0.8518 - val_loss: 0.4397 - val_accuracy: 0.8101\n",
      "Epoch 137/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8525 - val_loss: 0.4394 - val_accuracy: 0.8111\n",
      "Epoch 138/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8528 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 139/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3805 - accuracy: 0.8533 - val_loss: 0.4397 - val_accuracy: 0.8091\n",
      "Epoch 140/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3798 - accuracy: 0.8539 - val_loss: 0.4386 - val_accuracy: 0.8115\n",
      "Epoch 141/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8544 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 142/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8543 - val_loss: 0.4382 - val_accuracy: 0.8120\n",
      "Epoch 143/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8554 - val_loss: 0.4378 - val_accuracy: 0.8115\n",
      "Epoch 144/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8552 - val_loss: 0.4377 - val_accuracy: 0.8125\n",
      "Epoch 145/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8547 - val_loss: 0.4373 - val_accuracy: 0.8115\n",
      "Epoch 146/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8547 - val_loss: 0.4375 - val_accuracy: 0.8125\n",
      "Epoch 147/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8549 - val_loss: 0.4370 - val_accuracy: 0.8115\n",
      "Epoch 148/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8558 - val_loss: 0.4366 - val_accuracy: 0.8125\n",
      "Epoch 149/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3752 - accuracy: 0.8549 - val_loss: 0.4383 - val_accuracy: 0.8086\n",
      "Epoch 150/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8565 - val_loss: 0.4370 - val_accuracy: 0.8115\n",
      "Epoch 151/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8558 - val_loss: 0.4357 - val_accuracy: 0.8135\n",
      "Epoch 152/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3737 - accuracy: 0.8565 - val_loss: 0.4366 - val_accuracy: 0.8115\n",
      "Epoch 153/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8565 - val_loss: 0.4352 - val_accuracy: 0.8135\n",
      "Epoch 154/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8556 - val_loss: 0.4349 - val_accuracy: 0.8111\n",
      "Epoch 155/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8579 - val_loss: 0.4349 - val_accuracy: 0.8120\n",
      "Epoch 156/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3718 - accuracy: 0.8576 - val_loss: 0.4346 - val_accuracy: 0.8115\n",
      "Epoch 157/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8581 - val_loss: 0.4348 - val_accuracy: 0.8130\n",
      "Epoch 158/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3709 - accuracy: 0.8574 - val_loss: 0.4340 - val_accuracy: 0.8101\n",
      "Epoch 159/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8580 - val_loss: 0.4352 - val_accuracy: 0.8115\n",
      "Epoch 160/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3701 - accuracy: 0.8581 - val_loss: 0.4336 - val_accuracy: 0.8150\n",
      "Epoch 161/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3696 - accuracy: 0.8585 - val_loss: 0.4337 - val_accuracy: 0.8125\n",
      "Epoch 162/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3692 - accuracy: 0.8584 - val_loss: 0.4334 - val_accuracy: 0.8120\n",
      "Epoch 163/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8584 - val_loss: 0.4332 - val_accuracy: 0.8125\n",
      "Epoch 164/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8592 - val_loss: 0.4339 - val_accuracy: 0.8150\n",
      "Epoch 165/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3677 - accuracy: 0.8586 - val_loss: 0.4328 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3674 - accuracy: 0.8583 - val_loss: 0.4322 - val_accuracy: 0.8115\n",
      "Epoch 167/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8589 - val_loss: 0.4323 - val_accuracy: 0.8120\n",
      "Epoch 168/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8599 - val_loss: 0.4319 - val_accuracy: 0.8120\n",
      "Epoch 169/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3661 - accuracy: 0.8596 - val_loss: 0.4318 - val_accuracy: 0.8130\n",
      "Epoch 170/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.8593 - val_loss: 0.4328 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3652 - accuracy: 0.8607 - val_loss: 0.4313 - val_accuracy: 0.8140\n",
      "Epoch 172/200\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3649 - accuracy: 0.8598 - val_loss: 0.4318 - val_accuracy: 0.8150\n",
      "Epoch 173/200\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3643 - accuracy: 0.8595 - val_loss: 0.4321 - val_accuracy: 0.8150\n",
      "Epoch 174/200\n",
      "507/507 [==============================] - 3s 7ms/step - loss: 0.3640 - accuracy: 0.8599 - val_loss: 0.4312 - val_accuracy: 0.8140\n",
      "Epoch 175/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3636 - accuracy: 0.8611 - val_loss: 0.4308 - val_accuracy: 0.8130\n",
      "Epoch 176/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3633 - accuracy: 0.8597 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
      "Epoch 177/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8601 - val_loss: 0.4301 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8615 - val_loss: 0.4299 - val_accuracy: 0.8130\n",
      "Epoch 179/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8608 - val_loss: 0.4307 - val_accuracy: 0.8165\n",
      "Epoch 180/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8599 - val_loss: 0.4296 - val_accuracy: 0.8135\n",
      "Epoch 181/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8607 - val_loss: 0.4298 - val_accuracy: 0.8135\n",
      "Epoch 182/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8618 - val_loss: 0.4297 - val_accuracy: 0.8135\n",
      "Epoch 183/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8626 - val_loss: 0.4308 - val_accuracy: 0.8155\n",
      "Epoch 184/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8620 - val_loss: 0.4288 - val_accuracy: 0.8115\n",
      "Epoch 185/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8618 - val_loss: 0.4288 - val_accuracy: 0.8150\n",
      "Epoch 186/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8612 - val_loss: 0.4301 - val_accuracy: 0.8160\n",
      "Epoch 187/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8613 - val_loss: 0.4299 - val_accuracy: 0.8165\n",
      "Epoch 188/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8609 - val_loss: 0.4282 - val_accuracy: 0.8145\n",
      "Epoch 189/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8620 - val_loss: 0.4285 - val_accuracy: 0.8125\n",
      "Epoch 190/200\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3578 - accuracy: 0.8623 - val_loss: 0.4288 - val_accuracy: 0.8175\n",
      "Epoch 191/200\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3574 - accuracy: 0.8618 - val_loss: 0.4299 - val_accuracy: 0.8155\n",
      "Epoch 192/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3572 - accuracy: 0.8623 - val_loss: 0.4275 - val_accuracy: 0.8120\n",
      "Epoch 193/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8626 - val_loss: 0.4278 - val_accuracy: 0.8130\n",
      "Epoch 194/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8634 - val_loss: 0.4273 - val_accuracy: 0.8155\n",
      "Epoch 195/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.8626 - val_loss: 0.4270 - val_accuracy: 0.8130\n",
      "Epoch 196/200\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8633 - val_loss: 0.4273 - val_accuracy: 0.8130\n",
      "Epoch 197/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8635 - val_loss: 0.4269 - val_accuracy: 0.8150\n",
      "Epoch 198/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8637 - val_loss: 0.4267 - val_accuracy: 0.8150\n",
      "Epoch 199/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8641 - val_loss: 0.4268 - val_accuracy: 0.8150\n",
      "Epoch 200/200\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8641 - val_loss: 0.4279 - val_accuracy: 0.8165\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8640\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8175\n",
      "training loss: 0.35726192593574524 training accuracy 0.8639950752258301\n",
      "validation loss: 0.42880958318710327 validation accuracy 0.8174642324447632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=200, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer], initial_epoch=100)\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories[-1] = history\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703c5a9-bd2b-46b3-9bee-bcc381ac8189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3574 - accuracy: 0.8630 - val_loss: 0.4288 - val_accuracy: 0.8155\n",
      "Epoch 202/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3571 - accuracy: 0.8625 - val_loss: 0.4279 - val_accuracy: 0.8125\n",
      "Epoch 203/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.8631 - val_loss: 0.4274 - val_accuracy: 0.8155\n",
      "Epoch 204/1000\n",
      "507/507 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8628 - val_loss: 0.4279 - val_accuracy: 0.8155\n",
      "Epoch 205/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3560 - accuracy: 0.8641 - val_loss: 0.4277 - val_accuracy: 0.8155\n",
      "Epoch 206/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8636 - val_loss: 0.4271 - val_accuracy: 0.8155\n",
      "Epoch 207/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3553 - accuracy: 0.8634 - val_loss: 0.4274 - val_accuracy: 0.8155\n",
      "Epoch 208/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3550 - accuracy: 0.8637 - val_loss: 0.4279 - val_accuracy: 0.8160\n",
      "Epoch 209/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8637 - val_loss: 0.4266 - val_accuracy: 0.8165\n",
      "Epoch 210/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8647 - val_loss: 0.4263 - val_accuracy: 0.8145\n",
      "Epoch 211/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.8648 - val_loss: 0.4262 - val_accuracy: 0.8140\n",
      "Epoch 212/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8642 - val_loss: 0.4260 - val_accuracy: 0.8140\n",
      "Epoch 213/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8663 - val_loss: 0.4274 - val_accuracy: 0.8165\n",
      "Epoch 214/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8650 - val_loss: 0.4258 - val_accuracy: 0.8140\n",
      "Epoch 215/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8655 - val_loss: 0.4259 - val_accuracy: 0.8175\n",
      "Epoch 216/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3523 - accuracy: 0.8657 - val_loss: 0.4259 - val_accuracy: 0.8165\n",
      "Epoch 217/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8645 - val_loss: 0.4255 - val_accuracy: 0.8170\n",
      "Epoch 218/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8651 - val_loss: 0.4253 - val_accuracy: 0.8155\n",
      "Epoch 219/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8654 - val_loss: 0.4263 - val_accuracy: 0.8145\n",
      "Epoch 220/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8662 - val_loss: 0.4249 - val_accuracy: 0.8145\n",
      "Epoch 221/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3507 - accuracy: 0.8650 - val_loss: 0.4249 - val_accuracy: 0.8145\n",
      "Epoch 222/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8652 - val_loss: 0.4254 - val_accuracy: 0.8165\n",
      "Epoch 223/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8665 - val_loss: 0.4252 - val_accuracy: 0.8165\n",
      "Epoch 224/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8651 - val_loss: 0.4245 - val_accuracy: 0.8150\n",
      "Epoch 225/1000\n",
      "507/507 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8666 - val_loss: 0.4243 - val_accuracy: 0.8150\n",
      "Epoch 226/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3491 - accuracy: 0.8665 - val_loss: 0.4249 - val_accuracy: 0.8160\n",
      "Epoch 227/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3488 - accuracy: 0.8660 - val_loss: 0.4242 - val_accuracy: 0.8175\n",
      "Epoch 228/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8663 - val_loss: 0.4241 - val_accuracy: 0.8180\n",
      "Epoch 229/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8669 - val_loss: 0.4240 - val_accuracy: 0.8180\n",
      "Epoch 230/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.8672 - val_loss: 0.4248 - val_accuracy: 0.8140\n",
      "Epoch 231/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8675 - val_loss: 0.4239 - val_accuracy: 0.8185\n",
      "Epoch 232/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8676 - val_loss: 0.4237 - val_accuracy: 0.8180\n",
      "Epoch 233/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8664 - val_loss: 0.4234 - val_accuracy: 0.8155\n",
      "Epoch 234/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8669 - val_loss: 0.4232 - val_accuracy: 0.8165\n",
      "Epoch 235/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8676 - val_loss: 0.4231 - val_accuracy: 0.8155\n",
      "Epoch 236/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8685 - val_loss: 0.4230 - val_accuracy: 0.8155\n",
      "Epoch 237/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8681 - val_loss: 0.4229 - val_accuracy: 0.8165\n",
      "Epoch 238/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8678 - val_loss: 0.4227 - val_accuracy: 0.8165\n",
      "Epoch 239/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8682 - val_loss: 0.4234 - val_accuracy: 0.8180\n",
      "Epoch 240/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8685 - val_loss: 0.4225 - val_accuracy: 0.8175\n",
      "Epoch 241/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8682 - val_loss: 0.4230 - val_accuracy: 0.8189\n",
      "Epoch 242/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.8678 - val_loss: 0.4225 - val_accuracy: 0.8175\n",
      "Epoch 243/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8699 - val_loss: 0.4224 - val_accuracy: 0.8175\n",
      "Epoch 244/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8694 - val_loss: 0.4223 - val_accuracy: 0.8175\n",
      "Epoch 245/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8688 - val_loss: 0.4221 - val_accuracy: 0.8175\n",
      "Epoch 246/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8700 - val_loss: 0.4223 - val_accuracy: 0.8170\n",
      "Epoch 247/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3429 - accuracy: 0.8690 - val_loss: 0.4221 - val_accuracy: 0.8170\n",
      "Epoch 248/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3427 - accuracy: 0.8704 - val_loss: 0.4219 - val_accuracy: 0.8180\n",
      "Epoch 249/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8691 - val_loss: 0.4234 - val_accuracy: 0.8140\n",
      "Epoch 250/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3421 - accuracy: 0.8700 - val_loss: 0.4225 - val_accuracy: 0.8165\n",
      "Epoch 251/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8689 - val_loss: 0.4214 - val_accuracy: 0.8160\n",
      "Epoch 252/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8701 - val_loss: 0.4224 - val_accuracy: 0.8180\n",
      "Epoch 253/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8699 - val_loss: 0.4212 - val_accuracy: 0.8170\n",
      "Epoch 254/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8698 - val_loss: 0.4211 - val_accuracy: 0.8170\n",
      "Epoch 255/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8708 - val_loss: 0.4212 - val_accuracy: 0.8185\n",
      "Epoch 256/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8709 - val_loss: 0.4211 - val_accuracy: 0.8175\n",
      "Epoch 257/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3402 - accuracy: 0.8704 - val_loss: 0.4214 - val_accuracy: 0.8175\n",
      "Epoch 258/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8711 - val_loss: 0.4208 - val_accuracy: 0.8175\n",
      "Epoch 259/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8711 - val_loss: 0.4221 - val_accuracy: 0.8160\n",
      "Epoch 260/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8703 - val_loss: 0.4206 - val_accuracy: 0.8199\n",
      "Epoch 261/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8712 - val_loss: 0.4207 - val_accuracy: 0.8180\n",
      "Epoch 262/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8716 - val_loss: 0.4206 - val_accuracy: 0.8180\n",
      "Epoch 263/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8707 - val_loss: 0.4207 - val_accuracy: 0.8175\n",
      "Epoch 264/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8715 - val_loss: 0.4214 - val_accuracy: 0.8189\n",
      "Epoch 265/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.8717 - val_loss: 0.4204 - val_accuracy: 0.8189\n",
      "Epoch 266/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8712 - val_loss: 0.4200 - val_accuracy: 0.8165\n",
      "Epoch 267/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8705 - val_loss: 0.4203 - val_accuracy: 0.8175\n",
      "Epoch 268/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8725 - val_loss: 0.4199 - val_accuracy: 0.8180\n",
      "Epoch 269/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8716 - val_loss: 0.4200 - val_accuracy: 0.8194\n",
      "Epoch 270/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8716 - val_loss: 0.4210 - val_accuracy: 0.8180\n",
      "Epoch 271/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8719 - val_loss: 0.4197 - val_accuracy: 0.8204\n",
      "Epoch 272/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3365 - accuracy: 0.8727 - val_loss: 0.4203 - val_accuracy: 0.8189\n",
      "Epoch 273/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8726 - val_loss: 0.4206 - val_accuracy: 0.8189\n",
      "Epoch 274/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8726 - val_loss: 0.4200 - val_accuracy: 0.8189\n",
      "Epoch 275/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8725 - val_loss: 0.4196 - val_accuracy: 0.8185\n",
      "Epoch 276/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8724 - val_loss: 0.4194 - val_accuracy: 0.8199\n",
      "Epoch 277/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8727 - val_loss: 0.4192 - val_accuracy: 0.8199\n",
      "Epoch 278/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8731 - val_loss: 0.4192 - val_accuracy: 0.8199\n",
      "Epoch 279/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8721 - val_loss: 0.4198 - val_accuracy: 0.8185\n",
      "Epoch 280/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8726 - val_loss: 0.4190 - val_accuracy: 0.8189\n",
      "Epoch 281/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8726 - val_loss: 0.4193 - val_accuracy: 0.8189\n",
      "Epoch 282/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8740 - val_loss: 0.4193 - val_accuracy: 0.8189\n",
      "Epoch 283/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8740 - val_loss: 0.4204 - val_accuracy: 0.8165\n",
      "Epoch 284/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8739 - val_loss: 0.4187 - val_accuracy: 0.8175\n",
      "Epoch 285/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8729 - val_loss: 0.4187 - val_accuracy: 0.8185\n",
      "Epoch 286/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8729 - val_loss: 0.4200 - val_accuracy: 0.8175\n",
      "Epoch 287/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8732 - val_loss: 0.4199 - val_accuracy: 0.8170\n",
      "Epoch 288/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3326 - accuracy: 0.8744 - val_loss: 0.4184 - val_accuracy: 0.8180\n",
      "Epoch 289/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8729 - val_loss: 0.4188 - val_accuracy: 0.8204\n",
      "Epoch 290/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8745 - val_loss: 0.4191 - val_accuracy: 0.8194\n",
      "Epoch 291/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8741 - val_loss: 0.4201 - val_accuracy: 0.8165\n",
      "Epoch 292/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8750 - val_loss: 0.4181 - val_accuracy: 0.8189\n",
      "Epoch 293/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8749 - val_loss: 0.4184 - val_accuracy: 0.8209\n",
      "Epoch 294/1000\n",
      "507/507 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8745 - val_loss: 0.4180 - val_accuracy: 0.8180\n",
      "Epoch 295/1000\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8753 - val_loss: 0.4179 - val_accuracy: 0.8189\n",
      "Epoch 296/1000\n",
      "115/507 [=====>........................] - ETA: 1s - loss: 0.3340 - accuracy: 0.8774"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(dev_feats_matrix, dev_label_matrix),\n",
    "                    epochs=1000, batch_size=32, verbose=1,\n",
    "                    callbacks=[checkpointer], initial_epoch=200)\n",
    "model = keras.models.load_model(\"./models/mlp.keras\",\n",
    "                                custom_objects={\"LayerNormalization\": LayerNormalization})\n",
    "\n",
    "train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n",
    "                             batch_size=32)\n",
    "dev_score = model.evaluate(dev_feats_matrix, dev_label_matrix,\n",
    "                           batch_size=32)\n",
    "\n",
    "histories[-1] = history\n",
    "\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"validation loss:\", dev_score[0], \"validation accuracy\", dev_score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECS289G",
   "language": "python",
   "name": "ecs289g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
